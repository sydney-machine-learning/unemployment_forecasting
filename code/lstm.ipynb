{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9\n",
      "         CPI  CurrentACT  Minwage  Immigration   NASDAQ       RGDP   YthUnem  \\\n",
      "2     40.000        0.24     1.60     370478.0   105.97   4834.349  12.63333   \n",
      "3     40.500       -0.14     1.60     370478.0   107.80   4861.938  12.90000   \n",
      "4     40.800       -0.18     1.60     370478.0   109.03   4899.950  12.70000   \n",
      "5     41.100       -0.39     1.60     370478.0   114.12   4914.261  12.70000   \n",
      "6     41.400       -0.55     1.60     384685.0   128.14   5002.436  12.76667   \n",
      "7     41.700       -0.53     1.60     384685.0   130.08   5118.278  12.00000   \n",
      "8     42.100       -0.40     1.60     384685.0   129.61   5165.448  12.03333   \n",
      "9     42.500       -0.34     1.60     384685.0   133.73   5251.226  11.60000   \n",
      "10    43.400        0.04     1.60     398515.0   117.46   5380.502  10.50000   \n",
      "11    44.200        0.25     1.60     398515.0   100.98   5441.504  10.70000   \n",
      "12    45.200        0.76     1.60     398515.0   111.20   5411.935  10.53333   \n",
      "13    46.300        0.91     1.60     398515.0    92.19   5462.397  10.30000   \n",
      "14    47.800        0.43     1.60     393919.0    92.27   5417.024  10.83333   \n",
      "15    49.000        0.03     2.00     393919.0    75.96   5431.265  11.20000   \n",
      "16    50.600       -0.08     2.00     393919.0    55.67   5378.679  12.13333   \n",
      "17    51.900        0.13     2.00     393919.0    59.82   5357.166  13.36667   \n",
      "18    52.800        1.04     2.10     385378.0    75.66   5292.444  15.63333   \n",
      "19    53.500        1.21     2.10     385378.0    87.02   5333.220  16.56667   \n",
      "20    54.600        0.95     2.10     385378.0    74.33   5421.357  16.33333   \n",
      "21    55.600        1.09     2.10     385378.0    77.62   5494.446  15.80000   \n",
      "22    56.000        0.56     2.30     499093.0    90.62   5618.520  14.90000   \n",
      "23    56.700        0.36     2.30     499093.0    90.32   5660.972  14.56667   \n",
      "24    57.600       -0.02     2.30     499093.0    91.26   5689.756  14.53333   \n",
      "25    58.400        0.03     2.30     499093.0    97.88   5732.462  14.86667   \n",
      "26    59.600       -0.54     2.30     458755.0    94.13   5799.160  14.33333   \n",
      "27    60.500       -0.59     2.30     458755.0    99.73   5912.977  13.80000   \n",
      "28    61.300       -0.52     2.30     458755.0   100.85   6017.586  13.50000   \n",
      "29    62.300       -1.08     2.30     458755.0   105.05   6018.218  12.76667   \n",
      "30    63.400       -1.27     2.65     589810.0   106.20   6039.158  12.96667   \n",
      "31    65.000       -0.65     2.65     589810.0   120.30   6273.963  12.03333   \n",
      "..       ...         ...      ...          ...      ...        ...       ...   \n",
      "144  202.800       -6.17     5.15    1266129.0  2258.43  14602.633  10.73333   \n",
      "145  203.100       -5.33     5.15    1266129.0  2415.29  14716.930  10.40000   \n",
      "146  205.288       -5.58     5.15    1052415.0  2421.64  14726.022  10.06667   \n",
      "147  207.234       -5.22     5.15    1052415.0  2603.23  14838.664  10.26667   \n",
      "148  208.547       -4.64     5.85    1052415.0  2701.50  14938.467  10.80000   \n",
      "149  211.445       -4.29     5.85    1052415.0  2652.28  14991.784  11.06667   \n",
      "150  213.448       -4.90     5.85    1107126.0  2279.10  14889.450  11.50000   \n",
      "151  217.463       -4.77     5.85    1107126.0  2292.98  14963.357  12.30000   \n",
      "152  218.877       -4.71     6.55    1107126.0  2082.33  14891.643  13.36667   \n",
      "153  211.398       -4.14     6.55    1107126.0  1577.03  14576.985  14.13333   \n",
      "154  212.495       -2.68     6.55    1130818.0  1528.59  14375.018  15.83333   \n",
      "155  214.790       -2.46     6.55    1130818.0  1835.04  14355.558  17.43333   \n",
      "156  215.861       -2.61     7.25    1130818.0  2122.42  14402.477  18.13333   \n",
      "157  217.347       -2.84     7.25    1130818.0  2269.15  14541.901  19.03333   \n",
      "158  217.353       -2.98     7.25    1042625.0  2397.96  14604.845  18.76667   \n",
      "159  217.199       -3.10     7.25    1042625.0  2109.24  14745.933  18.60000   \n",
      "160  218.275       -3.20     7.25    1042625.0  2368.62  14845.458  18.00000   \n",
      "161  220.472       -2.74     7.25    1042625.0  2652.87  14939.001  18.36667   \n",
      "162  223.046       -3.06     7.25    1062040.0  2781.07  14881.301  17.80000   \n",
      "163  224.806       -3.08     7.25    1062040.0  2773.52  14989.555  17.33333   \n",
      "164  226.597       -2.71     7.25    1062040.0  2415.40  15021.149  17.33333   \n",
      "165  227.223       -2.95     7.25    1062040.0  2605.15  15190.255  16.80000   \n",
      "166  228.807       -3.03     7.25    1031631.0  3091.57  15291.035  16.26667   \n",
      "167  228.524       -2.74     7.25    1031631.0  2935.06  15362.415  16.30000   \n",
      "168  231.015       -2.63     7.25    1031631.0  3116.23  15380.802  16.16667   \n",
      "169  231.221       -2.51     7.25    1031631.0  3019.51  15384.254  16.13333   \n",
      "170  232.299       -2.55     7.25     990553.0  3267.52  15491.878  16.40000   \n",
      "171  232.374       -2.34     7.25     990553.0  3403.25  15521.559  16.20000   \n",
      "172  233.632       -2.30     7.25     990553.0  3771.48  15641.336  15.33333   \n",
      "173  234.723       -1.91     7.25     990553.0  4176.59  15793.928  14.16667   \n",
      "\n",
      "      LaborFrc  Hsingstrt  Fedfund      Unem  \n",
      "2     83676.00       1910     3.71  5.933333  \n",
      "3     83929.00       2026     4.91  5.900000  \n",
      "4     84581.34       2041     5.55  6.033333  \n",
      "5     85318.34       2295     4.14  5.933333  \n",
      "6     86208.34       2334     3.83  5.766667  \n",
      "7     86809.66       2254     4.46  5.700000  \n",
      "8     87350.66       2481     4.87  5.566667  \n",
      "9     87675.34       2366     5.33  5.366667  \n",
      "10    88232.34       2365     7.09  4.933333  \n",
      "11    89181.00       2067     8.49  4.933333  \n",
      "12    89650.34       1874    10.78  4.800000  \n",
      "13    90579.00       1526     9.95  4.766667  \n",
      "14    91379.00       1555     9.35  5.133333  \n",
      "15    91583.66       1513    11.93  5.200000  \n",
      "16    92253.00       1150    11.34  5.633333  \n",
      "17    92688.00        975     8.53  6.600000  \n",
      "18    93023.00        993     5.54  8.266666  \n",
      "19    93619.34       1087     5.55  8.866667  \n",
      "20    94128.34       1264     6.24  8.466666  \n",
      "21    94308.66       1321     5.20  8.300000  \n",
      "22    95049.00       1421     4.84  7.733333  \n",
      "23    95826.00       1495     5.48  7.566667  \n",
      "24    96625.66       1720     5.25  7.733333  \n",
      "25    97102.00       1804     4.65  7.766667  \n",
      "26    97702.66       2063     4.69  7.500000  \n",
      "27    98696.00       1893     5.39  7.133333  \n",
      "28    99244.00       1949     6.14  6.900000  \n",
      "29   100294.00       2142     6.56  6.666667  \n",
      "30   100934.00       2032     6.79  6.333333  \n",
      "31   101947.00       2070     7.60  6.000000  \n",
      "..         ...        ...      ...       ...  \n",
      "144  151585.00       1720     5.25  4.633333  \n",
      "145  152393.00       1649     5.24  4.433333  \n",
      "146  153059.30       1495     5.26  4.500000  \n",
      "147  152715.30       1448     5.25  4.500000  \n",
      "148  153072.30       1183     4.94  4.666667  \n",
      "149  153645.30       1037     4.24  4.800000  \n",
      "150  153874.70       1005     2.61  5.000000  \n",
      "151  154128.30       1046     2.00  5.333333  \n",
      "152  154560.00        820     1.81  6.000000  \n",
      "153  154723.30        560     0.16  6.866667  \n",
      "154  154293.70        505     0.18  8.266666  \n",
      "155  154657.30        585     0.21  9.300000  \n",
      "156  154212.00        585     0.15  9.633333  \n",
      "157  153591.00        581     0.12  9.933333  \n",
      "158  153710.70        636     0.16  9.833333  \n",
      "159  154109.70        536     0.18  9.633333  \n",
      "160  153917.30        594     0.19  9.466666  \n",
      "161  153803.30        539     0.18  9.500000  \n",
      "162  153284.30        600     0.14  9.033334  \n",
      "163  153456.00        608     0.09  9.066667  \n",
      "164  153726.30        650     0.08  9.000000  \n",
      "165  154028.00        694     0.07  8.633333  \n",
      "166  154600.30        695     0.13  8.266666  \n",
      "167  154831.30        757     0.16  8.200000  \n",
      "168  154957.00        847     0.14  8.033334  \n",
      "169  155506.70        976     0.16  7.800000  \n",
      "170  155317.70        999     0.14  7.733333  \n",
      "171  155539.00        852     0.09  7.533333  \n",
      "172  155662.30        860     0.08  7.266667  \n",
      "173  155062.70       1010     0.09  6.933333  \n",
      "\n",
      "[172 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras.layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "import seaborn as sns\n",
    "from keras import Sequential\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "datad = pd.read_csv('USunemqt.csv')\n",
    "#datad = datad.iloc[:,:-1]\n",
    "date = datad.loc[:,'DATE']\n",
    "date = date.iloc[2:]\n",
    "cols = datad.columns.tolist()\n",
    "cols = cols[2:] + cols[:2]\n",
    "datad = datad.reindex(columns = cols)\n",
    "datadmin=3.9\n",
    "datadmax = 10.66667\n",
    "\n",
    "datad = datad.drop('DATE', axis = 1)\n",
    "#datad = datad.drop(['Hsingstrt','Fedfund'], axis = 1)\n",
    "#datad = datad.diff()\n",
    "datad = datad.dropna()\n",
    "x = datad.loc[:,'Unem']\n",
    "print(x.min())\n",
    "print(datad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140    2005-Q3\n",
       "141    2005-Q4\n",
       "142    2006-Q1\n",
       "143    2006-Q2\n",
       "144    2006-Q3\n",
       "145    2006-Q4\n",
       "146    2007-Q1\n",
       "147    2007-Q2\n",
       "148    2007-Q3\n",
       "149    2007-Q4\n",
       "150    2008-Q1\n",
       "151    2008-Q2\n",
       "152    2008-Q3\n",
       "153    2008-Q4\n",
       "154    2009-Q1\n",
       "155    2009-Q2\n",
       "156    2009-Q3\n",
       "157    2009-Q4\n",
       "158    2010-Q1\n",
       "159    2010-Q2\n",
       "160    2010-Q3\n",
       "161    2010-Q4\n",
       "162    2011-Q1\n",
       "163    2011-Q2\n",
       "164    2011-Q3\n",
       "165    2011-Q4\n",
       "166    2012-Q1\n",
       "167    2012-Q2\n",
       "168    2012-Q3\n",
       "169    2012-Q4\n",
       "170    2013-Q1\n",
       "171    2013-Q2\n",
       "172    2013-Q3\n",
       "173    2013-Q4\n",
       "Name: DATE, dtype: object"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract test dates for later\n",
    "Datadate = pd.read_csv('USunemqt.csv')\n",
    "dates = Datadate.iloc[140:174,0]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var6(t-2)  \\\n",
      "0     0.004108   0.812668   0.000000   0.000000   0.011813   0.005986   \n",
      "1     0.005649   0.784367   0.000000   0.000000   0.012940   0.007292   \n",
      "2     0.007190   0.762803   0.000000   0.009757   0.016043   0.015337   \n",
      "3     0.008730   0.765499   0.000000   0.009757   0.016473   0.025907   \n",
      "4     0.010785   0.783019   0.000000   0.009757   0.016369   0.030211   \n",
      "5     0.012839   0.791105   0.000000   0.009757   0.017281   0.038038   \n",
      "6     0.017461   0.842318   0.000000   0.019255   0.013679   0.049833   \n",
      "7     0.021569   0.870620   0.000000   0.019255   0.010031   0.055399   \n",
      "8     0.026705   0.939353   0.000000   0.019255   0.012293   0.052701   \n",
      "9     0.032354   0.959569   0.000000   0.019255   0.008085   0.057306   \n",
      "10    0.040057   0.894879   0.000000   0.016098   0.008102   0.053166   \n",
      "11    0.046220   0.840970   0.070796   0.016098   0.004492   0.054465   \n",
      "12    0.054436   0.826146   0.070796   0.016098   0.000000   0.049667   \n",
      "13    0.061112   0.854447   0.070796   0.016098   0.000919   0.047704   \n",
      "14    0.065734   0.977089   0.088496   0.010233   0.004425   0.041799   \n",
      "15    0.069329   1.000000   0.088496   0.010233   0.006940   0.045519   \n",
      "16    0.074978   0.964960   0.088496   0.010233   0.004131   0.053561   \n",
      "17    0.080114   0.983827   0.088496   0.010233   0.004859   0.060230   \n",
      "18    0.082168   0.912399   0.123894   0.088327   0.007737   0.071551   \n",
      "19    0.085763   0.885445   0.123894   0.088327   0.007671   0.075425   \n",
      "20    0.090385   0.834232   0.123894   0.088327   0.007879   0.078051   \n",
      "21    0.094493   0.840970   0.123894   0.088327   0.009344   0.081948   \n",
      "22    0.100656   0.764151   0.123894   0.060625   0.008514   0.088034   \n",
      "23    0.105278   0.757412   0.123894   0.060625   0.009754   0.098419   \n",
      "24    0.109386   0.766846   0.123894   0.060625   0.010002   0.107964   \n",
      "25    0.114522   0.691375   0.123894   0.060625   0.010932   0.108021   \n",
      "26    0.120171   0.665768   0.185841   0.150628   0.011186   0.109932   \n",
      "27    0.128388   0.749326   0.185841   0.150628   0.014308   0.131357   \n",
      "28    0.136091   0.754717   0.185841   0.150628   0.017095   0.136955   \n",
      "29    0.143280   0.822102   0.185841   0.150628   0.013794   0.144708   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "140   0.836059   0.005391   0.628319   0.615095   0.487643   0.891301   \n",
      "141   0.837600   0.118598   0.628319   0.615095   0.522368   0.901730   \n",
      "142   0.848837   0.084906   0.628319   0.468326   0.523774   0.902560   \n",
      "143   0.858830   0.133423   0.628319   0.468326   0.563974   0.912838   \n",
      "144   0.865573   0.211590   0.752212   0.468326   0.585729   0.921944   \n",
      "145   0.880456   0.258760   0.752212   0.468326   0.574832   0.926809   \n",
      "146   0.890742   0.176550   0.752212   0.505899   0.492219   0.917471   \n",
      "147   0.911361   0.194070   0.752212   0.505899   0.495291   0.924215   \n",
      "148   0.918623   0.202156   0.876106   0.505899   0.448658   0.917672   \n",
      "149   0.880214   0.278976   0.876106   0.505899   0.336796   0.888961   \n",
      "150   0.885848   0.475741   0.876106   0.522170   0.326072   0.870532   \n",
      "151   0.897634   0.505391   0.876106   0.522170   0.393913   0.868757   \n",
      "152   0.903134   0.485175   1.000000   0.522170   0.457533   0.873038   \n",
      "153   0.910766   0.454178   1.000000   0.522170   0.490016   0.885760   \n",
      "154   0.910796   0.435310   1.000000   0.461602   0.518532   0.891503   \n",
      "155   0.910005   0.419137   1.000000   0.461602   0.454615   0.904376   \n",
      "156   0.915531   0.405660   1.000000   0.461602   0.512036   0.913457   \n",
      "157   0.926814   0.467655   1.000000   0.461602   0.574963   0.921993   \n",
      "158   0.940033   0.424528   1.000000   0.474936   0.603344   0.916728   \n",
      "159   0.949071   0.421833   1.000000   0.474936   0.601672   0.926605   \n",
      "160   0.958269   0.471698   1.000000   0.474936   0.522392   0.929488   \n",
      "161   0.961484   0.439353   1.000000   0.474936   0.564399   0.944918   \n",
      "162   0.969618   0.428571   1.000000   0.454052   0.672082   0.954114   \n",
      "163   0.968165   0.467655   1.000000   0.454052   0.637434   0.960627   \n",
      "164   0.980958   0.482480   1.000000   0.454052   0.677541   0.962305   \n",
      "165   0.982015   0.498652   1.000000   0.454052   0.656129   0.962620   \n",
      "166   0.987552   0.493261   1.000000   0.425841   0.711033   0.972440   \n",
      "167   0.987937   0.521563   1.000000   0.425841   0.741081   0.975148   \n",
      "168   0.994397   0.526954   1.000000   0.425841   0.822599   0.986077   \n",
      "169   1.000000   0.579515   1.000000   0.425841   0.912281   1.000000   \n",
      "\n",
      "     var7(t-2)  var8(t-2)  var9(t-2)  var10(t-2)     ...      var2(t+2)  \\\n",
      "0     0.364549   0.012577   0.777328    0.287966     ...       0.812668   \n",
      "1     0.364549   0.022815   0.905870    0.213873     ...       0.784367   \n",
      "2     0.371238   0.035178   0.925607    0.197583     ...       0.762803   \n",
      "3     0.294314   0.043531   0.885121    0.230688     ...       0.765499   \n",
      "4     0.297659   0.051047   1.000000    0.252233     ...       0.783019   \n",
      "5     0.254181   0.055557   0.941802    0.276406     ...       0.791105   \n",
      "6     0.143813   0.063295   0.941296    0.368891     ...       0.842318   \n",
      "7     0.163880   0.076473   0.790486    0.442459     ...       0.870620   \n",
      "8     0.147157   0.082993   0.692814    0.562796     ...       0.939353   \n",
      "9     0.123746   0.095893   0.516700    0.519180     ...       0.959569   \n",
      "10    0.177257   0.107006   0.531377    0.487651     ...       0.894879   \n",
      "11    0.214047   0.109850   0.510121    0.623226     ...       0.840970   \n",
      "12    0.307692   0.119148   0.326417    0.592223     ...       0.826146   \n",
      "13    0.431439   0.125190   0.237854    0.444561     ...       0.854447   \n",
      "14    0.658863   0.129844   0.246964    0.287441     ...       0.977089   \n",
      "15    0.752509   0.138128   0.294534    0.287966     ...       1.000000   \n",
      "16    0.729097   0.145199   0.384109    0.324225     ...       0.964960   \n",
      "17    0.675585   0.147704   0.412955    0.269574     ...       0.983827   \n",
      "18    0.585284   0.157988   0.463563    0.250657     ...       0.912399   \n",
      "19    0.551840   0.168782   0.501012    0.284288     ...       0.885445   \n",
      "20    0.548495   0.179891   0.614879    0.272202     ...       0.834232   \n",
      "21    0.581940   0.186508   0.657389    0.240673     ...       0.840970   \n",
      "22    0.528428   0.194852   0.788462    0.242775     ...       0.764151   \n",
      "23    0.474917   0.208651   0.702429    0.279559     ...       0.757412   \n",
      "24    0.444816   0.216263   0.730769    0.318970     ...       0.766846   \n",
      "25    0.371238   0.230849   0.828441    0.341040     ...       0.691375   \n",
      "26    0.391305   0.239740   0.772773    0.353127     ...       0.665768   \n",
      "27    0.297659   0.253812   0.792004    0.395691     ...       0.749326   \n",
      "28    0.304348   0.262443   0.741397    0.440357     ...       0.754717   \n",
      "29    0.277592   0.275159   0.778846    0.523384     ...       0.822102   \n",
      "..         ...        ...        ...         ...     ...            ...   \n",
      "140   0.167224   0.943360   0.614879    0.272202     ...       0.005391   \n",
      "141   0.133779   0.954584   0.578947    0.271676     ...       0.118598   \n",
      "142   0.100335   0.963840   0.501012    0.272727     ...       0.084906   \n",
      "143   0.120402   0.959062   0.477227    0.272202     ...       0.133423   \n",
      "144   0.173913   0.964021   0.343117    0.255912     ...       0.211590   \n",
      "145   0.200669   0.971981   0.269231    0.219128     ...       0.258760   \n",
      "146   0.244147   0.975167   0.253036    0.133473     ...       0.176550   \n",
      "147   0.324415   0.978690   0.273785    0.101419     ...       0.194070   \n",
      "148   0.431439   0.984687   0.159413    0.091435     ...       0.202156   \n",
      "149   0.508361   0.986956   0.027834    0.004729     ...       0.278976   \n",
      "150   0.678930   0.980988   0.000000    0.005780     ...       0.475741   \n",
      "151   0.839465   0.986039   0.040486    0.007357     ...       0.505391   \n",
      "152   0.909699   0.979853   0.040486    0.004204     ...       0.485175   \n",
      "153   1.000000   0.971226   0.038462    0.002627     ...       0.454178   \n",
      "154   0.973245   0.972889   0.066296    0.004729     ...       0.435310   \n",
      "155   0.956522   0.978432   0.015688    0.005780     ...       0.419137   \n",
      "156   0.896321   0.975759   0.045040    0.006306     ...       0.405660   \n",
      "157   0.933111   0.974176   0.017206    0.005780     ...       0.467655   \n",
      "158   0.876254   0.966966   0.048077    0.003678     ...       0.424528   \n",
      "159   0.829431   0.969351   0.052126    0.001051     ...       0.421833   \n",
      "160   0.829431   0.973106   0.073381    0.000525     ...       0.471698   \n",
      "161   0.775920   0.977297   0.095648    0.000000     ...       0.439353   \n",
      "162   0.722409   0.985247   0.096154    0.003153     ...       0.428571   \n",
      "163   0.725753   0.988456   0.127530    0.004729     ...       0.467655   \n",
      "164   0.712375   0.990202   0.173077    0.003678     ...       0.482480   \n",
      "165   0.709030   0.997838   0.238360    0.004729     ...       0.498652   \n",
      "166   0.735786   0.995213   0.250000    0.003678     ...       0.493261   \n",
      "167   0.715719   0.998287   0.175607    0.001051     ...       0.521563   \n",
      "168   0.628762   1.000000   0.179656    0.000525     ...       0.526954   \n",
      "169   0.511706   0.991671   0.255567    0.001051     ...       0.579515   \n",
      "\n",
      "     var3(t+2)  var4(t+2)  var5(t+2)  var6(t+2)  var7(t+2)  var8(t+2)  \\\n",
      "0     0.000000   0.000000   0.011813   0.005986   0.364549   0.012577   \n",
      "1     0.000000   0.000000   0.012940   0.007292   0.364549   0.022815   \n",
      "2     0.000000   0.009757   0.016043   0.015337   0.371238   0.035178   \n",
      "3     0.000000   0.009757   0.016473   0.025907   0.294314   0.043531   \n",
      "4     0.000000   0.009757   0.016369   0.030211   0.297659   0.051047   \n",
      "5     0.000000   0.009757   0.017281   0.038038   0.254181   0.055557   \n",
      "6     0.000000   0.019255   0.013679   0.049833   0.143813   0.063295   \n",
      "7     0.000000   0.019255   0.010031   0.055399   0.163880   0.076473   \n",
      "8     0.000000   0.019255   0.012293   0.052701   0.147157   0.082993   \n",
      "9     0.000000   0.019255   0.008085   0.057306   0.123746   0.095893   \n",
      "10    0.000000   0.016098   0.008102   0.053166   0.177257   0.107006   \n",
      "11    0.070796   0.016098   0.004492   0.054465   0.214047   0.109850   \n",
      "12    0.070796   0.016098   0.000000   0.049667   0.307692   0.119148   \n",
      "13    0.070796   0.016098   0.000919   0.047704   0.431439   0.125190   \n",
      "14    0.088496   0.010233   0.004425   0.041799   0.658863   0.129844   \n",
      "15    0.088496   0.010233   0.006940   0.045519   0.752509   0.138128   \n",
      "16    0.088496   0.010233   0.004131   0.053561   0.729097   0.145199   \n",
      "17    0.088496   0.010233   0.004859   0.060230   0.675585   0.147704   \n",
      "18    0.123894   0.088327   0.007737   0.071551   0.585284   0.157988   \n",
      "19    0.123894   0.088327   0.007671   0.075425   0.551840   0.168782   \n",
      "20    0.123894   0.088327   0.007879   0.078051   0.548495   0.179891   \n",
      "21    0.123894   0.088327   0.009344   0.081948   0.581940   0.186508   \n",
      "22    0.123894   0.060625   0.008514   0.088034   0.528428   0.194852   \n",
      "23    0.123894   0.060625   0.009754   0.098419   0.474917   0.208651   \n",
      "24    0.123894   0.060625   0.010002   0.107964   0.444816   0.216263   \n",
      "25    0.123894   0.060625   0.010932   0.108021   0.371238   0.230849   \n",
      "26    0.185841   0.150628   0.011186   0.109932   0.391305   0.239740   \n",
      "27    0.185841   0.150628   0.014308   0.131357   0.297659   0.253812   \n",
      "28    0.185841   0.150628   0.017095   0.136955   0.304348   0.262443   \n",
      "29    0.185841   0.150628   0.013794   0.144708   0.277592   0.275159   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "140   0.628319   0.615095   0.487643   0.891301   0.167224   0.943360   \n",
      "141   0.628319   0.615095   0.522368   0.901730   0.133779   0.954584   \n",
      "142   0.628319   0.468326   0.523774   0.902560   0.100335   0.963840   \n",
      "143   0.628319   0.468326   0.563974   0.912838   0.120402   0.959062   \n",
      "144   0.752212   0.468326   0.585729   0.921944   0.173913   0.964021   \n",
      "145   0.752212   0.468326   0.574832   0.926809   0.200669   0.971981   \n",
      "146   0.752212   0.505899   0.492219   0.917471   0.244147   0.975167   \n",
      "147   0.752212   0.505899   0.495291   0.924215   0.324415   0.978690   \n",
      "148   0.876106   0.505899   0.448658   0.917672   0.431439   0.984687   \n",
      "149   0.876106   0.505899   0.336796   0.888961   0.508361   0.986956   \n",
      "150   0.876106   0.522170   0.326072   0.870532   0.678930   0.980988   \n",
      "151   0.876106   0.522170   0.393913   0.868757   0.839465   0.986039   \n",
      "152   1.000000   0.522170   0.457533   0.873038   0.909699   0.979853   \n",
      "153   1.000000   0.522170   0.490016   0.885760   1.000000   0.971226   \n",
      "154   1.000000   0.461602   0.518532   0.891503   0.973245   0.972889   \n",
      "155   1.000000   0.461602   0.454615   0.904376   0.956522   0.978432   \n",
      "156   1.000000   0.461602   0.512036   0.913457   0.896321   0.975759   \n",
      "157   1.000000   0.461602   0.574963   0.921993   0.933111   0.974176   \n",
      "158   1.000000   0.474936   0.603344   0.916728   0.876254   0.966966   \n",
      "159   1.000000   0.474936   0.601672   0.926605   0.829431   0.969351   \n",
      "160   1.000000   0.474936   0.522392   0.929488   0.829431   0.973106   \n",
      "161   1.000000   0.474936   0.564399   0.944918   0.775920   0.977297   \n",
      "162   1.000000   0.454052   0.672082   0.954114   0.722409   0.985247   \n",
      "163   1.000000   0.454052   0.637434   0.960627   0.725753   0.988456   \n",
      "164   1.000000   0.454052   0.677541   0.962305   0.712375   0.990202   \n",
      "165   1.000000   0.454052   0.656129   0.962620   0.709030   0.997838   \n",
      "166   1.000000   0.425841   0.711033   0.972440   0.735786   0.995213   \n",
      "167   1.000000   0.425841   0.741081   0.975148   0.715719   0.998287   \n",
      "168   1.000000   0.425841   0.822599   0.986077   0.628762   1.000000   \n",
      "169   1.000000   0.425841   0.912281   1.000000   0.511706   0.991671   \n",
      "\n",
      "     var9(t+2)  var10(t+2)  var11(t+2)  \n",
      "0     0.777328    0.287966    0.315271  \n",
      "1     0.905870    0.213873    0.300492  \n",
      "2     0.925607    0.197583    0.275862  \n",
      "3     0.885121    0.230688    0.266010  \n",
      "4     1.000000    0.252233    0.246305  \n",
      "5     0.941802    0.276406    0.216749  \n",
      "6     0.941296    0.368891    0.152709  \n",
      "7     0.790486    0.442459    0.152709  \n",
      "8     0.692814    0.562796    0.133005  \n",
      "9     0.516700    0.519180    0.128079  \n",
      "10    0.531377    0.487651    0.182266  \n",
      "11    0.510121    0.623226    0.192118  \n",
      "12    0.326417    0.592223    0.256157  \n",
      "13    0.237854    0.444561    0.399015  \n",
      "14    0.246964    0.287441    0.645320  \n",
      "15    0.294534    0.287966    0.733990  \n",
      "16    0.384109    0.324225    0.674876  \n",
      "17    0.412955    0.269574    0.650246  \n",
      "18    0.463563    0.250657    0.566502  \n",
      "19    0.501012    0.284288    0.541872  \n",
      "20    0.614879    0.272202    0.566502  \n",
      "21    0.657389    0.240673    0.571428  \n",
      "22    0.788462    0.242775    0.532019  \n",
      "23    0.702429    0.279559    0.477832  \n",
      "24    0.730769    0.318970    0.443350  \n",
      "25    0.828441    0.341040    0.408867  \n",
      "26    0.772773    0.353127    0.359606  \n",
      "27    0.792004    0.395691    0.310345  \n",
      "28    0.741397    0.440357    0.315271  \n",
      "29    0.778846    0.523384    0.295566  \n",
      "..         ...         ...         ...  \n",
      "140   0.614879    0.272202    0.108374  \n",
      "141   0.578947    0.271676    0.078818  \n",
      "142   0.501012    0.272727    0.088670  \n",
      "143   0.477227    0.272202    0.088670  \n",
      "144   0.343117    0.255912    0.113300  \n",
      "145   0.269231    0.219128    0.133005  \n",
      "146   0.253036    0.133473    0.162561  \n",
      "147   0.273785    0.101419    0.211823  \n",
      "148   0.159413    0.091435    0.310345  \n",
      "149   0.027834    0.004729    0.438423  \n",
      "150   0.000000    0.005780    0.645320  \n",
      "151   0.040486    0.007357    0.798029  \n",
      "152   0.040486    0.004204    0.847290  \n",
      "153   0.038462    0.002627    0.891625  \n",
      "154   0.066296    0.004729    0.876847  \n",
      "155   0.015688    0.005780    0.847290  \n",
      "156   0.045040    0.006306    0.822660  \n",
      "157   0.017206    0.005780    0.827586  \n",
      "158   0.048077    0.003678    0.758620  \n",
      "159   0.052126    0.001051    0.763546  \n",
      "160   0.073381    0.000525    0.753694  \n",
      "161   0.095648    0.000000    0.699507  \n",
      "162   0.096154    0.003153    0.645320  \n",
      "163   0.127530    0.004729    0.635468  \n",
      "164   0.173077    0.003678    0.610837  \n",
      "165   0.238360    0.004729    0.576354  \n",
      "166   0.250000    0.003678    0.566502  \n",
      "167   0.175607    0.001051    0.536945  \n",
      "168   0.179656    0.000525    0.497537  \n",
      "169   0.255567    0.001051    0.448276  \n",
      "\n",
      "[170 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.  \n",
    "        Arguments:\n",
    "            data: Sequence of observations as a list or np.array\n",
    "            n_in: Number of lag observations as input(X)\n",
    "            n_out: Number of observations as output(y)\n",
    "            dropnan: Boolean to drop rows with NaN values\n",
    "        Returns:\n",
    "            Pandas Dataframe of series framed for supervised learning\n",
    "         \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    #input sequence for (t-n,.... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(-i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i) ) for j in range(n_vars)]\n",
    "       \n",
    "    #forecast sequence for (t, t+1, .... t+n)\n",
    "    for i in range (0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0: \n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names +=[('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    #add it all up\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    #drop NaN rows\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "datad[datad.columns] = scaler.fit_transform(datad[datad.columns])\n",
    "values = datad.values\n",
    "\n",
    "\n",
    "#scaled = scaler.fit_transform(values)\n",
    "reframed = series_to_supervised(values,2,3)\n",
    "print(reframed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 170 entries, 0 to 169\n",
      "Data columns (total 34 columns):\n",
      "var1(t-2)     170 non-null float64\n",
      "var2(t-2)     170 non-null float64\n",
      "var3(t-2)     170 non-null float64\n",
      "var4(t-2)     170 non-null float64\n",
      "var5(t-2)     170 non-null float64\n",
      "var6(t-2)     170 non-null float64\n",
      "var7(t-2)     170 non-null float64\n",
      "var8(t-2)     170 non-null float64\n",
      "var9(t-2)     170 non-null float64\n",
      "var10(t-2)    170 non-null float64\n",
      "var11(t-2)    170 non-null float64\n",
      "var1(t-1)     170 non-null float64\n",
      "var2(t-1)     170 non-null float64\n",
      "var3(t-1)     170 non-null float64\n",
      "var4(t-1)     170 non-null float64\n",
      "var5(t-1)     170 non-null float64\n",
      "var6(t-1)     170 non-null float64\n",
      "var7(t-1)     170 non-null float64\n",
      "var8(t-1)     170 non-null float64\n",
      "var9(t-1)     170 non-null float64\n",
      "var10(t-1)    170 non-null float64\n",
      "var11(t-1)    170 non-null float64\n",
      "var1(t)       170 non-null float64\n",
      "var2(t)       170 non-null float64\n",
      "var3(t)       170 non-null float64\n",
      "var4(t)       170 non-null float64\n",
      "var5(t)       170 non-null float64\n",
      "var6(t)       170 non-null float64\n",
      "var7(t)       170 non-null float64\n",
      "var8(t)       170 non-null float64\n",
      "var9(t)       170 non-null float64\n",
      "var10(t)      170 non-null float64\n",
      "var11(t)      170 non-null float64\n",
      "var11(t+2)    170 non-null float64\n",
      "dtypes: float64(34)\n",
      "memory usage: 46.5 KB\n"
     ]
    }
   ],
   "source": [
    "#drops unneeded variables from yt to yt+h.  number should be lags * n + n \n",
    "todrop1 = reframed.iloc[:,33:-1]\n",
    "reframed = reframed.drop(todrop1, axis=1)\n",
    "\n",
    "reframed.info()\n",
    "#print(reframed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 1, 33) (136,) (34, 1, 33) (34,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "values = reframed.values\n",
    "n_train = int(len(values) * 0.8)\n",
    "train= values[:n_train,:]\n",
    "test = values[n_train:,:]\n",
    "train_x, train_y = train[:, :-1], train[:, -1]\n",
    "test_x, test_y = test[:, :-1], test[:, -1]\n",
    "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "test_x = test_x.reshape(test_x.shape[0], 1, test_x.shape[1])\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136 samples, validate on 34 samples\n",
      "Epoch 1/1000\n",
      "136/136 [==============================] - 10s 70ms/step - loss: 0.1153 - val_loss: 0.1470\n",
      "Epoch 2/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.1426\n",
      "Epoch 3/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0525\n",
      "Epoch 4/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0811\n",
      "Epoch 5/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.1105\n",
      "Epoch 6/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0726\n",
      "Epoch 7/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.0488\n",
      "Epoch 8/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0511\n",
      "Epoch 9/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0248\n",
      "Epoch 10/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0090\n",
      "Epoch 11/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0080\n",
      "Epoch 12/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 13/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 14/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 15/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 16/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 17/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 18/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0031\n",
      "Epoch 20/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 21/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 22/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 23/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 24/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 25/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 26/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 27/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 28/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 29/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 30/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 31/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 32/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.9713e-04 - val_loss: 0.0024\n",
      "Epoch 33/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.7338e-04 - val_loss: 0.00175  \n",
      "Epoch 34/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 35/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.9039e-04 - val_loss: 0.0019\n",
      "Epoch 36/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.7012e-04 - val_loss: 0.0020\n",
      "Epoch 37/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.5706e-04 - val_loss: 0.0019\n",
      "Epoch 38/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.2415e-04 - val_loss: 0.0015\n",
      "Epoch 39/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.4536e-04 - val_loss: 0.0016\n",
      "Epoch 40/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.7520e-04 - val_loss: 0.0019\n",
      "Epoch 41/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.3764e-04 - val_loss: 0.0016\n",
      "Epoch 42/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.0526e-04 - val_loss: 0.0019\n",
      "Epoch 43/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.5545e-04 - val_loss: 0.0018\n",
      "Epoch 44/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.5119e-04 - val_loss: 0.0017\n",
      "Epoch 45/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.8599e-04 - val_loss: 0.0015\n",
      "Epoch 46/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.9014e-04 - val_loss: 0.0019\n",
      "Epoch 47/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.1470e-04 - val_loss: 0.0015\n",
      "Epoch 48/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.5308e-04 - val_loss: 0.0020\n",
      "Epoch 49/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.9710e-04 - val_loss: 0.0014\n",
      "Epoch 50/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.9429e-04 - val_loss: 0.0024\n",
      "Epoch 51/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.1005e-04 - val_loss: 0.0014\n",
      "Epoch 52/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.3529e-04 - val_loss: 0.0019\n",
      "Epoch 53/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.0525e-04 - val_loss: 0.0015\n",
      "Epoch 54/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.8885e-04 - val_loss: 0.0026\n",
      "Epoch 55/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4699e-04 - val_loss: 0.0013\n",
      "Epoch 56/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.9531e-04 - val_loss: 0.0031\n",
      "Epoch 57/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.5752e-04 - val_loss: 0.0015\n",
      "Epoch 58/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.7835e-04 - val_loss: 0.0028\n",
      "Epoch 59/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.4836e-04 - val_loss: 0.0015\n",
      "Epoch 60/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.5769e-04 - val_loss: 0.0021\n",
      "Epoch 61/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.9392e-04 - val_loss: 0.0022\n",
      "Epoch 62/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.6659e-04 - val_loss: 0.0023\n",
      "Epoch 63/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.9108e-04 - val_loss: 0.0011\n",
      "Epoch 64/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.0398e-04 - val_loss: 0.0027\n",
      "Epoch 65/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.5531e-04 - val_loss: 0.0017\n",
      "Epoch 66/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.1080e-04 - val_loss: 0.0021\n",
      "Epoch 67/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2247e-04 - val_loss: 0.0017\n",
      "Epoch 68/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.3408e-04 - val_loss: 0.0019\n",
      "Epoch 69/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.4957e-04 - val_loss: 0.0018\n",
      "Epoch 70/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.7885e-04 - val_loss: 0.0015\n",
      "Epoch 71/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.9706e-04 - val_loss: 0.0017\n",
      "Epoch 72/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.8861e-04 - val_loss: 0.0010\n",
      "Epoch 73/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4790e-04 - val_loss: 9.6655e-04\n",
      "Epoch 74/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.9795e-04 - val_loss: 0.0020\n",
      "Epoch 75/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.0629e-04 - val_loss: 0.0012\n",
      "Epoch 76/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.9594e-04 - val_loss: 0.0023\n",
      "Epoch 77/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.4723e-04 - val_loss: 0.0018\n",
      "Epoch 78/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.8395e-04 - val_loss: 0.0015\n",
      "Epoch 79/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.9255e-04 - val_loss: 0.0013\n",
      "Epoch 80/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.8313e-04 - val_loss: 0.0024\n",
      "Epoch 81/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2370e-04 - val_loss: 0.0018\n",
      "Epoch 82/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.9696e-04 - val_loss: 0.0017\n",
      "Epoch 83/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.3837e-04 - val_loss: 0.0022\n",
      "Epoch 84/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.0979e-04 - val_loss: 0.0023\n",
      "Epoch 85/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.2689e-04 - val_loss: 0.0011\n",
      "Epoch 86/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.6955e-04 - val_loss: 0.0020\n",
      "Epoch 87/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.0994e-04 - val_loss: 0.0019\n",
      "Epoch 88/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.0238e-04 - val_loss: 0.0022\n",
      "Epoch 89/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.9953e-04 - val_loss: 7.9563e-04\n",
      "Epoch 90/1000\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 8.0134e-04 - val_loss: 0.0025\n",
      "Epoch 91/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4850e-04 - val_loss: 0.0015\n",
      "Epoch 92/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4538e-04 - val_loss: 0.0017\n",
      "Epoch 93/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.3014e-04 - val_loss: 0.0015\n",
      "Epoch 94/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.4829e-04 - val_loss: 0.0015\n",
      "Epoch 95/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.1384e-04 - val_loss: 0.0018\n",
      "Epoch 96/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.1954e-04 - val_loss: 9.9881e-04\n",
      "Epoch 97/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.6126e-04 - val_loss: 0.0013\n",
      "Epoch 98/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2422e-04 - val_loss: 0.0013\n",
      "Epoch 99/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.9189e-04 - val_loss: 0.0012\n",
      "Epoch 100/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6034e-04 - val_loss: 0.0011\n",
      "Epoch 101/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.4867e-04 - val_loss: 0.0025\n",
      "Epoch 102/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.2605e-04 - val_loss: 9.4415e-04\n",
      "Epoch 103/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2246e-04 - val_loss: 0.0018\n",
      "Epoch 104/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.3494e-04 - val_loss: 0.0013\n",
      "Epoch 105/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4140e-04 - val_loss: 0.0012\n",
      "Epoch 106/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6517e-04 - val_loss: 0.0012\n",
      "Epoch 107/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.8667e-04 - val_loss: 8.5147e-04\n",
      "Epoch 108/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.0274e-04 - val_loss: 0.0017\n",
      "Epoch 109/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.8903e-04 - val_loss: 0.0015\n",
      "Epoch 110/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5138e-04 - val_loss: 9.4795e-04\n",
      "Epoch 111/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.9740e-04 - val_loss: 0.0029\n",
      "Epoch 112/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.8477e-04 - val_loss: 0.0013\n",
      "Epoch 113/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7076e-04 - val_loss: 0.0024\n",
      "Epoch 114/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8043e-04 - val_loss: 0.0012\n",
      "Epoch 115/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2231e-04 - val_loss: 0.0023\n",
      "Epoch 116/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.9210e-04 - val_loss: 0.0012\n",
      "Epoch 117/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4040e-04 - val_loss: 0.0014\n",
      "Epoch 118/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7014e-04 - val_loss: 0.0015\n",
      "Epoch 119/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.3606e-04 - val_loss: 0.0011\n",
      "Epoch 120/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.1607e-04 - val_loss: 0.0012\n",
      "Epoch 121/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4425e-04 - val_loss: 9.5834e-04\n",
      "Epoch 122/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4381e-04 - val_loss: 0.0013\n",
      "Epoch 123/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.3587e-04 - val_loss: 0.0014\n",
      "Epoch 124/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0438e-04 - val_loss: 0.0021\n",
      "Epoch 125/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.9632e-04 - val_loss: 0.0012\n",
      "Epoch 126/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4629e-04 - val_loss: 0.0017\n",
      "Epoch 127/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.2609e-04 - val_loss: 0.0014\n",
      "Epoch 128/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8205e-04 - val_loss: 0.0016\n",
      "Epoch 129/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.2973e-04 - val_loss: 0.0011\n",
      "Epoch 130/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6627e-04 - val_loss: 0.0019\n",
      "Epoch 131/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.3702e-04 - val_loss: 7.0047e-04\n",
      "Epoch 132/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.7189e-04 - val_loss: 0.0017\n",
      "Epoch 133/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4381e-04 - val_loss: 0.0017\n",
      "Epoch 134/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.9565e-04 - val_loss: 0.0012\n",
      "Epoch 135/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6668e-04 - val_loss: 0.0016\n",
      "Epoch 136/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3172e-04 - val_loss: 0.0018\n",
      "Epoch 137/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2149e-04 - val_loss: 9.2268e-04\n",
      "Epoch 138/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6156e-04 - val_loss: 0.0014\n",
      "Epoch 139/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.2006e-04 - val_loss: 0.0011\n",
      "Epoch 140/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5604e-04 - val_loss: 0.0014\n",
      "Epoch 141/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.5886e-04 - val_loss: 6.0594e-04\n",
      "Epoch 142/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.1896e-04 - val_loss: 0.0019\n",
      "Epoch 143/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9630e-04 - val_loss: 9.3906e-04\n",
      "Epoch 144/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1576e-04 - val_loss: 0.0021\n",
      "Epoch 145/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0651e-04 - val_loss: 7.3762e-04\n",
      "Epoch 146/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.2136e-04 - val_loss: 0.0011\n",
      "Epoch 147/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0446e-04 - val_loss: 0.0011\n",
      "Epoch 148/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.7144e-04 - val_loss: 0.0014\n",
      "Epoch 149/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6041e-04 - val_loss: 0.0011\n",
      "Epoch 150/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8240e-04 - val_loss: 9.2772e-04\n",
      "Epoch 151/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2038e-04 - val_loss: 9.4699e-04\n",
      "Epoch 152/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5141e-04 - val_loss: 7.0250e-04\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0439e-04 - val_loss: 0.0011\n",
      "Epoch 154/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9964e-04 - val_loss: 0.0015\n",
      "Epoch 155/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7118e-04 - val_loss: 8.1212e-04\n",
      "Epoch 156/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6544e-04 - val_loss: 0.0016\n",
      "Epoch 157/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6534e-04 - val_loss: 8.7993e-04\n",
      "Epoch 158/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.2561e-04 - val_loss: 0.0012\n",
      "Epoch 159/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8270e-04 - val_loss: 0.0012\n",
      "Epoch 160/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7136e-04 - val_loss: 0.0012\n",
      "Epoch 161/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.9239e-04 - val_loss: 0.0010\n",
      "Epoch 162/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8404e-04 - val_loss: 0.0011\n",
      "Epoch 163/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7122e-04 - val_loss: 8.3240e-04\n",
      "Epoch 164/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3971e-04 - val_loss: 0.0014\n",
      "Epoch 165/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7781e-04 - val_loss: 9.6639e-04\n",
      "Epoch 166/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6638e-04 - val_loss: 8.7320e-04\n",
      "Epoch 167/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4203e-04 - val_loss: 0.0015\n",
      "Epoch 168/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.9857e-04 - val_loss: 6.5030e-04\n",
      "Epoch 169/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.9647e-04 - val_loss: 9.4008e-04\n",
      "Epoch 170/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4106e-04 - val_loss: 0.0013\n",
      "Epoch 171/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1167e-04 - val_loss: 9.4752e-04\n",
      "Epoch 172/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4654e-04 - val_loss: 9.5009e-04\n",
      "Epoch 173/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6471e-04 - val_loss: 0.0014\n",
      "Epoch 174/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9803e-04 - val_loss: 0.0011\n",
      "Epoch 175/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6172e-04 - val_loss: 0.0012\n",
      "Epoch 176/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4150e-04 - val_loss: 6.6529e-04\n",
      "Epoch 177/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7622e-04 - val_loss: 0.0010\n",
      "Epoch 178/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3196e-04 - val_loss: 7.0976e-04\n",
      "Epoch 179/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3616e-04 - val_loss: 0.0019\n",
      "Epoch 180/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6117e-04 - val_loss: 7.9986e-04\n",
      "Epoch 181/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.7928e-04 - val_loss: 0.0012\n",
      "Epoch 182/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6182e-04 - val_loss: 7.9315e-04\n",
      "Epoch 183/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2898e-04 - val_loss: 7.8346e-04\n",
      "Epoch 184/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7653e-04 - val_loss: 6.2059e-04\n",
      "Epoch 185/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8124e-04 - val_loss: 8.7743e-04\n",
      "Epoch 186/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7075e-04 - val_loss: 6.4130e-04\n",
      "Epoch 187/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5807e-04 - val_loss: 5.9567e-04\n",
      "Epoch 188/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5356e-04 - val_loss: 0.0013\n",
      "Epoch 189/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5778e-04 - val_loss: 4.6294e-04\n",
      "Epoch 190/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0716e-04 - val_loss: 0.0015\n",
      "Epoch 191/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3398e-04 - val_loss: 5.8329e-04\n",
      "Epoch 192/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3708e-04 - val_loss: 0.0014\n",
      "Epoch 193/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4648e-04 - val_loss: 5.1455e-04\n",
      "Epoch 194/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2566e-04 - val_loss: 8.1618e-04\n",
      "Epoch 195/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.3427e-04 - val_loss: 9.7545e-04\n",
      "Epoch 196/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5177e-04 - val_loss: 6.9627e-04\n",
      "Epoch 197/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.9556e-04 - val_loss: 6.0521e-04\n",
      "Epoch 198/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8781e-04 - val_loss: 0.0013\n",
      "Epoch 199/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0534e-04 - val_loss: 4.5633e-04\n",
      "Epoch 200/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9134e-04 - val_loss: 9.6156e-04\n",
      "Epoch 201/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6543e-04 - val_loss: 5.3622e-04\n",
      "Epoch 202/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5919e-04 - val_loss: 0.0015\n",
      "Epoch 203/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8238e-04 - val_loss: 5.3584e-04\n",
      "Epoch 204/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4048e-04 - val_loss: 0.0018\n",
      "Epoch 205/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.1196e-04 - val_loss: 4.5969e-04\n",
      "Epoch 206/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7595e-04 - val_loss: 0.0012\n",
      "Epoch 207/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7165e-04 - val_loss: 5.4658e-04\n",
      "Epoch 208/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4136e-04 - val_loss: 0.0013\n",
      "Epoch 209/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4139e-04 - val_loss: 4.1726e-04\n",
      "Epoch 210/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4968e-04 - val_loss: 0.0014\n",
      "Epoch 211/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6625e-04 - val_loss: 4.2938e-04\n",
      "Epoch 212/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4861e-04 - val_loss: 0.0017\n",
      "Epoch 213/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0488e-04 - val_loss: 5.4143e-04\n",
      "Epoch 214/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.8529e-04 - val_loss: 0.0028\n",
      "Epoch 215/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.0117e-04 - val_loss: 6.5851e-04\n",
      "Epoch 216/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.6162e-04 - val_loss: 0.0029\n",
      "Epoch 217/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.1747e-04 - val_loss: 4.0629e-04\n",
      "Epoch 218/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.7163e-04 - val_loss: 0.0016\n",
      "Epoch 219/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5708e-04 - val_loss: 4.4510e-04\n",
      "Epoch 220/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.3451e-04 - val_loss: 9.5611e-04\n",
      "Epoch 221/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3792e-04 - val_loss: 6.7676e-04\n",
      "Epoch 222/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3336e-04 - val_loss: 6.8479e-04\n",
      "Epoch 223/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2747e-04 - val_loss: 7.2224e-04\n",
      "Epoch 224/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4284e-04 - val_loss: 5.2476e-04\n",
      "Epoch 225/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0237e-04 - val_loss: 9.8946e-04\n",
      "Epoch 226/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1861e-04 - val_loss: 3.4108e-04\n",
      "Epoch 227/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1906e-04 - val_loss: 0.0013\n",
      "Epoch 228/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2209e-04 - val_loss: 3.6515e-04\n",
      "Epoch 229/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9776e-04 - val_loss: 0.0012\n",
      "Epoch 230/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3868e-04 - val_loss: 3.7086e-04\n",
      "Epoch 231/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6443e-04 - val_loss: 0.0020\n",
      "Epoch 232/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6571e-04 - val_loss: 4.6427e-04\n",
      "Epoch 233/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5362e-04 - val_loss: 0.0022\n",
      "Epoch 234/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6529e-04 - val_loss: 4.6562e-04\n",
      "Epoch 235/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.1724e-04 - val_loss: 0.0020\n",
      "Epoch 236/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.3497e-04 - val_loss: 6.0583e-04\n",
      "Epoch 237/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 5.6722e-04 - val_loss: 0.0027\n",
      "Epoch 238/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.1819e-04 - val_loss: 3.6957e-04\n",
      "Epoch 239/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 5.3686e-04 - val_loss: 0.0018\n",
      "Epoch 240/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 5.6083e-04 - val_loss: 3.5007e-04\n",
      "Epoch 241/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 5.5632e-04 - val_loss: 0.0014\n",
      "Epoch 242/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2690e-04 - val_loss: 3.4703e-04\n",
      "Epoch 243/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.1565e-04 - val_loss: 0.0013\n",
      "Epoch 244/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 4.0299e-04 - val_loss: 3.6518e-04\n",
      "Epoch 245/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0829e-04 - val_loss: 8.8888e-04\n",
      "Epoch 246/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.7726e-04 - val_loss: 3.8922e-04\n",
      "Epoch 247/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.4292e-04 - val_loss: 5.7879e-04\n",
      "Epoch 248/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5003e-04 - val_loss: 3.3069e-04\n",
      "Epoch 249/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2787e-04 - val_loss: 5.5299e-04\n",
      "Epoch 250/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2019e-04 - val_loss: 3.4379e-04\n",
      "Epoch 251/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0182e-04 - val_loss: 5.1340e-04\n",
      "Epoch 252/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6532e-04 - val_loss: 6.2783e-04\n",
      "Epoch 253/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1429e-04 - val_loss: 4.0597e-04\n",
      "Epoch 254/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3891e-04 - val_loss: 7.5808e-04\n",
      "Epoch 255/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1362e-04 - val_loss: 3.1548e-04\n",
      "Epoch 256/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8741e-04 - val_loss: 0.0012\n",
      "Epoch 257/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7085e-04 - val_loss: 5.1050e-04\n",
      "Epoch 258/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.1154e-04 - val_loss: 0.0017\n",
      "Epoch 259/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.3885e-04 - val_loss: 9.5139e-04\n",
      "Epoch 260/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.3388e-04 - val_loss: 0.0029\n",
      "Epoch 261/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4326e-04 - val_loss: 0.0010\n",
      "Epoch 262/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.5837e-04 - val_loss: 0.0023\n",
      "Epoch 263/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.0350e-04 - val_loss: 5.8866e-04\n",
      "Epoch 264/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.1024e-04 - val_loss: 0.0016\n",
      "Epoch 265/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 6.7864e-04 - val_loss: 4.0531e-04\n",
      "Epoch 266/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6891e-04 - val_loss: 8.7340e-04\n",
      "Epoch 267/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.3639e-04 - val_loss: 3.4102e-04\n",
      "Epoch 268/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2447e-04 - val_loss: 5.0257e-04\n",
      "Epoch 269/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0373e-04 - val_loss: 4.7095e-04\n",
      "Epoch 270/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0499e-04 - val_loss: 3.4446e-04\n",
      "Epoch 271/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2644e-04 - val_loss: 4.3003e-04\n",
      "Epoch 272/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3648e-04 - val_loss: 3.2968e-04\n",
      "Epoch 273/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2507e-04 - val_loss: 4.9557e-04\n",
      "Epoch 274/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2893e-04 - val_loss: 3.0609e-04\n",
      "Epoch 275/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6611e-04 - val_loss: 7.5855e-04\n",
      "Epoch 276/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1577e-04 - val_loss: 3.0676e-04\n",
      "Epoch 277/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2969e-04 - val_loss: 6.4930e-04\n",
      "Epoch 278/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1191e-04 - val_loss: 3.5431e-04\n",
      "Epoch 279/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2072e-04 - val_loss: 8.2347e-04\n",
      "Epoch 280/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9490e-04 - val_loss: 3.8253e-04\n",
      "Epoch 281/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8791e-04 - val_loss: 0.0011\n",
      "Epoch 282/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5596e-04 - val_loss: 4.8919e-04\n",
      "Epoch 283/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0013e-04 - val_loss: 8.8408e-04\n",
      "Epoch 284/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3348e-04 - val_loss: 3.2648e-04\n",
      "Epoch 285/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2631e-04 - val_loss: 0.0012\n",
      "Epoch 286/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4527e-04 - val_loss: 3.1688e-04\n",
      "Epoch 287/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5621e-04 - val_loss: 9.1179e-04\n",
      "Epoch 288/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0542e-04 - val_loss: 3.1349e-04\n",
      "Epoch 289/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1403e-04 - val_loss: 8.2735e-04\n",
      "Epoch 290/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1347e-04 - val_loss: 3.3604e-04\n",
      "Epoch 291/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1391e-04 - val_loss: 0.0011\n",
      "Epoch 292/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4829e-04 - val_loss: 3.1185e-04\n",
      "Epoch 293/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8990e-04 - val_loss: 7.9028e-04\n",
      "Epoch 294/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0046e-04 - val_loss: 3.0608e-04\n",
      "Epoch 295/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5865e-04 - val_loss: 4.0416e-04\n",
      "Epoch 296/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3978e-04 - val_loss: 3.1876e-04\n",
      "Epoch 297/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9712e-04 - val_loss: 3.1588e-04\n",
      "Epoch 298/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5532e-04 - val_loss: 3.2918e-04\n",
      "Epoch 299/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8536e-04 - val_loss: 3.3862e-04\n",
      "Epoch 300/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9256e-04 - val_loss: 4.1916e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.4799e-04 - val_loss: 3.2910e-04\n",
      "Epoch 302/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6077e-04 - val_loss: 3.7828e-04\n",
      "Epoch 303/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.8448e-04 - val_loss: 3.7649e-04\n",
      "Epoch 304/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5981e-04 - val_loss: 4.7660e-04\n",
      "Epoch 305/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3439e-04 - val_loss: 3.1677e-04\n",
      "Epoch 306/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8565e-04 - val_loss: 4.4722e-04\n",
      "Epoch 307/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3234e-04 - val_loss: 3.3373e-04\n",
      "Epoch 308/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0210e-04 - val_loss: 5.3258e-04\n",
      "Epoch 309/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3887e-04 - val_loss: 3.6074e-04\n",
      "Epoch 310/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7620e-04 - val_loss: 5.4229e-04\n",
      "Epoch 311/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6859e-04 - val_loss: 3.2576e-04\n",
      "Epoch 312/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6505e-04 - val_loss: 3.6576e-04\n",
      "Epoch 313/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9810e-04 - val_loss: 3.4157e-04\n",
      "Epoch 314/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8327e-04 - val_loss: 5.3451e-04\n",
      "Epoch 315/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1577e-04 - val_loss: 2.9492e-04\n",
      "Epoch 316/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7844e-04 - val_loss: 4.7533e-04\n",
      "Epoch 317/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1469e-04 - val_loss: 3.0371e-04\n",
      "Epoch 318/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5393e-04 - val_loss: 3.8827e-04\n",
      "Epoch 319/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1688e-04 - val_loss: 3.0920e-04\n",
      "Epoch 320/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0327e-04 - val_loss: 3.8528e-04\n",
      "Epoch 321/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1084e-04 - val_loss: 3.1157e-04\n",
      "Epoch 322/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6108e-04 - val_loss: 3.1631e-04\n",
      "Epoch 323/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5082e-04 - val_loss: 2.9611e-04\n",
      "Epoch 324/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8953e-04 - val_loss: 2.9703e-04\n",
      "Epoch 325/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7656e-04 - val_loss: 3.5973e-04\n",
      "Epoch 326/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9300e-04 - val_loss: 3.3858e-04\n",
      "Epoch 327/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7489e-04 - val_loss: 3.0524e-04\n",
      "Epoch 328/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1379e-04 - val_loss: 4.0375e-04\n",
      "Epoch 329/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9925e-04 - val_loss: 6.5511e-04\n",
      "Epoch 330/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2232e-04 - val_loss: 5.8867e-04\n",
      "Epoch 331/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2908e-04 - val_loss: 3.6269e-04\n",
      "Epoch 332/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1293e-04 - val_loss: 7.8775e-04\n",
      "Epoch 333/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8702e-04 - val_loss: 8.5579e-04\n",
      "Epoch 334/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.7095e-04 - val_loss: 0.0020\n",
      "Epoch 335/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.5162e-04 - val_loss: 0.0017\n",
      "Epoch 336/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.8920e-04 - val_loss: 0.0031\n",
      "Epoch 337/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 338/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.6246e-04 - val_loss: 0.0017\n",
      "Epoch 339/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.8543e-04 - val_loss: 2.7905e-04\n",
      "Epoch 340/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8251e-04 - val_loss: 2.8140e-04\n",
      "Epoch 341/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2522e-04 - val_loss: 4.3541e-04\n",
      "Epoch 342/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5424e-04 - val_loss: 5.9108e-04\n",
      "Epoch 343/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8080e-04 - val_loss: 3.1866e-04\n",
      "Epoch 344/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5600e-04 - val_loss: 4.1445e-04\n",
      "Epoch 345/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0110e-04 - val_loss: 2.9291e-04\n",
      "Epoch 346/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0382e-04 - val_loss: 4.3490e-04\n",
      "Epoch 347/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7484e-04 - val_loss: 4.5677e-04\n",
      "Epoch 348/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2073e-04 - val_loss: 4.3128e-04\n",
      "Epoch 349/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9967e-04 - val_loss: 3.1745e-04\n",
      "Epoch 350/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7627e-04 - val_loss: 3.5327e-04\n",
      "Epoch 351/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8525e-04 - val_loss: 2.8135e-04\n",
      "Epoch 352/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6639e-04 - val_loss: 2.8815e-04\n",
      "Epoch 353/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5790e-04 - val_loss: 2.7929e-04\n",
      "Epoch 354/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6711e-04 - val_loss: 2.9690e-04\n",
      "Epoch 355/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7474e-04 - val_loss: 3.1558e-04\n",
      "Epoch 356/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8607e-04 - val_loss: 2.9587e-04\n",
      "Epoch 357/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6726e-04 - val_loss: 2.7293e-04\n",
      "Epoch 358/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9924e-04 - val_loss: 3.0941e-04\n",
      "Epoch 359/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2633e-04 - val_loss: 3.0493e-04\n",
      "Epoch 360/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6053e-04 - val_loss: 4.0706e-04\n",
      "Epoch 361/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2097e-04 - val_loss: 2.8262e-04\n",
      "Epoch 362/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9359e-04 - val_loss: 3.5909e-04\n",
      "Epoch 363/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8453e-04 - val_loss: 3.7624e-04\n",
      "Epoch 364/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5751e-04 - val_loss: 5.9806e-04\n",
      "Epoch 365/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6779e-04 - val_loss: 4.5142e-04\n",
      "Epoch 366/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2588e-04 - val_loss: 3.4636e-04\n",
      "Epoch 367/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2947e-04 - val_loss: 3.5789e-04\n",
      "Epoch 368/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9845e-04 - val_loss: 2.8619e-04\n",
      "Epoch 369/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6740e-04 - val_loss: 4.9042e-04\n",
      "Epoch 370/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2981e-04 - val_loss: 5.6154e-04\n",
      "Epoch 371/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7915e-04 - val_loss: 7.4167e-04\n",
      "Epoch 372/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1746e-04 - val_loss: 4.3351e-04\n",
      "Epoch 373/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4711e-04 - val_loss: 4.9186e-04\n",
      "Epoch 374/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8674e-04 - val_loss: 3.9742e-04\n",
      "Epoch 375/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5003e-04 - val_loss: 4.3621e-04\n",
      "Epoch 376/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8492e-04 - val_loss: 3.3506e-04\n",
      "Epoch 377/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7582e-04 - val_loss: 2.7271e-04\n",
      "Epoch 378/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7418e-04 - val_loss: 2.7773e-04\n",
      "Epoch 379/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4442e-04 - val_loss: 2.7732e-04\n",
      "Epoch 380/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7154e-04 - val_loss: 4.3735e-04\n",
      "Epoch 381/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2213e-04 - val_loss: 4.1378e-04\n",
      "Epoch 382/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9711e-04 - val_loss: 3.2900e-04\n",
      "Epoch 383/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0805e-04 - val_loss: 4.7285e-04\n",
      "Epoch 384/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4392e-04 - val_loss: 7.2469e-04\n",
      "Epoch 385/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6205e-04 - val_loss: 6.0024e-04\n",
      "Epoch 386/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2200e-04 - val_loss: 8.7445e-04\n",
      "Epoch 387/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2727e-04 - val_loss: 3.8882e-04\n",
      "Epoch 388/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8295e-04 - val_loss: 5.3787e-04\n",
      "Epoch 389/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6473e-04 - val_loss: 3.3215e-04\n",
      "Epoch 390/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5216e-04 - val_loss: 4.5089e-04\n",
      "Epoch 391/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0631e-04 - val_loss: 2.6850e-04\n",
      "Epoch 392/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2920e-04 - val_loss: 3.0052e-04\n",
      "Epoch 393/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7689e-04 - val_loss: 3.1252e-04\n",
      "Epoch 394/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9231e-04 - val_loss: 2.9595e-04\n",
      "Epoch 395/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8379e-04 - val_loss: 2.9804e-04\n",
      "Epoch 396/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6019e-04 - val_loss: 3.4598e-04\n",
      "Epoch 397/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9978e-04 - val_loss: 3.1673e-04\n",
      "Epoch 398/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2968e-04 - val_loss: 3.4746e-04\n",
      "Epoch 399/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4366e-04 - val_loss: 4.1773e-04\n",
      "Epoch 400/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2367e-04 - val_loss: 5.2627e-04\n",
      "Epoch 401/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4347e-04 - val_loss: 5.8609e-04\n",
      "Epoch 402/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3133e-04 - val_loss: 3.4842e-04\n",
      "Epoch 403/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0380e-04 - val_loss: 3.3062e-04\n",
      "Epoch 404/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.0572e-04 - val_loss: 3.9422e-04\n",
      "Epoch 405/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.6102e-04 - val_loss: 4.0614e-04\n",
      "Epoch 406/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0755e-04 - val_loss: 2.8398e-04\n",
      "Epoch 407/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7497e-04 - val_loss: 2.9408e-04\n",
      "Epoch 408/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2992e-04 - val_loss: 2.7524e-04\n",
      "Epoch 409/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.6910e-04 - val_loss: 2.7454e-04\n",
      "Epoch 410/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6952e-04 - val_loss: 2.7587e-04\n",
      "Epoch 411/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8702e-04 - val_loss: 3.0502e-04\n",
      "Epoch 412/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.7771e-04 - val_loss: 2.7632e-04\n",
      "Epoch 413/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4964e-04 - val_loss: 3.2249e-04\n",
      "Epoch 414/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9259e-04 - val_loss: 3.8041e-04\n",
      "Epoch 415/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0622e-04 - val_loss: 4.0181e-04\n",
      "Epoch 416/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.8838e-04 - val_loss: 4.2064e-04\n",
      "Epoch 417/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3163e-04 - val_loss: 6.3684e-04\n",
      "Epoch 418/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.5248e-04 - val_loss: 6.0730e-04\n",
      "Epoch 419/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 3.1853e-04 - val_loss: 7.3619e-04\n",
      "Epoch 420/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.6823e-04 - val_loss: 4.5873e-04\n",
      "Epoch 421/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2579e-04 - val_loss: 0.0014\n",
      "Epoch 422/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.9455e-04 - val_loss: 6.1569e-04\n",
      "Epoch 423/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7194e-04 - val_loss: 0.0013\n",
      "Epoch 424/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6834e-04 - val_loss: 9.2180e-04\n",
      "Epoch 425/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.8623e-04 - val_loss: 0.0020\n",
      "Epoch 426/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 427/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.2392e-04 - val_loss: 0.0017\n",
      "Epoch 428/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.7006e-04 - val_loss: 4.1607e-04\n",
      "Epoch 429/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5800e-04 - val_loss: 4.3724e-04\n",
      "Epoch 430/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3037e-04 - val_loss: 3.4175e-04\n",
      "Epoch 431/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2207e-04 - val_loss: 3.0231e-04\n",
      "Epoch 432/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5205e-04 - val_loss: 3.3212e-04\n",
      "Epoch 433/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3235e-04 - val_loss: 3.3996e-04\n",
      "Epoch 434/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7416e-04 - val_loss: 2.9748e-04\n",
      "Epoch 435/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9547e-04 - val_loss: 2.9902e-04\n",
      "Epoch 436/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1495e-04 - val_loss: 3.5427e-04\n",
      "Epoch 437/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6255e-04 - val_loss: 3.2716e-04\n",
      "Epoch 438/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5232e-04 - val_loss: 3.3391e-04\n",
      "Epoch 439/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5630e-04 - val_loss: 2.8439e-04\n",
      "Epoch 440/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5154e-04 - val_loss: 3.9860e-04\n",
      "Epoch 441/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.5237e-04 - val_loss: 3.9015e-04\n",
      "Epoch 442/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1452e-04 - val_loss: 2.8317e-04\n",
      "Epoch 443/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.3180e-04 - val_loss: 3.6138e-04\n",
      "Epoch 444/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5816e-04 - val_loss: 4.7631e-04\n",
      "Epoch 445/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.9227e-04 - val_loss: 4.5687e-04\n",
      "Epoch 446/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9024e-04 - val_loss: 3.4470e-04\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step - loss: 2.1444e-04 - val_loss: 3.8868e-04\n",
      "Epoch 448/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0023e-04 - val_loss: 4.5436e-04\n",
      "Epoch 449/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.5718e-04 - val_loss: 4.4828e-04\n",
      "Epoch 450/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5970e-04 - val_loss: 3.6663e-04\n",
      "Epoch 451/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7407e-04 - val_loss: 3.3493e-04\n",
      "Epoch 452/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0596e-04 - val_loss: 3.6080e-04\n",
      "Epoch 453/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1633e-04 - val_loss: 4.0308e-04\n",
      "Epoch 454/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7351e-04 - val_loss: 3.0113e-04\n",
      "Epoch 455/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8797e-04 - val_loss: 3.9068e-04\n",
      "Epoch 456/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.8036e-04 - val_loss: 2.9149e-04\n",
      "Epoch 457/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.5353e-04 - val_loss: 3.1306e-04\n",
      "Epoch 458/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.4961e-04 - val_loss: 2.9964e-04\n",
      "Epoch 459/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.4144e-04 - val_loss: 2.7835e-04\n",
      "Epoch 460/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.3197e-04 - val_loss: 3.0878e-04\n",
      "Epoch 461/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.5456e-04 - val_loss: 3.2385e-04\n",
      "Epoch 462/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0896e-04 - val_loss: 3.4217e-04\n",
      "Epoch 463/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2086e-04 - val_loss: 3.4344e-04\n",
      "Epoch 464/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3903e-04 - val_loss: 3.2166e-04\n",
      "Epoch 465/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7644e-04 - val_loss: 3.3052e-04\n",
      "Epoch 466/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9246e-04 - val_loss: 4.1263e-04\n",
      "Epoch 467/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0146e-04 - val_loss: 3.8100e-04\n",
      "Epoch 468/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7990e-04 - val_loss: 3.4231e-04\n",
      "Epoch 469/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9084e-04 - val_loss: 2.9580e-04\n",
      "Epoch 470/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8777e-04 - val_loss: 4.1234e-04\n",
      "Epoch 471/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8595e-04 - val_loss: 3.7034e-04\n",
      "Epoch 472/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.6153e-04 - val_loss: 2.8800e-04\n",
      "Epoch 473/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4492e-04 - val_loss: 3.5875e-04\n",
      "Epoch 474/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7437e-04 - val_loss: 3.6020e-04\n",
      "Epoch 475/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4260e-04 - val_loss: 3.0390e-04\n",
      "Epoch 476/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0667e-04 - val_loss: 3.4225e-04\n",
      "Epoch 477/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5887e-04 - val_loss: 3.1353e-04\n",
      "Epoch 478/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5626e-04 - val_loss: 3.3491e-04\n",
      "Epoch 479/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1663e-04 - val_loss: 4.8562e-04\n",
      "Epoch 480/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4251e-04 - val_loss: 2.6849e-04\n",
      "Epoch 481/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5846e-04 - val_loss: 3.6806e-04\n",
      "Epoch 482/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1315e-04 - val_loss: 3.1266e-04\n",
      "Epoch 483/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3630e-04 - val_loss: 3.0590e-04\n",
      "Epoch 484/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8526e-04 - val_loss: 3.6211e-04\n",
      "Epoch 485/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2849e-04 - val_loss: 3.1427e-04\n",
      "Epoch 486/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0713e-04 - val_loss: 4.3918e-04\n",
      "Epoch 487/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1635e-04 - val_loss: 3.9153e-04\n",
      "Epoch 488/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6505e-04 - val_loss: 5.2469e-04\n",
      "Epoch 489/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3286e-04 - val_loss: 6.9046e-04\n",
      "Epoch 490/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2677e-04 - val_loss: 3.2015e-04\n",
      "Epoch 491/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7486e-04 - val_loss: 6.2110e-04\n",
      "Epoch 492/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1413e-04 - val_loss: 5.0283e-04\n",
      "Epoch 493/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7911e-04 - val_loss: 5.9454e-04\n",
      "Epoch 494/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4214e-04 - val_loss: 7.6316e-04\n",
      "Epoch 495/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5147e-04 - val_loss: 0.0011\n",
      "Epoch 496/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.2966e-04 - val_loss: 0.0010\n",
      "Epoch 497/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5035e-04 - val_loss: 0.0016\n",
      "Epoch 498/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.8927e-04 - val_loss: 0.0014\n",
      "Epoch 499/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.1722e-04 - val_loss: 0.0019\n",
      "Epoch 500/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.8874e-04 - val_loss: 8.4426e-04\n",
      "Epoch 501/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.0313e-04 - val_loss: 0.0014\n",
      "Epoch 502/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2671e-04 - val_loss: 4.9972e-04\n",
      "Epoch 503/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6231e-04 - val_loss: 0.0011\n",
      "Epoch 504/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.3342e-04 - val_loss: 4.8870e-04\n",
      "Epoch 505/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8595e-04 - val_loss: 7.8794e-04\n",
      "Epoch 506/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9024e-04 - val_loss: 3.3468e-04\n",
      "Epoch 507/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4976e-04 - val_loss: 4.6578e-04\n",
      "Epoch 508/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1265e-04 - val_loss: 4.8342e-04\n",
      "Epoch 509/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7316e-04 - val_loss: 5.1160e-04\n",
      "Epoch 510/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0878e-04 - val_loss: 3.4098e-04\n",
      "Epoch 511/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9130e-04 - val_loss: 3.1281e-04\n",
      "Epoch 512/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1106e-04 - val_loss: 5.0694e-04\n",
      "Epoch 513/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1394e-04 - val_loss: 4.5483e-04\n",
      "Epoch 514/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2137e-04 - val_loss: 2.8989e-04\n",
      "Epoch 515/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0357e-04 - val_loss: 4.8995e-04\n",
      "Epoch 516/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8758e-04 - val_loss: 3.3663e-04\n",
      "Epoch 517/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2514e-04 - val_loss: 3.9058e-04\n",
      "Epoch 518/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7744e-04 - val_loss: 4.0970e-04\n",
      "Epoch 519/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8064e-04 - val_loss: 3.5579e-04\n",
      "Epoch 520/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8944e-04 - val_loss: 3.2402e-04\n",
      "Epoch 521/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2595e-04 - val_loss: 4.1723e-04\n",
      "Epoch 522/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3480e-04 - val_loss: 5.8801e-04\n",
      "Epoch 523/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0852e-04 - val_loss: 8.3252e-04\n",
      "Epoch 524/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4076e-04 - val_loss: 6.5453e-04\n",
      "Epoch 525/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8222e-04 - val_loss: 8.0166e-04\n",
      "Epoch 526/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4581e-04 - val_loss: 6.5481e-04\n",
      "Epoch 527/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0794e-04 - val_loss: 8.7574e-04\n",
      "Epoch 528/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1038e-04 - val_loss: 5.6849e-04\n",
      "Epoch 529/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2967e-04 - val_loss: 0.0011\n",
      "Epoch 530/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5214e-04 - val_loss: 4.0617e-04\n",
      "Epoch 531/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0852e-04 - val_loss: 9.5977e-04\n",
      "Epoch 532/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0941e-04 - val_loss: 4.9321e-04\n",
      "Epoch 533/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2432e-04 - val_loss: 7.1440e-04\n",
      "Epoch 534/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6732e-04 - val_loss: 3.9111e-04\n",
      "Epoch 535/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2803e-04 - val_loss: 7.1453e-04\n",
      "Epoch 536/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5293e-04 - val_loss: 5.3903e-04\n",
      "Epoch 537/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4535e-04 - val_loss: 7.4331e-04\n",
      "Epoch 538/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7874e-04 - val_loss: 9.3164e-04\n",
      "Epoch 539/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.8070e-04 - val_loss: 0.0014\n",
      "Epoch 540/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.7238e-04 - val_loss: 8.6301e-04\n",
      "Epoch 541/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6963e-04 - val_loss: 0.0014\n",
      "Epoch 542/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.6742e-04 - val_loss: 0.0013\n",
      "Epoch 543/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.3953e-04 - val_loss: 0.0013\n",
      "Epoch 544/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.8019e-04 - val_loss: 0.0011\n",
      "Epoch 545/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.1174e-04 - val_loss: 9.1528e-04\n",
      "Epoch 546/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.2532e-04 - val_loss: 5.2348e-04\n",
      "Epoch 547/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6160e-04 - val_loss: 6.3115e-04\n",
      "Epoch 548/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8266e-04 - val_loss: 3.5788e-04\n",
      "Epoch 549/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4717e-04 - val_loss: 4.3534e-04\n",
      "Epoch 550/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0523e-04 - val_loss: 3.5530e-04\n",
      "Epoch 551/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3318e-04 - val_loss: 4.3725e-04\n",
      "Epoch 552/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6362e-04 - val_loss: 3.0827e-04\n",
      "Epoch 553/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5875e-04 - val_loss: 4.6934e-04\n",
      "Epoch 554/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4887e-04 - val_loss: 3.9229e-04\n",
      "Epoch 555/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3338e-04 - val_loss: 3.1037e-04\n",
      "Epoch 556/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3726e-04 - val_loss: 2.8984e-04\n",
      "Epoch 557/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0784e-04 - val_loss: 2.9724e-04\n",
      "Epoch 558/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.8643e-05 - val_loss: 3.2749e-04\n",
      "Epoch 559/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5255e-04 - val_loss: 3.2336e-04\n",
      "Epoch 560/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3252e-04 - val_loss: 3.5745e-04\n",
      "Epoch 561/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3150e-04 - val_loss: 2.7640e-04\n",
      "Epoch 562/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3340e-04 - val_loss: 3.0397e-04\n",
      "Epoch 563/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4887e-04 - val_loss: 2.6987e-04\n",
      "Epoch 564/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3579e-04 - val_loss: 3.2055e-04\n",
      "Epoch 565/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2360e-04 - val_loss: 2.8288e-04\n",
      "Epoch 566/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2156e-04 - val_loss: 3.1588e-04\n",
      "Epoch 567/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6268e-04 - val_loss: 3.2406e-04\n",
      "Epoch 568/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2059e-04 - val_loss: 3.0991e-04\n",
      "Epoch 569/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4862e-04 - val_loss: 3.0663e-04\n",
      "Epoch 570/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4130e-04 - val_loss: 3.5529e-04\n",
      "Epoch 571/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2862e-04 - val_loss: 2.9599e-04\n",
      "Epoch 572/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3163e-04 - val_loss: 4.0356e-04\n",
      "Epoch 573/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3422e-04 - val_loss: 4.1223e-04\n",
      "Epoch 574/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1164e-04 - val_loss: 3.1873e-04\n",
      "Epoch 575/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1613e-04 - val_loss: 3.8145e-04\n",
      "Epoch 576/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0347e-04 - val_loss: 3.8719e-04\n",
      "Epoch 577/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0827e-04 - val_loss: 3.9236e-04\n",
      "Epoch 578/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3134e-04 - val_loss: 3.9804e-04\n",
      "Epoch 579/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9544e-04 - val_loss: 3.7000e-04\n",
      "Epoch 580/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3631e-04 - val_loss: 3.9651e-04\n",
      "Epoch 581/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4880e-04 - val_loss: 3.3236e-04\n",
      "Epoch 582/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3927e-04 - val_loss: 3.0607e-04\n",
      "Epoch 583/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.1340e-05 - val_loss: 4.7434e-04\n",
      "Epoch 584/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8591e-04 - val_loss: 3.8161e-04\n",
      "Epoch 585/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8064e-04 - val_loss: 4.2961e-04\n",
      "Epoch 586/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5748e-04 - val_loss: 3.5238e-04\n",
      "Epoch 587/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3943e-04 - val_loss: 3.4887e-04\n",
      "Epoch 588/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4484e-04 - val_loss: 3.4978e-04\n",
      "Epoch 589/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0175e-04 - val_loss: 6.2653e-04\n",
      "Epoch 590/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4294e-04 - val_loss: 5.0962e-04\n",
      "Epoch 591/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3102e-04 - val_loss: 7.2027e-04\n",
      "Epoch 592/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7511e-04 - val_loss: 6.2678e-04\n",
      "Epoch 593/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6607e-04 - val_loss: 7.7075e-04\n",
      "Epoch 594/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5776e-04 - val_loss: 9.5178e-04\n",
      "Epoch 595/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0568e-04 - val_loss: 7.9209e-04\n",
      "Epoch 596/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5769e-04 - val_loss: 0.0010\n",
      "Epoch 597/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1839e-04 - val_loss: 0.0010\n",
      "Epoch 598/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.9110e-04 - val_loss: 0.0011\n",
      "Epoch 599/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.7521e-04 - val_loss: 0.0015\n",
      "Epoch 600/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.6457e-04 - val_loss: 5.2265e-04\n",
      "Epoch 601/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1397e-04 - val_loss: 8.7279e-04\n",
      "Epoch 602/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.0951e-04 - val_loss: 6.6823e-04\n",
      "Epoch 603/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.2554e-04 - val_loss: 9.3247e-04\n",
      "Epoch 604/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5063e-04 - val_loss: 6.4850e-04\n",
      "Epoch 605/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6596e-04 - val_loss: 7.8240e-04\n",
      "Epoch 606/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2958e-04 - val_loss: 3.7138e-04\n",
      "Epoch 607/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4286e-04 - val_loss: 4.0959e-04\n",
      "Epoch 608/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8021e-04 - val_loss: 4.0147e-04\n",
      "Epoch 609/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4717e-04 - val_loss: 3.1098e-04\n",
      "Epoch 610/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5060e-04 - val_loss: 6.1491e-04\n",
      "Epoch 611/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7283e-04 - val_loss: 3.0037e-04\n",
      "Epoch 612/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7921e-04 - val_loss: 5.7456e-04\n",
      "Epoch 613/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.5232e-04 - val_loss: 3.2053e-04\n",
      "Epoch 614/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8315e-04 - val_loss: 5.2421e-04\n",
      "Epoch 615/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9111e-04 - val_loss: 4.0242e-04\n",
      "Epoch 616/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4724e-04 - val_loss: 5.7967e-04\n",
      "Epoch 617/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2489e-04 - val_loss: 5.7304e-04\n",
      "Epoch 618/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7849e-04 - val_loss: 7.9942e-04\n",
      "Epoch 619/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4685e-04 - val_loss: 3.0790e-04\n",
      "Epoch 620/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4753e-04 - val_loss: 4.3211e-04\n",
      "Epoch 621/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9179e-04 - val_loss: 3.6729e-04\n",
      "Epoch 622/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4489e-04 - val_loss: 3.9322e-04\n",
      "Epoch 623/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1379e-04 - val_loss: 3.3670e-04\n",
      "Epoch 624/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5558e-04 - val_loss: 3.4916e-04\n",
      "Epoch 625/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8449e-04 - val_loss: 4.5964e-04\n",
      "Epoch 626/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9743e-04 - val_loss: 3.0328e-04\n",
      "Epoch 627/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3051e-04 - val_loss: 5.4675e-04\n",
      "Epoch 628/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8701e-04 - val_loss: 9.0825e-04\n",
      "Epoch 629/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.9157e-04 - val_loss: 0.0011\n",
      "Epoch 630/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.9484e-04 - val_loss: 7.4739e-04\n",
      "Epoch 631/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0699e-04 - val_loss: 0.0011\n",
      "Epoch 632/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9743e-04 - val_loss: 4.9734e-04\n",
      "Epoch 633/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.8343e-04 - val_loss: 7.4525e-04\n",
      "Epoch 634/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2789e-04 - val_loss: 3.0089e-04\n",
      "Epoch 635/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3891e-04 - val_loss: 3.4706e-04\n",
      "Epoch 636/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1055e-04 - val_loss: 7.0742e-04\n",
      "Epoch 637/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.7185e-04 - val_loss: 4.6410e-04\n",
      "Epoch 638/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3791e-04 - val_loss: 4.2320e-04\n",
      "Epoch 639/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5998e-04 - val_loss: 6.5998e-04\n",
      "Epoch 640/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6167e-04 - val_loss: 4.0846e-04\n",
      "Epoch 641/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0901e-04 - val_loss: 4.4816e-04\n",
      "Epoch 642/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7153e-04 - val_loss: 3.3914e-04\n",
      "Epoch 643/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6250e-04 - val_loss: 4.3603e-04\n",
      "Epoch 644/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4432e-04 - val_loss: 3.2660e-04\n",
      "Epoch 645/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3100e-04 - val_loss: 4.1636e-04\n",
      "Epoch 646/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8023e-04 - val_loss: 5.3715e-04\n",
      "Epoch 647/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8660e-04 - val_loss: 6.5900e-04\n",
      "Epoch 648/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4495e-04 - val_loss: 3.3749e-04\n",
      "Epoch 649/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4615e-04 - val_loss: 5.4122e-04\n",
      "Epoch 650/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1606e-04 - val_loss: 3.5971e-04\n",
      "Epoch 651/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2802e-04 - val_loss: 3.4709e-04\n",
      "Epoch 652/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9456e-04 - val_loss: 3.7325e-04\n",
      "Epoch 653/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.7253e-05 - val_loss: 4.3111e-04\n",
      "Epoch 654/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2812e-04 - val_loss: 3.0255e-04\n",
      "Epoch 655/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3924e-04 - val_loss: 2.9347e-04\n",
      "Epoch 656/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0950e-04 - val_loss: 3.8244e-04\n",
      "Epoch 657/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1965e-04 - val_loss: 4.1619e-04\n",
      "Epoch 658/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0145e-04 - val_loss: 6.5845e-04\n",
      "Epoch 659/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3781e-04 - val_loss: 8.6356e-04\n",
      "Epoch 660/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9756e-04 - val_loss: 9.4012e-04\n",
      "Epoch 661/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3598e-04 - val_loss: 8.6088e-04\n",
      "Epoch 662/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7084e-04 - val_loss: 0.0014\n",
      "Epoch 663/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.8245e-04 - val_loss: 6.3186e-04\n",
      "Epoch 664/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0469e-04 - val_loss: 7.8917e-04\n",
      "Epoch 665/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.7059e-04 - val_loss: 3.9696e-04\n",
      "Epoch 666/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5172e-04 - val_loss: 3.2809e-04\n",
      "Epoch 667/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5622e-04 - val_loss: 3.9680e-04\n",
      "Epoch 668/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1507e-04 - val_loss: 6.0730e-04\n",
      "Epoch 669/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0233e-04 - val_loss: 6.0536e-04\n",
      "Epoch 670/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 2.0493e-04 - val_loss: 3.0285e-04\n",
      "Epoch 671/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5557e-04 - val_loss: 4.1296e-04\n",
      "Epoch 672/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0453e-04 - val_loss: 4.1544e-04\n",
      "Epoch 673/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6507e-04 - val_loss: 4.3770e-04\n",
      "Epoch 674/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6117e-04 - val_loss: 3.0733e-04\n",
      "Epoch 675/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1925e-04 - val_loss: 3.5482e-04\n",
      "Epoch 676/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0321e-04 - val_loss: 3.4374e-04\n",
      "Epoch 677/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5307e-04 - val_loss: 3.2057e-04\n",
      "Epoch 678/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.8699e-05 - val_loss: 3.4094e-04\n",
      "Epoch 679/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0977e-04 - val_loss: 3.5394e-04\n",
      "Epoch 680/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2101e-04 - val_loss: 3.1662e-04\n",
      "Epoch 681/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2221e-04 - val_loss: 3.0748e-04\n",
      "Epoch 682/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0596e-04 - val_loss: 3.6532e-04\n",
      "Epoch 683/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2625e-04 - val_loss: 3.2289e-04\n",
      "Epoch 684/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4075e-04 - val_loss: 4.1194e-04\n",
      "Epoch 685/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2084e-04 - val_loss: 3.3595e-04\n",
      "Epoch 686/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2489e-04 - val_loss: 3.1789e-04\n",
      "Epoch 687/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4221e-04 - val_loss: 2.8662e-04\n",
      "Epoch 688/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0362e-04 - val_loss: 3.3653e-04\n",
      "Epoch 689/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0465e-04 - val_loss: 4.6075e-04\n",
      "Epoch 690/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2249e-04 - val_loss: 4.1223e-04\n",
      "Epoch 691/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3250e-04 - val_loss: 2.8311e-04\n",
      "Epoch 692/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2155e-04 - val_loss: 3.3297e-04\n",
      "Epoch 693/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6354e-04 - val_loss: 4.1934e-04\n",
      "Epoch 694/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5947e-04 - val_loss: 3.8440e-04\n",
      "Epoch 695/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1590e-04 - val_loss: 2.7694e-04\n",
      "Epoch 696/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.6742e-05 - val_loss: 3.4534e-04\n",
      "Epoch 697/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0909e-04 - val_loss: 3.2489e-04\n",
      "Epoch 698/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1340e-04 - val_loss: 2.9640e-04\n",
      "Epoch 699/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2620e-04 - val_loss: 3.9202e-04\n",
      "Epoch 700/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2421e-04 - val_loss: 4.2659e-04\n",
      "Epoch 701/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0500e-04 - val_loss: 3.0308e-04\n",
      "Epoch 702/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2349e-04 - val_loss: 2.8808e-04\n",
      "Epoch 703/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3995e-04 - val_loss: 4.4833e-04\n",
      "Epoch 704/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2283e-04 - val_loss: 4.1658e-04\n",
      "Epoch 705/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0755e-04 - val_loss: 3.1434e-04\n",
      "Epoch 706/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2537e-04 - val_loss: 3.2672e-04\n",
      "Epoch 707/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2282e-04 - val_loss: 3.4926e-04\n",
      "Epoch 708/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4635e-04 - val_loss: 4.0757e-04\n",
      "Epoch 709/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3277e-04 - val_loss: 4.8173e-04\n",
      "Epoch 710/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5417e-04 - val_loss: 3.2110e-04\n",
      "Epoch 711/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7050e-04 - val_loss: 3.9686e-04\n",
      "Epoch 712/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1410e-04 - val_loss: 4.3306e-04\n",
      "Epoch 713/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4503e-04 - val_loss: 3.6623e-04\n",
      "Epoch 714/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4771e-04 - val_loss: 3.3644e-04\n",
      "Epoch 715/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1460e-04 - val_loss: 4.4022e-04\n",
      "Epoch 716/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6335e-04 - val_loss: 3.7371e-04\n",
      "Epoch 717/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3977e-04 - val_loss: 3.6920e-04\n",
      "Epoch 718/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2026e-04 - val_loss: 3.8812e-04\n",
      "Epoch 719/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4338e-04 - val_loss: 3.1371e-04\n",
      "Epoch 720/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0925e-04 - val_loss: 3.0836e-04\n",
      "Epoch 721/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5361e-04 - val_loss: 3.8170e-04\n",
      "Epoch 722/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3234e-04 - val_loss: 3.9874e-04\n",
      "Epoch 723/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7006e-04 - val_loss: 3.5591e-04\n",
      "Epoch 724/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3405e-04 - val_loss: 3.7755e-04\n",
      "Epoch 725/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6824e-04 - val_loss: 5.5865e-04\n",
      "Epoch 726/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8046e-04 - val_loss: 4.9668e-04\n",
      "Epoch 727/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5860e-04 - val_loss: 4.2751e-04\n",
      "Epoch 728/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7328e-04 - val_loss: 5.4975e-04\n",
      "Epoch 729/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6545e-04 - val_loss: 8.5484e-04\n",
      "Epoch 730/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1292e-04 - val_loss: 8.5786e-04\n",
      "Epoch 731/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3766e-04 - val_loss: 9.8605e-04\n",
      "Epoch 732/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3103e-04 - val_loss: 0.0011\n",
      "Epoch 733/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.5029e-04 - val_loss: 0.0010\n",
      "Epoch 734/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.3675e-04 - val_loss: 5.5542e-04\n",
      "Epoch 735/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1027e-04 - val_loss: 4.9446e-04\n",
      "Epoch 736/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4832e-04 - val_loss: 3.2062e-04\n",
      "Epoch 737/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9851e-04 - val_loss: 3.1256e-04\n",
      "Epoch 738/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8157e-04 - val_loss: 4.2064e-04\n",
      "Epoch 739/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2436e-04 - val_loss: 3.1608e-04\n",
      "Epoch 740/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5529e-04 - val_loss: 3.7244e-04\n",
      "Epoch 741/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4201e-04 - val_loss: 3.1681e-04\n",
      "Epoch 742/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.5421e-05 - val_loss: 4.0164e-04\n",
      "Epoch 743/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 8.4184e-05 - val_loss: 3.8198e-04\n",
      "Epoch 744/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6554e-04 - val_loss: 4.0297e-04\n",
      "Epoch 745/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4252e-04 - val_loss: 3.5224e-04\n",
      "Epoch 746/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0354e-04 - val_loss: 3.5842e-04\n",
      "Epoch 747/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0842e-04 - val_loss: 4.1801e-04\n",
      "Epoch 748/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0569e-04 - val_loss: 4.5227e-04\n",
      "Epoch 749/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4997e-04 - val_loss: 4.3190e-04\n",
      "Epoch 750/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4556e-05 - val_loss: 3.3683e-04\n",
      "Epoch 751/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.6542e-05 - val_loss: 3.5047e-04\n",
      "Epoch 752/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2713e-04 - val_loss: 3.0723e-04\n",
      "Epoch 753/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.6093e-05 - val_loss: 3.8449e-04\n",
      "Epoch 754/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2323e-04 - val_loss: 3.9518e-04\n",
      "Epoch 755/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3721e-04 - val_loss: 3.4133e-04\n",
      "Epoch 756/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6051e-04 - val_loss: 6.2718e-04\n",
      "Epoch 757/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9494e-04 - val_loss: 4.4248e-04\n",
      "Epoch 758/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2425e-04 - val_loss: 5.0700e-04\n",
      "Epoch 759/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4614e-04 - val_loss: 4.5106e-04\n",
      "Epoch 760/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4893e-04 - val_loss: 5.9191e-04\n",
      "Epoch 761/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3442e-04 - val_loss: 7.4813e-04\n",
      "Epoch 762/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.0571e-04 - val_loss: 8.8854e-04\n",
      "Epoch 763/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1920e-04 - val_loss: 9.1098e-04\n",
      "Epoch 764/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2491e-04 - val_loss: 8.8980e-04\n",
      "Epoch 765/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.9103e-04 - val_loss: 9.9056e-04\n",
      "Epoch 766/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 4.4982e-04 - val_loss: 4.0701e-04\n",
      "Epoch 767/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.5016e-04 - val_loss: 5.2797e-04\n",
      "Epoch 768/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4469e-04 - val_loss: 4.1622e-04\n",
      "Epoch 769/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1767e-04 - val_loss: 3.3078e-04\n",
      "Epoch 770/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1279e-04 - val_loss: 4.0247e-04\n",
      "Epoch 771/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0921e-04 - val_loss: 3.8505e-04\n",
      "Epoch 772/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5727e-04 - val_loss: 3.4964e-04\n",
      "Epoch 773/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6529e-04 - val_loss: 4.4292e-04\n",
      "Epoch 774/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4166e-04 - val_loss: 4.2905e-04\n",
      "Epoch 775/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3545e-04 - val_loss: 4.7230e-04\n",
      "Epoch 776/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3799e-04 - val_loss: 3.8553e-04\n",
      "Epoch 777/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.6020e-05 - val_loss: 3.0646e-04\n",
      "Epoch 778/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2298e-04 - val_loss: 4.6297e-04\n",
      "Epoch 779/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3129e-04 - val_loss: 4.5442e-04\n",
      "Epoch 780/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1747e-04 - val_loss: 2.9645e-04\n",
      "Epoch 781/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0806e-04 - val_loss: 3.1355e-04\n",
      "Epoch 782/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1305e-04 - val_loss: 3.7332e-04\n",
      "Epoch 783/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1246e-04 - val_loss: 3.4471e-04\n",
      "Epoch 784/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0822e-04 - val_loss: 3.4029e-04\n",
      "Epoch 785/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.8661e-05 - val_loss: 2.9056e-04\n",
      "Epoch 786/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2449e-04 - val_loss: 3.7072e-04\n",
      "Epoch 787/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3208e-04 - val_loss: 4.6155e-04\n",
      "Epoch 788/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3698e-04 - val_loss: 3.8463e-04\n",
      "Epoch 789/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9285e-04 - val_loss: 3.3782e-04\n",
      "Epoch 790/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.5325e-05 - val_loss: 4.2546e-04\n",
      "Epoch 791/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1157e-04 - val_loss: 4.1200e-04\n",
      "Epoch 792/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5947e-04 - val_loss: 3.3347e-04\n",
      "Epoch 793/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6665e-04 - val_loss: 3.8261e-04\n",
      "Epoch 794/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0614e-04 - val_loss: 4.1228e-04\n",
      "Epoch 795/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2620e-04 - val_loss: 4.0652e-04\n",
      "Epoch 796/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6874e-04 - val_loss: 4.2580e-04\n",
      "Epoch 797/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5246e-04 - val_loss: 3.5872e-04\n",
      "Epoch 798/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3281e-04 - val_loss: 4.3973e-04\n",
      "Epoch 799/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2269e-04 - val_loss: 3.3568e-04\n",
      "Epoch 800/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0500e-04 - val_loss: 4.2298e-04\n",
      "Epoch 801/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2058e-04 - val_loss: 3.3703e-04\n",
      "Epoch 802/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0817e-04 - val_loss: 3.8156e-04\n",
      "Epoch 803/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0639e-04 - val_loss: 3.4165e-04\n",
      "Epoch 804/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0024e-04 - val_loss: 3.5252e-04\n",
      "Epoch 805/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4419e-05 - val_loss: 3.3587e-04\n",
      "Epoch 806/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.5279e-05 - val_loss: 3.9997e-04\n",
      "Epoch 807/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.5903e-05 - val_loss: 3.1654e-04\n",
      "Epoch 808/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0701e-04 - val_loss: 3.1917e-04\n",
      "Epoch 809/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6917e-04 - val_loss: 4.2646e-04\n",
      "Epoch 810/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8218e-04 - val_loss: 3.9663e-04\n",
      "Epoch 811/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0289e-04 - val_loss: 2.9478e-04\n",
      "Epoch 812/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6954e-04 - val_loss: 3.3566e-04\n",
      "Epoch 813/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1457e-04 - val_loss: 4.4763e-04\n",
      "Epoch 814/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2431e-04 - val_loss: 3.2971e-04\n",
      "Epoch 815/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5490e-04 - val_loss: 3.8703e-04\n",
      "Epoch 816/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1355e-04 - val_loss: 3.5936e-04\n",
      "Epoch 817/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3136e-04 - val_loss: 4.4910e-04\n",
      "Epoch 818/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9720e-04 - val_loss: 4.4249e-04\n",
      "Epoch 819/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7957e-04 - val_loss: 6.2447e-04\n",
      "Epoch 820/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2407e-04 - val_loss: 4.9667e-04\n",
      "Epoch 821/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4538e-04 - val_loss: 0.0012\n",
      "Epoch 822/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 5.2650e-04 - val_loss: 7.6703e-04\n",
      "Epoch 823/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2735e-04 - val_loss: 9.3156e-04\n",
      "Epoch 824/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.9365e-04 - val_loss: 4.0173e-04\n",
      "Epoch 825/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4228e-04 - val_loss: 4.3887e-04\n",
      "Epoch 826/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2680e-04 - val_loss: 3.2611e-04\n",
      "Epoch 827/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3350e-04 - val_loss: 3.7921e-04\n",
      "Epoch 828/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1067e-04 - val_loss: 4.5976e-04\n",
      "Epoch 829/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3996e-04 - val_loss: 4.0353e-04\n",
      "Epoch 830/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2822e-04 - val_loss: 4.1956e-04\n",
      "Epoch 831/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6347e-04 - val_loss: 4.7470e-04\n",
      "Epoch 832/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1107e-04 - val_loss: 5.2536e-04\n",
      "Epoch 833/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0632e-04 - val_loss: 3.9000e-04\n",
      "Epoch 834/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1720e-04 - val_loss: 3.5236e-04\n",
      "Epoch 835/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7105e-04 - val_loss: 3.5647e-04\n",
      "Epoch 836/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3778e-04 - val_loss: 3.0931e-04\n",
      "Epoch 837/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0708e-04 - val_loss: 4.1047e-04\n",
      "Epoch 838/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4359e-04 - val_loss: 3.2840e-04\n",
      "Epoch 839/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2667e-04 - val_loss: 3.3868e-04\n",
      "Epoch 840/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1415e-04 - val_loss: 3.1311e-04\n",
      "Epoch 841/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0046e-04 - val_loss: 2.8993e-04\n",
      "Epoch 842/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1717e-04 - val_loss: 3.1146e-04\n",
      "Epoch 843/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4150e-05 - val_loss: 3.3139e-04\n",
      "Epoch 844/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0702e-04 - val_loss: 3.8218e-04\n",
      "Epoch 845/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.5154e-05 - val_loss: 2.7013e-04\n",
      "Epoch 846/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.1185e-05 - val_loss: 3.0703e-04\n",
      "Epoch 847/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4414e-05 - val_loss: 3.5971e-04\n",
      "Epoch 848/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2635e-04 - val_loss: 3.6097e-04\n",
      "Epoch 849/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9986e-04 - val_loss: 4.6534e-04\n",
      "Epoch 850/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0735e-04 - val_loss: 5.4988e-04\n",
      "Epoch 851/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2090e-04 - val_loss: 3.2683e-04\n",
      "Epoch 852/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.8880e-05 - val_loss: 3.1802e-04\n",
      "Epoch 853/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.2468e-05 - val_loss: 3.8872e-04\n",
      "Epoch 854/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3972e-04 - val_loss: 3.5557e-04\n",
      "Epoch 855/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.9827e-05 - val_loss: 3.4197e-04\n",
      "Epoch 856/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.2325e-05 - val_loss: 2.8215e-04\n",
      "Epoch 857/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3129e-04 - val_loss: 3.2780e-04\n",
      "Epoch 858/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.3564e-05 - val_loss: 4.0785e-04\n",
      "Epoch 859/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1370e-04 - val_loss: 3.8434e-04\n",
      "Epoch 860/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1304e-04 - val_loss: 3.4267e-04\n",
      "Epoch 861/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.3693e-05 - val_loss: 3.8787e-04\n",
      "Epoch 862/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0330e-04 - val_loss: 3.3479e-04\n",
      "Epoch 863/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.1884e-05 - val_loss: 3.7597e-04\n",
      "Epoch 864/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2765e-04 - val_loss: 3.5476e-04\n",
      "Epoch 865/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0325e-04 - val_loss: 4.0054e-04\n",
      "Epoch 866/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.0280e-05 - val_loss: 2.9708e-04\n",
      "Epoch 867/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.2951e-05 - val_loss: 3.1093e-04\n",
      "Epoch 868/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2657e-04 - val_loss: 3.7949e-04\n",
      "Epoch 869/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7803e-04 - val_loss: 4.7316e-04\n",
      "Epoch 870/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7014e-04 - val_loss: 4.4988e-04\n",
      "Epoch 871/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4167e-04 - val_loss: 7.7025e-04\n",
      "Epoch 872/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.5402e-04 - val_loss: 8.6896e-04\n",
      "Epoch 873/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1372e-04 - val_loss: 0.0011\n",
      "Epoch 874/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1908e-04 - val_loss: 6.8082e-04\n",
      "Epoch 875/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.1230e-04 - val_loss: 9.0768e-04\n",
      "Epoch 876/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.4598e-04 - val_loss: 4.1304e-04\n",
      "Epoch 877/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0863e-04 - val_loss: 5.2415e-04\n",
      "Epoch 878/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0188e-04 - val_loss: 4.1390e-04\n",
      "Epoch 879/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9473e-04 - val_loss: 4.5425e-04\n",
      "Epoch 880/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4661e-04 - val_loss: 2.8790e-04\n",
      "Epoch 881/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1132e-04 - val_loss: 3.1681e-04\n",
      "Epoch 882/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.2141e-05 - val_loss: 4.5042e-04\n",
      "Epoch 883/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0221e-04 - val_loss: 3.6395e-04\n",
      "Epoch 884/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.6526e-05 - val_loss: 3.0496e-04\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3098e-04 - val_loss: 3.1304e-04\n",
      "Epoch 886/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1079e-04 - val_loss: 4.0182e-04\n",
      "Epoch 887/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0628e-04 - val_loss: 4.3205e-04\n",
      "Epoch 888/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0785e-04 - val_loss: 3.8771e-04\n",
      "Epoch 889/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4893e-05 - val_loss: 3.1027e-04\n",
      "Epoch 890/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0135e-04 - val_loss: 4.0643e-04\n",
      "Epoch 891/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3198e-04 - val_loss: 4.4615e-04\n",
      "Epoch 892/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.8113e-05 - val_loss: 3.0392e-04\n",
      "Epoch 893/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6991e-04 - val_loss: 3.7532e-04\n",
      "Epoch 894/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5533e-04 - val_loss: 5.0817e-04\n",
      "Epoch 895/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2533e-04 - val_loss: 3.4796e-04\n",
      "Epoch 896/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.0727e-04 - val_loss: 5.4558e-04\n",
      "Epoch 897/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4955e-04 - val_loss: 4.4434e-04\n",
      "Epoch 898/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.8807e-04 - val_loss: 5.6481e-04\n",
      "Epoch 899/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4107e-04 - val_loss: 5.6220e-04\n",
      "Epoch 900/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9234e-04 - val_loss: 4.6385e-04\n",
      "Epoch 901/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9170e-04 - val_loss: 6.6968e-04\n",
      "Epoch 902/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2152e-04 - val_loss: 4.9465e-04\n",
      "Epoch 903/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1086e-04 - val_loss: 7.3606e-04\n",
      "Epoch 904/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.7464e-04 - val_loss: 4.9815e-04\n",
      "Epoch 905/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6043e-04 - val_loss: 7.0078e-04\n",
      "Epoch 906/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1688e-04 - val_loss: 3.7944e-04\n",
      "Epoch 907/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.1029e-04 - val_loss: 6.4302e-04\n",
      "Epoch 908/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.8052e-04 - val_loss: 5.1029e-04\n",
      "Epoch 909/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3522e-04 - val_loss: 7.4504e-04\n",
      "Epoch 910/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4522e-04 - val_loss: 2.7556e-04\n",
      "Epoch 911/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1473e-04 - val_loss: 4.2355e-04\n",
      "Epoch 912/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2928e-04 - val_loss: 3.7067e-04\n",
      "Epoch 913/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4881e-04 - val_loss: 4.1125e-04\n",
      "Epoch 914/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.4008e-05 - val_loss: 3.2505e-04\n",
      "Epoch 915/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2670e-04 - val_loss: 3.0444e-04\n",
      "Epoch 916/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.9239e-05 - val_loss: 4.0503e-04\n",
      "Epoch 917/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0334e-04 - val_loss: 2.8945e-04\n",
      "Epoch 918/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1806e-04 - val_loss: 4.2855e-04\n",
      "Epoch 919/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5712e-04 - val_loss: 3.1704e-04\n",
      "Epoch 920/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3438e-04 - val_loss: 5.3934e-04\n",
      "Epoch 921/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.6808e-04 - val_loss: 3.4840e-04\n",
      "Epoch 922/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5123e-04 - val_loss: 6.7664e-04\n",
      "Epoch 923/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7160e-04 - val_loss: 4.6398e-04\n",
      "Epoch 924/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9063e-04 - val_loss: 8.9044e-04\n",
      "Epoch 925/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2243e-04 - val_loss: 5.7083e-04\n",
      "Epoch 926/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.4063e-04 - val_loss: 0.0010\n",
      "Epoch 927/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.0090e-04 - val_loss: 6.9656e-04\n",
      "Epoch 928/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6124e-04 - val_loss: 9.6626e-04\n",
      "Epoch 929/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.6563e-04 - val_loss: 3.7440e-04\n",
      "Epoch 930/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3778e-04 - val_loss: 3.1664e-04\n",
      "Epoch 931/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4945e-04 - val_loss: 4.0560e-04\n",
      "Epoch 932/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1928e-04 - val_loss: 3.3051e-04\n",
      "Epoch 933/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3168e-04 - val_loss: 3.9185e-04\n",
      "Epoch 934/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.5818e-05 - val_loss: 3.2827e-04\n",
      "Epoch 935/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2854e-04 - val_loss: 3.1177e-04\n",
      "Epoch 936/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1492e-04 - val_loss: 4.1332e-04\n",
      "Epoch 937/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.9549e-05 - val_loss: 3.7728e-04\n",
      "Epoch 938/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0895e-04 - val_loss: 3.7829e-04\n",
      "Epoch 939/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.1548e-05 - val_loss: 2.7492e-04\n",
      "Epoch 940/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0745e-04 - val_loss: 3.7008e-04\n",
      "Epoch 941/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0873e-04 - val_loss: 3.0713e-04\n",
      "Epoch 942/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1016e-04 - val_loss: 3.3089e-04\n",
      "Epoch 943/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.8626e-05 - val_loss: 3.6131e-04\n",
      "Epoch 944/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.4334e-05 - val_loss: 2.9580e-04\n",
      "Epoch 945/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.5328e-05 - val_loss: 3.2015e-04\n",
      "Epoch 946/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.5275e-05 - val_loss: 3.6046e-04\n",
      "Epoch 947/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 6.5770e-05 - val_loss: 3.1292e-04\n",
      "Epoch 948/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.2850e-04 - val_loss: 3.0156e-04\n",
      "Epoch 949/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.8491e-05 - val_loss: 3.1098e-04\n",
      "Epoch 950/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.6057e-05 - val_loss: 2.9658e-04\n",
      "Epoch 951/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.7606e-05 - val_loss: 3.5282e-04\n",
      "Epoch 952/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.0195e-04 - val_loss: 3.0453e-04\n",
      "Epoch 953/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.0227e-04 - val_loss: 4.3920e-04\n",
      "Epoch 954/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.0252e-04 - val_loss: 2.7703e-04\n",
      "Epoch 955/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.2515e-05 - val_loss: 3.4622e-04\n",
      "Epoch 956/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 1.1276e-04 - val_loss: 3.7243e-04\n",
      "Epoch 957/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.7557e-05 - val_loss: 3.6502e-04\n",
      "Epoch 958/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.5778e-05 - val_loss: 3.6211e-04\n",
      "Epoch 959/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 8.4202e-05 - val_loss: 2.6247e-04\n",
      "Epoch 960/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 8.8746e-05 - val_loss: 3.7452e-04\n",
      "Epoch 961/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.7920e-05 - val_loss: 3.0067e-04\n",
      "Epoch 962/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.8670e-05 - val_loss: 3.0077e-04\n",
      "Epoch 963/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.0214e-05 - val_loss: 2.6076e-04\n",
      "Epoch 964/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 9.6518e-05 - val_loss: 3.3284e-04\n",
      "Epoch 965/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1095e-04 - val_loss: 3.2193e-04\n",
      "Epoch 966/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.7409e-05 - val_loss: 2.6920e-04\n",
      "Epoch 967/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 7.3057e-05 - val_loss: 3.0809e-04\n",
      "Epoch 968/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0702e-04 - val_loss: 3.4849e-04\n",
      "Epoch 969/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5487e-04 - val_loss: 4.3282e-04\n",
      "Epoch 970/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0951e-04 - val_loss: 2.8475e-04\n",
      "Epoch 971/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.5801e-05 - val_loss: 3.6234e-04\n",
      "Epoch 972/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3469e-04 - val_loss: 4.0581e-04\n",
      "Epoch 973/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3278e-04 - val_loss: 4.6201e-04\n",
      "Epoch 974/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3532e-04 - val_loss: 3.3512e-04\n",
      "Epoch 975/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2594e-04 - val_loss: 3.6683e-04\n",
      "Epoch 976/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.1890e-05 - val_loss: 3.4733e-04\n",
      "Epoch 977/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5584e-04 - val_loss: 3.0023e-04\n",
      "Epoch 978/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.0051e-05 - val_loss: 2.9464e-04\n",
      "Epoch 979/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.6612e-05 - val_loss: 2.9932e-04\n",
      "Epoch 980/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0618e-04 - val_loss: 3.3656e-04\n",
      "Epoch 981/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1352e-04 - val_loss: 3.2492e-04\n",
      "Epoch 982/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 7.3119e-05 - val_loss: 2.9509e-04\n",
      "Epoch 983/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3417e-04 - val_loss: 3.1753e-04\n",
      "Epoch 984/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.2244e-04 - val_loss: 4.0072e-04\n",
      "Epoch 985/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.1802e-04 - val_loss: 3.3627e-04\n",
      "Epoch 986/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.5319e-05 - val_loss: 2.6375e-04\n",
      "Epoch 987/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.0511e-04 - val_loss: 2.8053e-04\n",
      "Epoch 988/1000\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 7.7361e-05 - val_loss: 3.4397e-04\n",
      "Epoch 989/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 8.5049e-05 - val_loss: 3.0324e-04\n",
      "Epoch 990/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4035e-04 - val_loss: 5.2858e-04\n",
      "Epoch 991/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.7627e-04 - val_loss: 3.9557e-04\n",
      "Epoch 992/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.4697e-04 - val_loss: 5.6020e-04\n",
      "Epoch 993/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.5977e-04 - val_loss: 5.6690e-04\n",
      "Epoch 994/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.6319e-04 - val_loss: 7.3847e-04\n",
      "Epoch 995/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 3.2407e-04 - val_loss: 5.4491e-04\n",
      "Epoch 996/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3647e-04 - val_loss: 5.9240e-04\n",
      "Epoch 997/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 2.3081e-04 - val_loss: 3.4187e-04\n",
      "Epoch 998/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.9731e-04 - val_loss: 3.1993e-04\n",
      "Epoch 999/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 1.3719e-04 - val_loss: 3.4622e-04\n",
      "Epoch 1000/1000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 9.2380e-05 - val_loss: 3.3874e-04\n"
     ]
    }
   ],
   "source": [
    "rms = keras.optimizers.rmsprop(lr = 0.005, decay = .00001)\n",
    "adagrad = keras.optimizers.adagrad(lr= 0.0075)\n",
    "Nadam = keras.optimizers.Nadam(lr = 0.001)\n",
    "adamax = keras.optimizers.adamax(lr = .005, decay = .001)\n",
    "sgd = keras.optimizers.sgd(lr=0.1, decay =0.001)\n",
    "drop = 0.05\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation = 'relu', recurrent_dropout = drop,  input_shape= (train_x.shape[1], train_x.shape[2])))\n",
    "#model.add(LSTM(50, activation = 'relu',  input_shape= (train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dropout(drop))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dropout(drop))\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = adamax ,loss = 'mean_squared_error')\n",
    "hist = model.fit(train_x, train_y, epochs = 1000, shuffle = False, validation_data=(test_x, test_y))#callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZJRR8IuIjDIKfhGRUUbBLyIyyvwbcL9a6nsk478AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x171bcb9ab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], label='train')\n",
    "plt.plot(hist.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1469857460435699, 0.14260473759735331, 0.052498884279938304, 0.08110772182836253, 0.11051994080052656, 0.0725513039266362, 0.0487737516489099, 0.05110337629037745, 0.02482143197866047, 0.009040681229260586, 0.008012851138654001, 0.002861816586707445, 0.0025621818974340227, 0.0030870147405520957, 0.0023145781323204145, 0.0021902660921435148, 0.002294490059070727, 0.0019712172215804458, 0.003107080796112046, 0.0021039339891799234, 0.004649452639141065, 0.00197930378935245, 0.004289196567911217, 0.002023809647653252, 0.00385429838549017, 0.0019593658054124236, 0.00268985066224345, 0.002568816623512676, 0.0022959620721795704, 0.0025746913347307675, 0.0017850689764600247, 0.002443478579259724, 0.0017275889609556865, 0.002051263632786097, 0.001901002528885489, 0.001975345807937522, 0.0019265355040261056, 0.0015497116461012732, 0.0016289214894213194, 0.0019156759483260376, 0.0016451027241761468, 0.0018566031559363611, 0.00181661632257815, 0.001746785625394242, 0.001517256796325776, 0.0019173524111358669, 0.001524241766995093, 0.002041090658167377, 0.0013807784707751125, 0.0023592232404660214, 0.0014415724555660477, 0.0019077558364883503, 0.0014909976213376092, 0.0025796298389596972, 0.0012921218979446327, 0.003071426975486033, 0.0015473388655878166, 0.002835208426832276, 0.0014981071255854605, 0.0021487208603716947, 0.0022114400190356024, 0.0022579826558392275, 0.0011254834312507335, 0.0026952523792929508, 0.0016635732780046323, 0.002098845167304663, 0.0016914778799914261, 0.001919366720625583, 0.0018215926966684707, 0.0014737675356788233, 0.0017388323390418116, 0.001014046898276052, 0.0009665536173783681, 0.0020295618211521823, 0.0012499747681431472, 0.002290494288043941, 0.0017701047198737368, 0.0015268209801219841, 0.0012638768564690562, 0.002425811513710548, 0.0018298573011313291, 0.0017124644809347741, 0.0021751337849041995, 0.002279298201970318, 0.0011187790591708, 0.0019603113452082172, 0.0018653050065040588, 0.0021855433416717194, 0.0007956271908958169, 0.0024597463745842964, 0.0015358524876372779, 0.0017358670011162758, 0.0015227008775314864, 0.0015440893304698607, 0.001813383197740597, 0.0009988082079764675, 0.0013216575333739027, 0.0012660404146813294, 0.0012270922101486254, 0.0011205742793048128, 0.0025347980177577805, 0.0009441453525248696, 0.0018233986270120915, 0.0013186547165626988, 0.0012119815903989708, 0.0011911481372354662, 0.0008514691418146386, 0.0017452588140526239, 0.001475566066801548, 0.0009479482712991097, 0.0029047154547537073, 0.0013288207804126775, 0.0024114654618589315, 0.001228728550760185, 0.002258211785160443, 0.0012427714571137639, 0.001403127221719307, 0.0014694516053971123, 0.0010792922146399232, 0.0011686662705067325, 0.0009583354215411579, 0.0013163641697781928, 0.0013541565687559983, 0.0020795511903569978, 0.001219771775033544, 0.0016825968153117335, 0.0013628688586108824, 0.0015831694198662743, 0.0010611983974847723, 0.0019389624323915033, 0.0007004734224585049, 0.0017095556044403244, 0.0016796435777317075, 0.001231145250665791, 0.0016387512304765336, 0.0018405268954880098, 0.0009226809420129832, 0.0013944644152241595, 0.0010531633708845166, 0.0014304383110035868, 0.0006059388123343096, 0.0019211623105494415, 0.0009390630978433525, 0.0020847435054533623, 0.0007376190932358013, 0.0011115807848160759, 0.0010672664160237594, 0.0013503821511917254, 0.0010606801575597596, 0.0009277230676482705, 0.0009469935287009267, 0.0007024954675751574, 0.0010899392312721295, 0.0015469032668453805, 0.0008121157640262562, 0.001593027263879776, 0.0008799316334154676, 0.0012381630127920823, 0.0011665962143417668, 0.0011535773656385787, 0.001020245158168323, 0.0010841748375883874, 0.0008324024212710998, 0.001390155459589818, 0.0009663876365212834, 0.000873203991967089, 0.0014526964548756095, 0.0006503012811984209, 0.0009400769383372629, 0.0013439602985539857, 0.0009475154939162381, 0.0009500894503777518, 0.0013515748467077227, 0.0010936914066619733, 0.001198354286744314, 0.000665288487011019, 0.0010167139253633864, 0.0007097586195039399, 0.001916908275555162, 0.0007998639553347055, 0.0012062670772566514, 0.0007931517902761698, 0.000783462159554748, 0.0006205888108952957, 0.0008774313610047102, 0.0006412955357090515, 0.0005956719328156289, 0.0013227059834581964, 0.0004629381617312046, 0.0015463546630652511, 0.000583286992931629, 0.0013625628095777595, 0.0005145512028213809, 0.0008161809459766921, 0.0009754488162477227, 0.0006962743423440877, 0.0006052089635940159, 0.0013118832892573932, 0.0004563328077304451, 0.0009615588111474234, 0.0005362243254614226, 0.001539867398712565, 0.0005358429762589581, 0.0018369037219706703, 0.00045968885944389244, 0.0012492081424330965, 0.0005465828649261419, 0.0012623424203518558, 0.00041726326761657703, 0.0013651275897727294, 0.00042937661740271487, 0.0017292487763744943, 0.0005414316341664423, 0.002844943500616971, 0.0006585129885934293, 0.0029457687838550877, 0.000406294348923599, 0.0016238277312368155, 0.0004451049573938636, 0.0009561078075100394, 0.0006767582449623767, 0.0006847875603639028, 0.0007222407935735057, 0.0005247596418485045, 0.000989462495507563, 0.0003410752842147999, 0.0013451132622054394, 0.00036515040761407684, 0.001168168505982441, 0.00037085646010168334, 0.00201180500580984, 0.0004642685971168034, 0.0022342548541286413, 0.0004656186656040304, 0.001995312132160453, 0.000605831335312413, 0.0026554392431588736, 0.00036956960855818847, 0.0018242439939914381, 0.0003500709768987316, 0.0014345011783435063, 0.0003470317255157758, 0.00133666763191714, 0.00036518285667304606, 0.0008888783837285112, 0.00038922499344848534, 0.0005787947105572504, 0.0003306929172728868, 0.0005529935553889064, 0.00034379168509450904, 0.0005134013344478957, 0.0006278349182513706, 0.0004059699815971886, 0.0007580789353917627, 0.00031548046150847394, 0.0011741688255878055, 0.0005104977034908883, 0.0016611003426506238, 0.0009513882978353649, 0.002946157200152383, 0.0010359370567397598, 0.002273179015473408, 0.0005886644323575584, 0.0016242070397471681, 0.00040530955062850435, 0.0008734016103998703, 0.0003410161007195711, 0.0005025706829174477, 0.00047095389762783754, 0.00034446415820104233, 0.00043002798167221686, 0.0003296815488925751, 0.0004955742521868909, 0.0003060936201911639, 0.0007585504585329224, 0.00030676486408885787, 0.0006493039990720503, 0.0003543051870485001, 0.0008234672850983985, 0.0003825279589578071, 0.0010937558048788238, 0.0004891851191025446, 0.0008840791689341559, 0.0003264804031727288, 0.0012316414675510982, 0.0003168831497211667, 0.0009117945617831805, 0.0003134861745981171, 0.0008273488732383531, 0.0003360405269845882, 0.0011013107483877854, 0.00031185330590233207, 0.0007902819403063725, 0.00030608422136591635, 0.00040415654588928996, 0.0003187618430649095, 0.0003158845116986948, 0.0003291758715503794, 0.0003386193112579777, 0.0004191552014911876, 0.00032910122878520806, 0.00037827933727599243, 0.00037649443016990144, 0.00047660327297361455, 0.00031677173341021817, 0.0004472155123949051, 0.0003337278715608751, 0.0005325764445040156, 0.0003607386076028514, 0.0005422882489202654, 0.00032576434108812143, 0.00036575718481531916, 0.0003415678785292103, 0.0005345123559784363, 0.0002949231968480436, 0.0004753260873258114, 0.0003037135294802925, 0.00038826733361929655, 0.00030919968369690813, 0.00038527995895813494, 0.0003115702831350705, 0.0003163122763747678, 0.00029611100292052417, 0.0002970294444821775, 0.00035973042865995974, 0.0003385777886518661, 0.00030523552970193764, 0.0004037493935731404, 0.0006551110486993019, 0.0005886733518255984, 0.0003626896034213988, 0.000787747256896075, 0.00085578701520503, 0.0019586830235579435, 0.0016539743108510533, 0.0031130566699978184, 0.0011035760373274302, 0.0016845119980109088, 0.000279047094997676, 0.00028140064986313093, 0.00043541436111006667, 0.0005910771364784416, 0.0003186592263826991, 0.0004144501187564696, 0.00029290685950614074, 0.0004349040682427585, 0.0004567731418372954, 0.00043128349523826996, 0.0003174462917206042, 0.00035327104577685106, 0.0002813518786912455, 0.0002881538068108699, 0.00027929289225379336, 0.00029690407545251003, 0.00031557786004508245, 0.00029587368343901983, 0.0002729308428516721, 0.0003094084814245648, 0.00030492654289392867, 0.00040706175187712204, 0.0002826164195807103, 0.00035908602534190696, 0.00037623803911949783, 0.0005980584058253205, 0.0004514213600058985, 0.00034636225523974965, 0.0003578919670818483, 0.00028619224972584666, 0.000490417519091245, 0.0005615447401343023, 0.0007416681687840644, 0.0004335119293126113, 0.0004918642944711097, 0.00039741717730922737, 0.00043620718369150865, 0.00033505891641492355, 0.00027271285173757114, 0.00027773243388818465, 0.00027732147410621536, 0.0004373516147846685, 0.00041378461002536556, 0.00032900051925988756, 0.0004728547509704881, 0.0007246918565429308, 0.0006002404269940384, 0.0008744518272578716, 0.00038882176672546743, 0.000537872122710242, 0.0003321495828191366, 0.00045088858699754756, 0.00026849591556717367, 0.0003005178022088812, 0.00031252458746380666, 0.00029594838441185216, 0.00029803719371557236, 0.0003459820359507028, 0.0003167316146359286, 0.00034745541736757495, 0.0004177273196332595, 0.0005262720686219194, 0.0005860898698515751, 0.0003484169428702444, 0.00033062344471759657, 0.00039422313805998247, 0.0004061378798831035, 0.00028397941701662014, 0.0002940769259379629, 0.00027523533893091716, 0.0002745368435759755, 0.00027587295249652336, 0.00030502299983602236, 0.0002763179843040074, 0.0003224880475660457, 0.0003804059421835358, 0.0004018149544101428, 0.00042064418769715466, 0.0006368439986973125, 0.000607295857180896, 0.0007361891295980005, 0.0004587337778716841, 0.001425917780793765, 0.0006156924286829855, 0.0013289098792216357, 0.0009218024386106716, 0.00204434574526899, 0.0013825991362168947, 0.00169433349305216, 0.0004160698427928283, 0.00043723753461723816, 0.0003417526056770893, 0.0003023147343329209, 0.000332116152789882, 0.00033996252836111714, 0.0002974757020745207, 0.00029902020126909893, 0.0003542715704123325, 0.0003271574181888033, 0.0003339055761256639, 0.00028439228395547937, 0.00039859639261575304, 0.00039014771498520584, 0.00028316881370675913, 0.0003613820847342996, 0.0004763059242738082, 0.00045687301933546276, 0.00034469977425246993, 0.00038867830709718605, 0.0004543574040700846, 0.0004482824793633293, 0.0003666255438207265, 0.0003349272369900171, 0.00036079525564085036, 0.0004030810326666516, 0.000301127096035463, 0.0003906800069243592, 0.0002914911464733236, 0.00031305799562045755, 0.0002996433005832574, 0.00027834843529169173, 0.00030878166024408797, 0.0003238479223321466, 0.0003421650994021226, 0.00034344040186089626, 0.00032165656482581706, 0.00033051583587246784, 0.00041262866066330494, 0.0003809954710852574, 0.0003423142103094827, 0.00029580126283690333, 0.0004123443436315831, 0.00037034191465114844, 0.00028799939558238666, 0.00035874850993209025, 0.0003602037219988073, 0.00030389559619566975, 0.0003422455595094053, 0.00031353129238328515, 0.00033491042182397316, 0.00048562010531039796, 0.0002684922210926957, 0.00036805568208151003, 0.0003126618787920212, 0.00030590306542923343, 0.0003621099184623317, 0.0003142664345967419, 0.0004391775411718032, 0.0003915319684892893, 0.0005246924650718403, 0.0006904558634714168, 0.00032014544258880266, 0.0006210997440468739, 0.0005028321859700715, 0.0005945416085202904, 0.0007631644291584106, 0.001102771788068554, 0.0010062478909008753, 0.0016280821223250207, 0.0013710390759275898, 0.0019360816325334942, 0.0008442613179795444, 0.001395753036965342, 0.000499715530382031, 0.0011183020713574747, 0.0004887009118272759, 0.0007879375069237807, 0.0003346828743815422, 0.0004657779833959306, 0.00048342153347809524, 0.0005116032450185979, 0.00034098348388557923, 0.0003128107774126179, 0.0005069446325411691, 0.0004548310055671369, 0.0002898897646981127, 0.0004899488104616894, 0.00033663424854988563, 0.00039057515780715384, 0.0004096976412898477, 0.00035578635630800445, 0.0003240158171940814, 0.0004172289114007179, 0.0005880052494296037, 0.0008325201240094269, 0.0006545314031160053, 0.000801658394801266, 0.000654812202008222, 0.0008757423801238046, 0.0005684931358486853, 0.0010994883281562257, 0.00040616800405961624, 0.0009597682613222038, 0.0004932136490584954, 0.0007143984069390332, 0.0003911140785716912, 0.0007145338801338392, 0.0005390339262221995, 0.0007433146923123037, 0.0009316368018249597, 0.0013854925192016013, 0.0008630126805441893, 0.0014373454648782225, 0.0012746144082698533, 0.0012832628015209647, 0.0010519402678576572, 0.0009152843233417062, 0.000523482180570307, 0.0006311505430323236, 0.00035788487601915705, 0.0004353371024241342, 0.0003552970558624057, 0.0004372495870270273, 0.0003082668032113682, 0.0004693402990917949, 0.00039229490314884223, 0.00031037097933756956, 0.00028984096271040687, 0.0002972368452259723, 0.00032749234849367947, 0.0003233581014415797, 0.00035745285533587723, 0.0002764029606409809, 0.00030396695878794967, 0.00026987172211246453, 0.0003205467775628409, 0.0002828783745987012, 0.00031588256345404424, 0.00032406426308786166, 0.00030990896116503896, 0.00030663493431775887, 0.00035528592107927096, 0.00029599419384099105, 0.00040356378646238763, 0.0004122291198548149, 0.00031872604877742776, 0.0003814529079724761, 0.00038719489170676647, 0.00039236378335558316, 0.0003980449469321791, 0.0003699966747423305, 0.0003965098123230478, 0.0003323561840635889, 0.00030607372344307164, 0.0004743411041357938, 0.00038160946603645296, 0.00042960983838009485, 0.0003523768939296989, 0.0003488655886886751, 0.000349781962166376, 0.0006265297792304088, 0.000509623097433873, 0.0007202718680834069, 0.0006267763075062676, 0.0007707457989454269, 0.0009517798179705791, 0.0007920922054087414, 0.0010405516770654632, 0.0010155174771652503, 0.0011003735879271785, 0.0015465083586819032, 0.0005226484191713526, 0.0008727911695399705, 0.0006682255890850416, 0.0009324725936440861, 0.0006485028493711177, 0.0007823980276418082, 0.0003713819400325198, 0.00040958907373030395, 0.0004014738301253494, 0.00031097809551283717, 0.0006149140775532407, 0.00030036752030034275, 0.000574560500407482, 0.00032053086975151123, 0.000524212934953325, 0.0004024164638180724, 0.0005796683596118408, 0.000573040871292024, 0.0007994249736999764, 0.0003079011289895896, 0.0004321084535845062, 0.0003672879846657024, 0.00039321652558796545, 0.0003366978489793837, 0.0003491626018384362, 0.00045964036903837146, 0.00030327635057106176, 0.0005467458395287395, 0.0009082459728233516, 0.0010698452482328696, 0.0007473920593517559, 0.0010714077609865105, 0.0004973403410986066, 0.0007452454609686838, 0.0003008912728332421, 0.0003470642670222065, 0.0007074161206700784, 0.0004641044446650673, 0.0004231994372436448, 0.0006599831942688016, 0.00040846346425549946, 0.0004481642972677946, 0.00033913746558348923, 0.00043602909564095387, 0.0003266041954595815, 0.0004163584877353381, 0.0005371542818679967, 0.0006589958348366268, 0.00033749333370531746, 0.0005412214805426844, 0.0003597133875112323, 0.00034708826227442305, 0.00037324984441511333, 0.00043111036339884293, 0.0003025480443337823, 0.000293469347525388, 0.00038244415019803187, 0.00041619202067308566, 0.0006584544967421714, 0.000863559334367678, 0.0009401187382857589, 0.0008608834100681741, 0.0014346811427351307, 0.0006318617430652547, 0.0007891653187792091, 0.0003969560733393711, 0.00032809329123291024, 0.0003967969130505534, 0.0006073003100669559, 0.000605364645119099, 0.00030285278540652464, 0.0004129555309191346, 0.0004154433297705563, 0.00043770038824090184, 0.000307332443566445, 0.0003548214787288624, 0.0003437418114010464, 0.0003205666058313321, 0.0003409388557295589, 0.00035394400508855195, 0.0003166177501792417, 0.00030747792163096806, 0.00036532225717297374, 0.00032289228607516955, 0.000411942443700836, 0.0003359510344179238, 0.00031788707436884153, 0.0002866232295191902, 0.00033653360750416625, 0.0004607547101948191, 0.00041223149609697214, 0.0002831083564909504, 0.000332965816864196, 0.0004193374941892484, 0.00038439619546646583, 0.0002769369851140415, 0.00034533727996270447, 0.000324885210241465, 0.0002963991548099062, 0.0003920210498001646, 0.00042658753912238516, 0.00030308199690326173, 0.00028808188610984125, 0.0004483337842804544, 0.0004165828063645784, 0.00031433920102084386, 0.0003267210045391146, 0.0003492582918089979, 0.00040756666224778574, 0.0004817321691114236, 0.00032110114732538075, 0.0003968614687704865, 0.00043305606060825726, 0.00036622748901957977, 0.0003364356919465696, 0.0004402171436916379, 0.0003737136584651821, 0.0003692020066356396, 0.0003881151000421275, 0.0003137080861693796, 0.00030835880897939205, 0.00038170069113702457, 0.0003987379194072941, 0.00035591423853903134, 0.0003775488174356082, 0.0005586486487813733, 0.0004966840531457873, 0.00042751179802614977, 0.0005497460198753021, 0.0008548358181381927, 0.0008578636847874697, 0.0009860524904284189, 0.0010641182991949951, 0.001004588302320746, 0.0005554210545276018, 0.0004944567233050132, 0.00032061524004401527, 0.00031255876220872295, 0.000420643448117463, 0.00031608455088537405, 0.00037244119790985305, 0.0003168144989210893, 0.0004016436116002938, 0.00038198196425047866, 0.00040297234184382595, 0.00035224145497469344, 0.00035841709263074924, 0.00041800776414354057, 0.0004522673861014054, 0.0004319018300841836, 0.0003368264536702019, 0.0003504712025032324, 0.0003072324119891752, 0.00038448602700715554, 0.00039518044521922577, 0.00034132822389330934, 0.0006271798047237098, 0.0004424826817258316, 0.0005069952954620342, 0.00045106191571582765, 0.0005919127605225452, 0.0007481318145223401, 0.0008885350133128026, 0.0009109787779914983, 0.0008897992956917733, 0.0009905632092233967, 0.00040701408665079405, 0.0005279691917273928, 0.0004162247813142398, 0.0003307782017680652, 0.0004024699754903422, 0.0003850526238024673, 0.0003496423664995853, 0.0004429172430023113, 0.0004290475455277106, 0.00047230055583093097, 0.00038552940960096964, 0.00030646228697150946, 0.00046296949114869624, 0.0004544179708532551, 0.0002964461386642035, 0.0003135476795518223, 0.00037331654525855006, 0.0003447082400431528, 0.00034028556033530654, 0.00029056236449190797, 0.0003707225482417818, 0.0004615493063979289, 0.0003846344496945248, 0.00033782241414027176, 0.00042545876246603094, 0.00041199563865495077, 0.0003334658891510438, 0.00038260902853353936, 0.0004122827462304164, 0.00040651708225007444, 0.00042579792823423357, 0.00035871787044657944, 0.0004397306851494838, 0.00033568405984517406, 0.00042297845870694695, 0.0003370291738332633, 0.0003815580926397268, 0.00034164766068844237, 0.00035252341288415827, 0.0003358692012946395, 0.0003999711069114068, 0.00031654165222254745, 0.0003191731486688642, 0.0004264587529606241, 0.00039662511142737726, 0.000294775321997483, 0.00033565596266485313, 0.0004476294031038004, 0.0003297149053062586, 0.000387025490293608, 0.0003593627445618896, 0.0004490980851080488, 0.0004424866210148834, 0.0006244690225952689, 0.0004966656492529985, 0.0011965889785000507, 0.0007670268181862091, 0.0009315568022429943, 0.0004017252358607948, 0.0004388702868977014, 0.00032611345351838013, 0.00037920976276783385, 0.00045975872918086895, 0.0004035257802837912, 0.000419555396279868, 0.0004747009849833215, 0.0005253605640438549, 0.00039000159321243274, 0.0003523578360567198, 0.0003564668175600031, 0.00030930570039131185, 0.0004104698925991269, 0.0003283974022933227, 0.0003386835485477658, 0.00031311382703921376, 0.00028993013342294623, 0.00031145964064361415, 0.0003313865848159527, 0.0003821845440303578, 0.00027013170491794455, 0.0003070324960657779, 0.0003597069743965917, 0.0003609695704653859, 0.0004653350727440899, 0.000549880726098576, 0.0003268345642615767, 0.00031801763072829037, 0.00038871960029663406, 0.0003555661396068685, 0.0003419725690037012, 0.00028214544427635917, 0.0003277966855367755, 0.0004078472950769698, 0.00038433587863383927, 0.00034267061924123587, 0.0003878658582620761, 0.00033479025382000734, 0.0003759696915307466, 0.00035475778927588286, 0.000400538878131877, 0.0002970793626873809, 0.00031092846149797826, 0.0003794877146206358, 0.00047316339195651165, 0.00044987817733165096, 0.0007702476783272098, 0.0008689553249175387, 0.001080651384066133, 0.0006808197529822149, 0.0009076828410958542, 0.0004130409215576947, 0.0005241483997772722, 0.00041389890590353925, 0.0004542472169679754, 0.0002879046369343996, 0.0003168064114802024, 0.00045041945379446536, 0.0003639536546817159, 0.0003049557083560263, 0.000313035082345938, 0.00040182116550996024, 0.0004320533377775813, 0.00038771403898649355, 0.00031026689034393607, 0.0004064327256534906, 0.00044614988762666196, 0.00030392385087907314, 0.0003753176287693136, 0.0005081707392545307, 0.0003479554057669114, 0.0005455813986961456, 0.0004443361848483191, 0.0005648077058140188, 0.0005622021853923798, 0.00046384510556783746, 0.0006696804125300225, 0.0004946538760765072, 0.0007360557450310272, 0.0004981510163120487, 0.0007007787113680559, 0.00037944351617411217, 0.0006430174278862336, 0.0005102867281119175, 0.0007450426928699017, 0.0002755612230804913, 0.00042355387225089707, 0.00037066891501822015, 0.000411254312733517, 0.00032504979411468785, 0.00030443663982784045, 0.00040503195486962795, 0.0002894503893056775, 0.0004285476855276262, 0.00031704354949076385, 0.0005393397501286338, 0.0003483965136932538, 0.0006766399327556, 0.00046398280092569837, 0.0008904364863958429, 0.0005708251247757717, 0.0010455359211739373, 0.0006965631362297298, 0.0009662556626340922, 0.0003744021797662272, 0.00031664143042529333, 0.0004056028898476678, 0.00033050829284440945, 0.0003918499398209593, 0.0003282671849078992, 0.0003117698600844425, 0.0004133215680827989, 0.00037727987065034756, 0.0003782871918862357, 0.00027492452371755946, 0.0003700828289284426, 0.0003071264363825321, 0.0003308909465832745, 0.0003613089074325912, 0.0002957986229482819, 0.00032015371492461245, 0.0003604584318750045, 0.00031292372766663045, 0.0003015638246913167, 0.00031097553779973705, 0.0002965776331941871, 0.0003528181353912634, 0.0003045326619244674, 0.0004391996737788705, 0.0002770268371986116, 0.00034621781121720285, 0.0003724290119648418, 0.00036501657792969663, 0.00036210929700995195, 0.00026247014894204983, 0.0003745243062867838, 0.0003006706657983801, 0.00030076605445869705, 0.0002607587204479119, 0.0003328441799727871, 0.00032192791182109536, 0.00026919590035343874, 0.0003080937038997517, 0.0003484895226874334, 0.0004328222027705873, 0.00028475294889443936, 0.000362337998333661, 0.00040581087951603183, 0.00046200711992295347, 0.00033512059941559155, 0.00036683071212952626, 0.00034733046777546406, 0.0003002291778102517, 0.0002946410540436559, 0.000299316954196376, 0.00033655663719400764, 0.0003249212852953111, 0.0002950904377297882, 0.0003175293574767078, 0.00040071799680042793, 0.0003362729159348151, 0.0002637536038973314, 0.0002805334241951213, 0.0003439654315383557, 0.0003032445332364124, 0.0005285779822289067, 0.00039557283162139356, 0.000560199492610991, 0.0005668991995181012, 0.0007384727873346385, 0.0005449099767514888, 0.0005923985188607784, 0.0003418661482796511, 0.00031993177253752947, 0.00034621964647051166, 0.0003387429272098576]\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var6(t-2)</th>\n",
       "      <th>var7(t-2)</th>\n",
       "      <th>var8(t-2)</th>\n",
       "      <th>var9(t-2)</th>\n",
       "      <th>var10(t-2)</th>\n",
       "      <th>...</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "      <th>var9(t)</th>\n",
       "      <th>var10(t)</th>\n",
       "      <th>var11(t)</th>\n",
       "      <th>var11(t+2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.812668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.364549</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>0.777328</td>\n",
       "      <td>0.287966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711032</td>\n",
       "      <td>0.191277</td>\n",
       "      <td>0.300492</td>\n",
       "      <td>0.315271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005649</td>\n",
       "      <td>0.784367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.364549</td>\n",
       "      <td>0.022815</td>\n",
       "      <td>0.905870</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011540</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.254335</td>\n",
       "      <td>0.295566</td>\n",
       "      <td>0.300492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007190</td>\n",
       "      <td>0.762803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.371238</td>\n",
       "      <td>0.035178</td>\n",
       "      <td>0.925607</td>\n",
       "      <td>0.197583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011813</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.364549</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>0.777328</td>\n",
       "      <td>0.287966</td>\n",
       "      <td>0.315271</td>\n",
       "      <td>0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.765499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.016473</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>0.294314</td>\n",
       "      <td>0.043531</td>\n",
       "      <td>0.885121</td>\n",
       "      <td>0.230688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012940</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.364549</td>\n",
       "      <td>0.022815</td>\n",
       "      <td>0.905870</td>\n",
       "      <td>0.213873</td>\n",
       "      <td>0.300492</td>\n",
       "      <td>0.266010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010785</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.371238</td>\n",
       "      <td>0.035178</td>\n",
       "      <td>0.925607</td>\n",
       "      <td>0.197583</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.246305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012839</td>\n",
       "      <td>0.791105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0.254181</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.941802</td>\n",
       "      <td>0.276406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.016473</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>0.294314</td>\n",
       "      <td>0.043531</td>\n",
       "      <td>0.885121</td>\n",
       "      <td>0.230688</td>\n",
       "      <td>0.266010</td>\n",
       "      <td>0.216749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017461</td>\n",
       "      <td>0.842318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.049833</td>\n",
       "      <td>0.143813</td>\n",
       "      <td>0.063295</td>\n",
       "      <td>0.941296</td>\n",
       "      <td>0.368891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.030211</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>0.051047</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.252233</td>\n",
       "      <td>0.246305</td>\n",
       "      <td>0.152709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.870620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>0.055399</td>\n",
       "      <td>0.163880</td>\n",
       "      <td>0.076473</td>\n",
       "      <td>0.790486</td>\n",
       "      <td>0.442459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.017281</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0.254181</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.941802</td>\n",
       "      <td>0.276406</td>\n",
       "      <td>0.216749</td>\n",
       "      <td>0.152709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.026705</td>\n",
       "      <td>0.939353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.012293</td>\n",
       "      <td>0.052701</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.082993</td>\n",
       "      <td>0.692814</td>\n",
       "      <td>0.562796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.049833</td>\n",
       "      <td>0.143813</td>\n",
       "      <td>0.063295</td>\n",
       "      <td>0.941296</td>\n",
       "      <td>0.368891</td>\n",
       "      <td>0.152709</td>\n",
       "      <td>0.133005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.032354</td>\n",
       "      <td>0.959569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.123746</td>\n",
       "      <td>0.095893</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.010031</td>\n",
       "      <td>0.055399</td>\n",
       "      <td>0.163880</td>\n",
       "      <td>0.076473</td>\n",
       "      <td>0.790486</td>\n",
       "      <td>0.442459</td>\n",
       "      <td>0.152709</td>\n",
       "      <td>0.128079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.040057</td>\n",
       "      <td>0.894879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.053166</td>\n",
       "      <td>0.177257</td>\n",
       "      <td>0.107006</td>\n",
       "      <td>0.531377</td>\n",
       "      <td>0.487651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.012293</td>\n",
       "      <td>0.052701</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.082993</td>\n",
       "      <td>0.692814</td>\n",
       "      <td>0.562796</td>\n",
       "      <td>0.133005</td>\n",
       "      <td>0.182266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.046220</td>\n",
       "      <td>0.840970</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.054465</td>\n",
       "      <td>0.214047</td>\n",
       "      <td>0.109850</td>\n",
       "      <td>0.510121</td>\n",
       "      <td>0.623226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.123746</td>\n",
       "      <td>0.095893</td>\n",
       "      <td>0.516700</td>\n",
       "      <td>0.519180</td>\n",
       "      <td>0.128079</td>\n",
       "      <td>0.192118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.054436</td>\n",
       "      <td>0.826146</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.119148</td>\n",
       "      <td>0.326417</td>\n",
       "      <td>0.592223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.053166</td>\n",
       "      <td>0.177257</td>\n",
       "      <td>0.107006</td>\n",
       "      <td>0.531377</td>\n",
       "      <td>0.487651</td>\n",
       "      <td>0.182266</td>\n",
       "      <td>0.256157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.061112</td>\n",
       "      <td>0.854447</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.047704</td>\n",
       "      <td>0.431439</td>\n",
       "      <td>0.125190</td>\n",
       "      <td>0.237854</td>\n",
       "      <td>0.444561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>0.054465</td>\n",
       "      <td>0.214047</td>\n",
       "      <td>0.109850</td>\n",
       "      <td>0.510121</td>\n",
       "      <td>0.623226</td>\n",
       "      <td>0.192118</td>\n",
       "      <td>0.399015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.065734</td>\n",
       "      <td>0.977089</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.041799</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.129844</td>\n",
       "      <td>0.246964</td>\n",
       "      <td>0.287441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.119148</td>\n",
       "      <td>0.326417</td>\n",
       "      <td>0.592223</td>\n",
       "      <td>0.256157</td>\n",
       "      <td>0.645320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.069329</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.045519</td>\n",
       "      <td>0.752509</td>\n",
       "      <td>0.138128</td>\n",
       "      <td>0.294534</td>\n",
       "      <td>0.287966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.047704</td>\n",
       "      <td>0.431439</td>\n",
       "      <td>0.125190</td>\n",
       "      <td>0.237854</td>\n",
       "      <td>0.444561</td>\n",
       "      <td>0.399015</td>\n",
       "      <td>0.733990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.074978</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.729097</td>\n",
       "      <td>0.145199</td>\n",
       "      <td>0.384109</td>\n",
       "      <td>0.324225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.041799</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.129844</td>\n",
       "      <td>0.246964</td>\n",
       "      <td>0.287441</td>\n",
       "      <td>0.645320</td>\n",
       "      <td>0.674876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.080114</td>\n",
       "      <td>0.983827</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.675585</td>\n",
       "      <td>0.147704</td>\n",
       "      <td>0.412955</td>\n",
       "      <td>0.269574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.045519</td>\n",
       "      <td>0.752509</td>\n",
       "      <td>0.138128</td>\n",
       "      <td>0.294534</td>\n",
       "      <td>0.287966</td>\n",
       "      <td>0.733990</td>\n",
       "      <td>0.650246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.082168</td>\n",
       "      <td>0.912399</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>0.071551</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>0.157988</td>\n",
       "      <td>0.463563</td>\n",
       "      <td>0.250657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.729097</td>\n",
       "      <td>0.145199</td>\n",
       "      <td>0.384109</td>\n",
       "      <td>0.324225</td>\n",
       "      <td>0.674876</td>\n",
       "      <td>0.566502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.085763</td>\n",
       "      <td>0.885445</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.075425</td>\n",
       "      <td>0.551840</td>\n",
       "      <td>0.168782</td>\n",
       "      <td>0.501012</td>\n",
       "      <td>0.284288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.675585</td>\n",
       "      <td>0.147704</td>\n",
       "      <td>0.412955</td>\n",
       "      <td>0.269574</td>\n",
       "      <td>0.650246</td>\n",
       "      <td>0.541872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.090385</td>\n",
       "      <td>0.834232</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.078051</td>\n",
       "      <td>0.548495</td>\n",
       "      <td>0.179891</td>\n",
       "      <td>0.614879</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.007737</td>\n",
       "      <td>0.071551</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>0.157988</td>\n",
       "      <td>0.463563</td>\n",
       "      <td>0.250657</td>\n",
       "      <td>0.566502</td>\n",
       "      <td>0.566502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.094493</td>\n",
       "      <td>0.840970</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.081948</td>\n",
       "      <td>0.581940</td>\n",
       "      <td>0.186508</td>\n",
       "      <td>0.657389</td>\n",
       "      <td>0.240673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.075425</td>\n",
       "      <td>0.551840</td>\n",
       "      <td>0.168782</td>\n",
       "      <td>0.501012</td>\n",
       "      <td>0.284288</td>\n",
       "      <td>0.541872</td>\n",
       "      <td>0.571428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.100656</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.088034</td>\n",
       "      <td>0.528428</td>\n",
       "      <td>0.194852</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.242775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.078051</td>\n",
       "      <td>0.548495</td>\n",
       "      <td>0.179891</td>\n",
       "      <td>0.614879</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>0.566502</td>\n",
       "      <td>0.532019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.105278</td>\n",
       "      <td>0.757412</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.098419</td>\n",
       "      <td>0.474917</td>\n",
       "      <td>0.208651</td>\n",
       "      <td>0.702429</td>\n",
       "      <td>0.279559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.088327</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.081948</td>\n",
       "      <td>0.581940</td>\n",
       "      <td>0.186508</td>\n",
       "      <td>0.657389</td>\n",
       "      <td>0.240673</td>\n",
       "      <td>0.571428</td>\n",
       "      <td>0.477832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.109386</td>\n",
       "      <td>0.766846</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.107964</td>\n",
       "      <td>0.444816</td>\n",
       "      <td>0.216263</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.318970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.088034</td>\n",
       "      <td>0.528428</td>\n",
       "      <td>0.194852</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.242775</td>\n",
       "      <td>0.532019</td>\n",
       "      <td>0.443350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.114522</td>\n",
       "      <td>0.691375</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.108021</td>\n",
       "      <td>0.371238</td>\n",
       "      <td>0.230849</td>\n",
       "      <td>0.828441</td>\n",
       "      <td>0.341040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.098419</td>\n",
       "      <td>0.474917</td>\n",
       "      <td>0.208651</td>\n",
       "      <td>0.702429</td>\n",
       "      <td>0.279559</td>\n",
       "      <td>0.477832</td>\n",
       "      <td>0.408867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.120171</td>\n",
       "      <td>0.665768</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.109932</td>\n",
       "      <td>0.391305</td>\n",
       "      <td>0.239740</td>\n",
       "      <td>0.772773</td>\n",
       "      <td>0.353127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.107964</td>\n",
       "      <td>0.444816</td>\n",
       "      <td>0.216263</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.318970</td>\n",
       "      <td>0.443350</td>\n",
       "      <td>0.359606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.128388</td>\n",
       "      <td>0.749326</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.131357</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>0.253812</td>\n",
       "      <td>0.792004</td>\n",
       "      <td>0.395691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123894</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.108021</td>\n",
       "      <td>0.371238</td>\n",
       "      <td>0.230849</td>\n",
       "      <td>0.828441</td>\n",
       "      <td>0.341040</td>\n",
       "      <td>0.408867</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.136091</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.017095</td>\n",
       "      <td>0.136955</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.262443</td>\n",
       "      <td>0.741397</td>\n",
       "      <td>0.440357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.109932</td>\n",
       "      <td>0.391305</td>\n",
       "      <td>0.239740</td>\n",
       "      <td>0.772773</td>\n",
       "      <td>0.353127</td>\n",
       "      <td>0.359606</td>\n",
       "      <td>0.315271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.143280</td>\n",
       "      <td>0.822102</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.144708</td>\n",
       "      <td>0.277592</td>\n",
       "      <td>0.275159</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.523384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185841</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.131357</td>\n",
       "      <td>0.297659</td>\n",
       "      <td>0.253812</td>\n",
       "      <td>0.792004</td>\n",
       "      <td>0.395691</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.295566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.836059</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.615095</td>\n",
       "      <td>0.487643</td>\n",
       "      <td>0.891301</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.943360</td>\n",
       "      <td>0.614879</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.615095</td>\n",
       "      <td>0.505654</td>\n",
       "      <td>0.886144</td>\n",
       "      <td>0.150502</td>\n",
       "      <td>0.929066</td>\n",
       "      <td>0.740891</td>\n",
       "      <td>0.237520</td>\n",
       "      <td>0.123153</td>\n",
       "      <td>0.108374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.837600</td>\n",
       "      <td>0.118598</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.615095</td>\n",
       "      <td>0.522368</td>\n",
       "      <td>0.901730</td>\n",
       "      <td>0.133779</td>\n",
       "      <td>0.954584</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.271676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.615095</td>\n",
       "      <td>0.468529</td>\n",
       "      <td>0.890110</td>\n",
       "      <td>0.117057</td>\n",
       "      <td>0.936641</td>\n",
       "      <td>0.656377</td>\n",
       "      <td>0.258539</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.078818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.848837</td>\n",
       "      <td>0.084906</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.523774</td>\n",
       "      <td>0.902560</td>\n",
       "      <td>0.100335</td>\n",
       "      <td>0.963840</td>\n",
       "      <td>0.501012</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.615095</td>\n",
       "      <td>0.487643</td>\n",
       "      <td>0.891301</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>0.943360</td>\n",
       "      <td>0.614879</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>0.108374</td>\n",
       "      <td>0.088670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.858830</td>\n",
       "      <td>0.133423</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.563974</td>\n",
       "      <td>0.912838</td>\n",
       "      <td>0.120402</td>\n",
       "      <td>0.959062</td>\n",
       "      <td>0.477227</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.615095</td>\n",
       "      <td>0.522368</td>\n",
       "      <td>0.901730</td>\n",
       "      <td>0.133779</td>\n",
       "      <td>0.954584</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.271676</td>\n",
       "      <td>0.078818</td>\n",
       "      <td>0.088670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.865573</td>\n",
       "      <td>0.211590</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.585729</td>\n",
       "      <td>0.921944</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.964021</td>\n",
       "      <td>0.343117</td>\n",
       "      <td>0.255912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.523774</td>\n",
       "      <td>0.902560</td>\n",
       "      <td>0.100335</td>\n",
       "      <td>0.963840</td>\n",
       "      <td>0.501012</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.088670</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.880456</td>\n",
       "      <td>0.258760</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.574832</td>\n",
       "      <td>0.926809</td>\n",
       "      <td>0.200669</td>\n",
       "      <td>0.971981</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.219128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.563974</td>\n",
       "      <td>0.912838</td>\n",
       "      <td>0.120402</td>\n",
       "      <td>0.959062</td>\n",
       "      <td>0.477227</td>\n",
       "      <td>0.272202</td>\n",
       "      <td>0.088670</td>\n",
       "      <td>0.133005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.890742</td>\n",
       "      <td>0.176550</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.492219</td>\n",
       "      <td>0.917471</td>\n",
       "      <td>0.244147</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.253036</td>\n",
       "      <td>0.133473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.585729</td>\n",
       "      <td>0.921944</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.964021</td>\n",
       "      <td>0.343117</td>\n",
       "      <td>0.255912</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.162561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.911361</td>\n",
       "      <td>0.194070</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.495291</td>\n",
       "      <td>0.924215</td>\n",
       "      <td>0.324415</td>\n",
       "      <td>0.978690</td>\n",
       "      <td>0.273785</td>\n",
       "      <td>0.101419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.468326</td>\n",
       "      <td>0.574832</td>\n",
       "      <td>0.926809</td>\n",
       "      <td>0.200669</td>\n",
       "      <td>0.971981</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.219128</td>\n",
       "      <td>0.133005</td>\n",
       "      <td>0.211823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.918623</td>\n",
       "      <td>0.202156</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.448658</td>\n",
       "      <td>0.917672</td>\n",
       "      <td>0.431439</td>\n",
       "      <td>0.984687</td>\n",
       "      <td>0.159413</td>\n",
       "      <td>0.091435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.492219</td>\n",
       "      <td>0.917471</td>\n",
       "      <td>0.244147</td>\n",
       "      <td>0.975167</td>\n",
       "      <td>0.253036</td>\n",
       "      <td>0.133473</td>\n",
       "      <td>0.162561</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.880214</td>\n",
       "      <td>0.278976</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.336796</td>\n",
       "      <td>0.888961</td>\n",
       "      <td>0.508361</td>\n",
       "      <td>0.986956</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.495291</td>\n",
       "      <td>0.924215</td>\n",
       "      <td>0.324415</td>\n",
       "      <td>0.978690</td>\n",
       "      <td>0.273785</td>\n",
       "      <td>0.101419</td>\n",
       "      <td>0.211823</td>\n",
       "      <td>0.438423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.885848</td>\n",
       "      <td>0.475741</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.326072</td>\n",
       "      <td>0.870532</td>\n",
       "      <td>0.678930</td>\n",
       "      <td>0.980988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.448658</td>\n",
       "      <td>0.917672</td>\n",
       "      <td>0.431439</td>\n",
       "      <td>0.984687</td>\n",
       "      <td>0.159413</td>\n",
       "      <td>0.091435</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.645320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.897634</td>\n",
       "      <td>0.505391</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.393913</td>\n",
       "      <td>0.868757</td>\n",
       "      <td>0.839465</td>\n",
       "      <td>0.986039</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.505899</td>\n",
       "      <td>0.336796</td>\n",
       "      <td>0.888961</td>\n",
       "      <td>0.508361</td>\n",
       "      <td>0.986956</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.438423</td>\n",
       "      <td>0.798029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.903134</td>\n",
       "      <td>0.485175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.457533</td>\n",
       "      <td>0.873038</td>\n",
       "      <td>0.909699</td>\n",
       "      <td>0.979853</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.326072</td>\n",
       "      <td>0.870532</td>\n",
       "      <td>0.678930</td>\n",
       "      <td>0.980988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.645320</td>\n",
       "      <td>0.847290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.910766</td>\n",
       "      <td>0.454178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.490016</td>\n",
       "      <td>0.885760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971226</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.393913</td>\n",
       "      <td>0.868757</td>\n",
       "      <td>0.839465</td>\n",
       "      <td>0.986039</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.007357</td>\n",
       "      <td>0.798029</td>\n",
       "      <td>0.891625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.910796</td>\n",
       "      <td>0.435310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.518532</td>\n",
       "      <td>0.891503</td>\n",
       "      <td>0.973245</td>\n",
       "      <td>0.972889</td>\n",
       "      <td>0.066296</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.457533</td>\n",
       "      <td>0.873038</td>\n",
       "      <td>0.909699</td>\n",
       "      <td>0.979853</td>\n",
       "      <td>0.040486</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.847290</td>\n",
       "      <td>0.876847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.910005</td>\n",
       "      <td>0.419137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.454615</td>\n",
       "      <td>0.904376</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.978432</td>\n",
       "      <td>0.015688</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522170</td>\n",
       "      <td>0.490016</td>\n",
       "      <td>0.885760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971226</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.891625</td>\n",
       "      <td>0.847290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.915531</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.512036</td>\n",
       "      <td>0.913457</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.975759</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.518532</td>\n",
       "      <td>0.891503</td>\n",
       "      <td>0.973245</td>\n",
       "      <td>0.972889</td>\n",
       "      <td>0.066296</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.822660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.926814</td>\n",
       "      <td>0.467655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.574963</td>\n",
       "      <td>0.921993</td>\n",
       "      <td>0.933111</td>\n",
       "      <td>0.974176</td>\n",
       "      <td>0.017206</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.454615</td>\n",
       "      <td>0.904376</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.978432</td>\n",
       "      <td>0.015688</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.847290</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.940033</td>\n",
       "      <td>0.424528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.603344</td>\n",
       "      <td>0.916728</td>\n",
       "      <td>0.876254</td>\n",
       "      <td>0.966966</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.512036</td>\n",
       "      <td>0.913457</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.975759</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.822660</td>\n",
       "      <td>0.758620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.949071</td>\n",
       "      <td>0.421833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.601672</td>\n",
       "      <td>0.926605</td>\n",
       "      <td>0.829431</td>\n",
       "      <td>0.969351</td>\n",
       "      <td>0.052126</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461602</td>\n",
       "      <td>0.574963</td>\n",
       "      <td>0.921993</td>\n",
       "      <td>0.933111</td>\n",
       "      <td>0.974176</td>\n",
       "      <td>0.017206</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.763546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.958269</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.522392</td>\n",
       "      <td>0.929488</td>\n",
       "      <td>0.829431</td>\n",
       "      <td>0.973106</td>\n",
       "      <td>0.073381</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.603344</td>\n",
       "      <td>0.916728</td>\n",
       "      <td>0.876254</td>\n",
       "      <td>0.966966</td>\n",
       "      <td>0.048077</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.758620</td>\n",
       "      <td>0.753694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.961484</td>\n",
       "      <td>0.439353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.564399</td>\n",
       "      <td>0.944918</td>\n",
       "      <td>0.775920</td>\n",
       "      <td>0.977297</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.601672</td>\n",
       "      <td>0.926605</td>\n",
       "      <td>0.829431</td>\n",
       "      <td>0.969351</td>\n",
       "      <td>0.052126</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.763546</td>\n",
       "      <td>0.699507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.969618</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.672082</td>\n",
       "      <td>0.954114</td>\n",
       "      <td>0.722409</td>\n",
       "      <td>0.985247</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.522392</td>\n",
       "      <td>0.929488</td>\n",
       "      <td>0.829431</td>\n",
       "      <td>0.973106</td>\n",
       "      <td>0.073381</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.753694</td>\n",
       "      <td>0.645320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.968165</td>\n",
       "      <td>0.467655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.637434</td>\n",
       "      <td>0.960627</td>\n",
       "      <td>0.725753</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.127530</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474936</td>\n",
       "      <td>0.564399</td>\n",
       "      <td>0.944918</td>\n",
       "      <td>0.775920</td>\n",
       "      <td>0.977297</td>\n",
       "      <td>0.095648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.699507</td>\n",
       "      <td>0.635468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.980958</td>\n",
       "      <td>0.482480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.677541</td>\n",
       "      <td>0.962305</td>\n",
       "      <td>0.712375</td>\n",
       "      <td>0.990202</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.672082</td>\n",
       "      <td>0.954114</td>\n",
       "      <td>0.722409</td>\n",
       "      <td>0.985247</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.645320</td>\n",
       "      <td>0.610837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.982015</td>\n",
       "      <td>0.498652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.656129</td>\n",
       "      <td>0.962620</td>\n",
       "      <td>0.709030</td>\n",
       "      <td>0.997838</td>\n",
       "      <td>0.238360</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.637434</td>\n",
       "      <td>0.960627</td>\n",
       "      <td>0.725753</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.127530</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.635468</td>\n",
       "      <td>0.576354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.987552</td>\n",
       "      <td>0.493261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425841</td>\n",
       "      <td>0.711033</td>\n",
       "      <td>0.972440</td>\n",
       "      <td>0.735786</td>\n",
       "      <td>0.995213</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.677541</td>\n",
       "      <td>0.962305</td>\n",
       "      <td>0.712375</td>\n",
       "      <td>0.990202</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.610837</td>\n",
       "      <td>0.566502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.987937</td>\n",
       "      <td>0.521563</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425841</td>\n",
       "      <td>0.741081</td>\n",
       "      <td>0.975148</td>\n",
       "      <td>0.715719</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>0.175607</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454052</td>\n",
       "      <td>0.656129</td>\n",
       "      <td>0.962620</td>\n",
       "      <td>0.709030</td>\n",
       "      <td>0.997838</td>\n",
       "      <td>0.238360</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.576354</td>\n",
       "      <td>0.536945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.994397</td>\n",
       "      <td>0.526954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425841</td>\n",
       "      <td>0.822599</td>\n",
       "      <td>0.986077</td>\n",
       "      <td>0.628762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179656</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425841</td>\n",
       "      <td>0.711033</td>\n",
       "      <td>0.972440</td>\n",
       "      <td>0.735786</td>\n",
       "      <td>0.995213</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.566502</td>\n",
       "      <td>0.497537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425841</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511706</td>\n",
       "      <td>0.991671</td>\n",
       "      <td>0.255567</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425841</td>\n",
       "      <td>0.741081</td>\n",
       "      <td>0.975148</td>\n",
       "      <td>0.715719</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>0.175607</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.536945</td>\n",
       "      <td>0.448276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var6(t-2)  \\\n",
       "0     0.004108   0.812668   0.000000   0.000000   0.011813   0.005986   \n",
       "1     0.005649   0.784367   0.000000   0.000000   0.012940   0.007292   \n",
       "2     0.007190   0.762803   0.000000   0.009757   0.016043   0.015337   \n",
       "3     0.008730   0.765499   0.000000   0.009757   0.016473   0.025907   \n",
       "4     0.010785   0.783019   0.000000   0.009757   0.016369   0.030211   \n",
       "5     0.012839   0.791105   0.000000   0.009757   0.017281   0.038038   \n",
       "6     0.017461   0.842318   0.000000   0.019255   0.013679   0.049833   \n",
       "7     0.021569   0.870620   0.000000   0.019255   0.010031   0.055399   \n",
       "8     0.026705   0.939353   0.000000   0.019255   0.012293   0.052701   \n",
       "9     0.032354   0.959569   0.000000   0.019255   0.008085   0.057306   \n",
       "10    0.040057   0.894879   0.000000   0.016098   0.008102   0.053166   \n",
       "11    0.046220   0.840970   0.070796   0.016098   0.004492   0.054465   \n",
       "12    0.054436   0.826146   0.070796   0.016098   0.000000   0.049667   \n",
       "13    0.061112   0.854447   0.070796   0.016098   0.000919   0.047704   \n",
       "14    0.065734   0.977089   0.088496   0.010233   0.004425   0.041799   \n",
       "15    0.069329   1.000000   0.088496   0.010233   0.006940   0.045519   \n",
       "16    0.074978   0.964960   0.088496   0.010233   0.004131   0.053561   \n",
       "17    0.080114   0.983827   0.088496   0.010233   0.004859   0.060230   \n",
       "18    0.082168   0.912399   0.123894   0.088327   0.007737   0.071551   \n",
       "19    0.085763   0.885445   0.123894   0.088327   0.007671   0.075425   \n",
       "20    0.090385   0.834232   0.123894   0.088327   0.007879   0.078051   \n",
       "21    0.094493   0.840970   0.123894   0.088327   0.009344   0.081948   \n",
       "22    0.100656   0.764151   0.123894   0.060625   0.008514   0.088034   \n",
       "23    0.105278   0.757412   0.123894   0.060625   0.009754   0.098419   \n",
       "24    0.109386   0.766846   0.123894   0.060625   0.010002   0.107964   \n",
       "25    0.114522   0.691375   0.123894   0.060625   0.010932   0.108021   \n",
       "26    0.120171   0.665768   0.185841   0.150628   0.011186   0.109932   \n",
       "27    0.128388   0.749326   0.185841   0.150628   0.014308   0.131357   \n",
       "28    0.136091   0.754717   0.185841   0.150628   0.017095   0.136955   \n",
       "29    0.143280   0.822102   0.185841   0.150628   0.013794   0.144708   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "140   0.836059   0.005391   0.628319   0.615095   0.487643   0.891301   \n",
       "141   0.837600   0.118598   0.628319   0.615095   0.522368   0.901730   \n",
       "142   0.848837   0.084906   0.628319   0.468326   0.523774   0.902560   \n",
       "143   0.858830   0.133423   0.628319   0.468326   0.563974   0.912838   \n",
       "144   0.865573   0.211590   0.752212   0.468326   0.585729   0.921944   \n",
       "145   0.880456   0.258760   0.752212   0.468326   0.574832   0.926809   \n",
       "146   0.890742   0.176550   0.752212   0.505899   0.492219   0.917471   \n",
       "147   0.911361   0.194070   0.752212   0.505899   0.495291   0.924215   \n",
       "148   0.918623   0.202156   0.876106   0.505899   0.448658   0.917672   \n",
       "149   0.880214   0.278976   0.876106   0.505899   0.336796   0.888961   \n",
       "150   0.885848   0.475741   0.876106   0.522170   0.326072   0.870532   \n",
       "151   0.897634   0.505391   0.876106   0.522170   0.393913   0.868757   \n",
       "152   0.903134   0.485175   1.000000   0.522170   0.457533   0.873038   \n",
       "153   0.910766   0.454178   1.000000   0.522170   0.490016   0.885760   \n",
       "154   0.910796   0.435310   1.000000   0.461602   0.518532   0.891503   \n",
       "155   0.910005   0.419137   1.000000   0.461602   0.454615   0.904376   \n",
       "156   0.915531   0.405660   1.000000   0.461602   0.512036   0.913457   \n",
       "157   0.926814   0.467655   1.000000   0.461602   0.574963   0.921993   \n",
       "158   0.940033   0.424528   1.000000   0.474936   0.603344   0.916728   \n",
       "159   0.949071   0.421833   1.000000   0.474936   0.601672   0.926605   \n",
       "160   0.958269   0.471698   1.000000   0.474936   0.522392   0.929488   \n",
       "161   0.961484   0.439353   1.000000   0.474936   0.564399   0.944918   \n",
       "162   0.969618   0.428571   1.000000   0.454052   0.672082   0.954114   \n",
       "163   0.968165   0.467655   1.000000   0.454052   0.637434   0.960627   \n",
       "164   0.980958   0.482480   1.000000   0.454052   0.677541   0.962305   \n",
       "165   0.982015   0.498652   1.000000   0.454052   0.656129   0.962620   \n",
       "166   0.987552   0.493261   1.000000   0.425841   0.711033   0.972440   \n",
       "167   0.987937   0.521563   1.000000   0.425841   0.741081   0.975148   \n",
       "168   0.994397   0.526954   1.000000   0.425841   0.822599   0.986077   \n",
       "169   1.000000   0.579515   1.000000   0.425841   0.912281   1.000000   \n",
       "\n",
       "     var7(t-2)  var8(t-2)  var9(t-2)  var10(t-2)     ...       var3(t)  \\\n",
       "0     0.364549   0.012577   0.777328    0.287966     ...      0.000000   \n",
       "1     0.364549   0.022815   0.905870    0.213873     ...      0.000000   \n",
       "2     0.371238   0.035178   0.925607    0.197583     ...      0.000000   \n",
       "3     0.294314   0.043531   0.885121    0.230688     ...      0.000000   \n",
       "4     0.297659   0.051047   1.000000    0.252233     ...      0.000000   \n",
       "5     0.254181   0.055557   0.941802    0.276406     ...      0.000000   \n",
       "6     0.143813   0.063295   0.941296    0.368891     ...      0.000000   \n",
       "7     0.163880   0.076473   0.790486    0.442459     ...      0.000000   \n",
       "8     0.147157   0.082993   0.692814    0.562796     ...      0.000000   \n",
       "9     0.123746   0.095893   0.516700    0.519180     ...      0.000000   \n",
       "10    0.177257   0.107006   0.531377    0.487651     ...      0.000000   \n",
       "11    0.214047   0.109850   0.510121    0.623226     ...      0.000000   \n",
       "12    0.307692   0.119148   0.326417    0.592223     ...      0.000000   \n",
       "13    0.431439   0.125190   0.237854    0.444561     ...      0.070796   \n",
       "14    0.658863   0.129844   0.246964    0.287441     ...      0.070796   \n",
       "15    0.752509   0.138128   0.294534    0.287966     ...      0.070796   \n",
       "16    0.729097   0.145199   0.384109    0.324225     ...      0.088496   \n",
       "17    0.675585   0.147704   0.412955    0.269574     ...      0.088496   \n",
       "18    0.585284   0.157988   0.463563    0.250657     ...      0.088496   \n",
       "19    0.551840   0.168782   0.501012    0.284288     ...      0.088496   \n",
       "20    0.548495   0.179891   0.614879    0.272202     ...      0.123894   \n",
       "21    0.581940   0.186508   0.657389    0.240673     ...      0.123894   \n",
       "22    0.528428   0.194852   0.788462    0.242775     ...      0.123894   \n",
       "23    0.474917   0.208651   0.702429    0.279559     ...      0.123894   \n",
       "24    0.444816   0.216263   0.730769    0.318970     ...      0.123894   \n",
       "25    0.371238   0.230849   0.828441    0.341040     ...      0.123894   \n",
       "26    0.391305   0.239740   0.772773    0.353127     ...      0.123894   \n",
       "27    0.297659   0.253812   0.792004    0.395691     ...      0.123894   \n",
       "28    0.304348   0.262443   0.741397    0.440357     ...      0.185841   \n",
       "29    0.277592   0.275159   0.778846    0.523384     ...      0.185841   \n",
       "..         ...        ...        ...         ...     ...           ...   \n",
       "140   0.167224   0.943360   0.614879    0.272202     ...      0.628319   \n",
       "141   0.133779   0.954584   0.578947    0.271676     ...      0.628319   \n",
       "142   0.100335   0.963840   0.501012    0.272727     ...      0.628319   \n",
       "143   0.120402   0.959062   0.477227    0.272202     ...      0.628319   \n",
       "144   0.173913   0.964021   0.343117    0.255912     ...      0.628319   \n",
       "145   0.200669   0.971981   0.269231    0.219128     ...      0.628319   \n",
       "146   0.244147   0.975167   0.253036    0.133473     ...      0.752212   \n",
       "147   0.324415   0.978690   0.273785    0.101419     ...      0.752212   \n",
       "148   0.431439   0.984687   0.159413    0.091435     ...      0.752212   \n",
       "149   0.508361   0.986956   0.027834    0.004729     ...      0.752212   \n",
       "150   0.678930   0.980988   0.000000    0.005780     ...      0.876106   \n",
       "151   0.839465   0.986039   0.040486    0.007357     ...      0.876106   \n",
       "152   0.909699   0.979853   0.040486    0.004204     ...      0.876106   \n",
       "153   1.000000   0.971226   0.038462    0.002627     ...      0.876106   \n",
       "154   0.973245   0.972889   0.066296    0.004729     ...      1.000000   \n",
       "155   0.956522   0.978432   0.015688    0.005780     ...      1.000000   \n",
       "156   0.896321   0.975759   0.045040    0.006306     ...      1.000000   \n",
       "157   0.933111   0.974176   0.017206    0.005780     ...      1.000000   \n",
       "158   0.876254   0.966966   0.048077    0.003678     ...      1.000000   \n",
       "159   0.829431   0.969351   0.052126    0.001051     ...      1.000000   \n",
       "160   0.829431   0.973106   0.073381    0.000525     ...      1.000000   \n",
       "161   0.775920   0.977297   0.095648    0.000000     ...      1.000000   \n",
       "162   0.722409   0.985247   0.096154    0.003153     ...      1.000000   \n",
       "163   0.725753   0.988456   0.127530    0.004729     ...      1.000000   \n",
       "164   0.712375   0.990202   0.173077    0.003678     ...      1.000000   \n",
       "165   0.709030   0.997838   0.238360    0.004729     ...      1.000000   \n",
       "166   0.735786   0.995213   0.250000    0.003678     ...      1.000000   \n",
       "167   0.715719   0.998287   0.175607    0.001051     ...      1.000000   \n",
       "168   0.628762   1.000000   0.179656    0.000525     ...      1.000000   \n",
       "169   0.511706   0.991671   0.255567    0.001051     ...      1.000000   \n",
       "\n",
       "      var4(t)   var5(t)   var6(t)   var7(t)   var8(t)   var9(t)  var10(t)  \\\n",
       "0    0.000000  0.011135  0.000000  0.357859  0.000000  0.711032  0.191277   \n",
       "1    0.000000  0.011540  0.002517  0.384615  0.003515  0.769737  0.254335   \n",
       "2    0.000000  0.011813  0.005986  0.364549  0.012577  0.777328  0.287966   \n",
       "3    0.000000  0.012940  0.007292  0.364549  0.022815  0.905870  0.213873   \n",
       "4    0.009757  0.016043  0.015337  0.371238  0.035178  0.925607  0.197583   \n",
       "5    0.009757  0.016473  0.025907  0.294314  0.043531  0.885121  0.230688   \n",
       "6    0.009757  0.016369  0.030211  0.297659  0.051047  1.000000  0.252233   \n",
       "7    0.009757  0.017281  0.038038  0.254181  0.055557  0.941802  0.276406   \n",
       "8    0.019255  0.013679  0.049833  0.143813  0.063295  0.941296  0.368891   \n",
       "9    0.019255  0.010031  0.055399  0.163880  0.076473  0.790486  0.442459   \n",
       "10   0.019255  0.012293  0.052701  0.147157  0.082993  0.692814  0.562796   \n",
       "11   0.019255  0.008085  0.057306  0.123746  0.095893  0.516700  0.519180   \n",
       "12   0.016098  0.008102  0.053166  0.177257  0.107006  0.531377  0.487651   \n",
       "13   0.016098  0.004492  0.054465  0.214047  0.109850  0.510121  0.623226   \n",
       "14   0.016098  0.000000  0.049667  0.307692  0.119148  0.326417  0.592223   \n",
       "15   0.016098  0.000919  0.047704  0.431439  0.125190  0.237854  0.444561   \n",
       "16   0.010233  0.004425  0.041799  0.658863  0.129844  0.246964  0.287441   \n",
       "17   0.010233  0.006940  0.045519  0.752509  0.138128  0.294534  0.287966   \n",
       "18   0.010233  0.004131  0.053561  0.729097  0.145199  0.384109  0.324225   \n",
       "19   0.010233  0.004859  0.060230  0.675585  0.147704  0.412955  0.269574   \n",
       "20   0.088327  0.007737  0.071551  0.585284  0.157988  0.463563  0.250657   \n",
       "21   0.088327  0.007671  0.075425  0.551840  0.168782  0.501012  0.284288   \n",
       "22   0.088327  0.007879  0.078051  0.548495  0.179891  0.614879  0.272202   \n",
       "23   0.088327  0.009344  0.081948  0.581940  0.186508  0.657389  0.240673   \n",
       "24   0.060625  0.008514  0.088034  0.528428  0.194852  0.788462  0.242775   \n",
       "25   0.060625  0.009754  0.098419  0.474917  0.208651  0.702429  0.279559   \n",
       "26   0.060625  0.010002  0.107964  0.444816  0.216263  0.730769  0.318970   \n",
       "27   0.060625  0.010932  0.108021  0.371238  0.230849  0.828441  0.341040   \n",
       "28   0.150628  0.011186  0.109932  0.391305  0.239740  0.772773  0.353127   \n",
       "29   0.150628  0.014308  0.131357  0.297659  0.253812  0.792004  0.395691   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "140  0.615095  0.505654  0.886144  0.150502  0.929066  0.740891  0.237520   \n",
       "141  0.615095  0.468529  0.890110  0.117057  0.936641  0.656377  0.258539   \n",
       "142  0.615095  0.487643  0.891301  0.167224  0.943360  0.614879  0.272202   \n",
       "143  0.615095  0.522368  0.901730  0.133779  0.954584  0.578947  0.271676   \n",
       "144  0.468326  0.523774  0.902560  0.100335  0.963840  0.501012  0.272727   \n",
       "145  0.468326  0.563974  0.912838  0.120402  0.959062  0.477227  0.272202   \n",
       "146  0.468326  0.585729  0.921944  0.173913  0.964021  0.343117  0.255912   \n",
       "147  0.468326  0.574832  0.926809  0.200669  0.971981  0.269231  0.219128   \n",
       "148  0.505899  0.492219  0.917471  0.244147  0.975167  0.253036  0.133473   \n",
       "149  0.505899  0.495291  0.924215  0.324415  0.978690  0.273785  0.101419   \n",
       "150  0.505899  0.448658  0.917672  0.431439  0.984687  0.159413  0.091435   \n",
       "151  0.505899  0.336796  0.888961  0.508361  0.986956  0.027834  0.004729   \n",
       "152  0.522170  0.326072  0.870532  0.678930  0.980988  0.000000  0.005780   \n",
       "153  0.522170  0.393913  0.868757  0.839465  0.986039  0.040486  0.007357   \n",
       "154  0.522170  0.457533  0.873038  0.909699  0.979853  0.040486  0.004204   \n",
       "155  0.522170  0.490016  0.885760  1.000000  0.971226  0.038462  0.002627   \n",
       "156  0.461602  0.518532  0.891503  0.973245  0.972889  0.066296  0.004729   \n",
       "157  0.461602  0.454615  0.904376  0.956522  0.978432  0.015688  0.005780   \n",
       "158  0.461602  0.512036  0.913457  0.896321  0.975759  0.045040  0.006306   \n",
       "159  0.461602  0.574963  0.921993  0.933111  0.974176  0.017206  0.005780   \n",
       "160  0.474936  0.603344  0.916728  0.876254  0.966966  0.048077  0.003678   \n",
       "161  0.474936  0.601672  0.926605  0.829431  0.969351  0.052126  0.001051   \n",
       "162  0.474936  0.522392  0.929488  0.829431  0.973106  0.073381  0.000525   \n",
       "163  0.474936  0.564399  0.944918  0.775920  0.977297  0.095648  0.000000   \n",
       "164  0.454052  0.672082  0.954114  0.722409  0.985247  0.096154  0.003153   \n",
       "165  0.454052  0.637434  0.960627  0.725753  0.988456  0.127530  0.004729   \n",
       "166  0.454052  0.677541  0.962305  0.712375  0.990202  0.173077  0.003678   \n",
       "167  0.454052  0.656129  0.962620  0.709030  0.997838  0.238360  0.004729   \n",
       "168  0.425841  0.711033  0.972440  0.735786  0.995213  0.250000  0.003678   \n",
       "169  0.425841  0.741081  0.975148  0.715719  0.998287  0.175607  0.001051   \n",
       "\n",
       "     var11(t)  var11(t+2)  \n",
       "0    0.300492    0.315271  \n",
       "1    0.295566    0.300492  \n",
       "2    0.315271    0.275862  \n",
       "3    0.300492    0.266010  \n",
       "4    0.275862    0.246305  \n",
       "5    0.266010    0.216749  \n",
       "6    0.246305    0.152709  \n",
       "7    0.216749    0.152709  \n",
       "8    0.152709    0.133005  \n",
       "9    0.152709    0.128079  \n",
       "10   0.133005    0.182266  \n",
       "11   0.128079    0.192118  \n",
       "12   0.182266    0.256157  \n",
       "13   0.192118    0.399015  \n",
       "14   0.256157    0.645320  \n",
       "15   0.399015    0.733990  \n",
       "16   0.645320    0.674876  \n",
       "17   0.733990    0.650246  \n",
       "18   0.674876    0.566502  \n",
       "19   0.650246    0.541872  \n",
       "20   0.566502    0.566502  \n",
       "21   0.541872    0.571428  \n",
       "22   0.566502    0.532019  \n",
       "23   0.571428    0.477832  \n",
       "24   0.532019    0.443350  \n",
       "25   0.477832    0.408867  \n",
       "26   0.443350    0.359606  \n",
       "27   0.408867    0.310345  \n",
       "28   0.359606    0.315271  \n",
       "29   0.310345    0.295566  \n",
       "..        ...         ...  \n",
       "140  0.123153    0.108374  \n",
       "141  0.108374    0.078818  \n",
       "142  0.108374    0.088670  \n",
       "143  0.078818    0.088670  \n",
       "144  0.088670    0.113300  \n",
       "145  0.088670    0.133005  \n",
       "146  0.113300    0.162561  \n",
       "147  0.133005    0.211823  \n",
       "148  0.162561    0.310345  \n",
       "149  0.211823    0.438423  \n",
       "150  0.310345    0.645320  \n",
       "151  0.438423    0.798029  \n",
       "152  0.645320    0.847290  \n",
       "153  0.798029    0.891625  \n",
       "154  0.847290    0.876847  \n",
       "155  0.891625    0.847290  \n",
       "156  0.876847    0.822660  \n",
       "157  0.847290    0.827586  \n",
       "158  0.822660    0.758620  \n",
       "159  0.827586    0.763546  \n",
       "160  0.758620    0.753694  \n",
       "161  0.763546    0.699507  \n",
       "162  0.753694    0.645320  \n",
       "163  0.699507    0.635468  \n",
       "164  0.645320    0.610837  \n",
       "165  0.635468    0.576354  \n",
       "166  0.610837    0.566502  \n",
       "167  0.576354    0.536945  \n",
       "168  0.566502    0.497537  \n",
       "169  0.536945    0.448276  \n",
       "\n",
       "[170 rows x 34 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30412912],\n",
       "       [0.29612058],\n",
       "       [0.28008616],\n",
       "       [0.2583109 ],\n",
       "       [0.2468001 ],\n",
       "       [0.21324506],\n",
       "       [0.15360302],\n",
       "       [0.14723341],\n",
       "       [0.12982875],\n",
       "       [0.12839806],\n",
       "       [0.17598239],\n",
       "       [0.19291134],\n",
       "       [0.25310653],\n",
       "       [0.39594078],\n",
       "       [0.6201349 ],\n",
       "       [0.7069893 ],\n",
       "       [0.6583565 ],\n",
       "       [0.62378895],\n",
       "       [0.56150025],\n",
       "       [0.52838874],\n",
       "       [0.54122263],\n",
       "       [0.55173653],\n",
       "       [0.52169   ],\n",
       "       [0.4678266 ],\n",
       "       [0.4313065 ],\n",
       "       [0.39383823],\n",
       "       [0.36199668],\n",
       "       [0.30888423],\n",
       "       [0.3099726 ],\n",
       "       [0.289717  ],\n",
       "       [0.28609362],\n",
       "       [0.26570207],\n",
       "       [0.28697467],\n",
       "       [0.3002004 ],\n",
       "       [0.34646797],\n",
       "       [0.4915257 ],\n",
       "       [0.54435   ],\n",
       "       [0.50284135],\n",
       "       [0.5084698 ],\n",
       "       [0.49952146],\n",
       "       [0.51313144],\n",
       "       [0.62006116],\n",
       "       [0.7040786 ],\n",
       "       [0.78139323],\n",
       "       [0.8667509 ],\n",
       "       [0.9534318 ],\n",
       "       [0.9261733 ],\n",
       "       [0.8795854 ],\n",
       "       [0.78078854],\n",
       "       [0.66405034],\n",
       "       [0.5755939 ],\n",
       "       [0.51270413],\n",
       "       [0.5030767 ],\n",
       "       [0.4889954 ],\n",
       "       [0.48243165],\n",
       "       [0.4839902 ],\n",
       "       [0.47557604],\n",
       "       [0.46653515],\n",
       "       [0.44926655],\n",
       "       [0.4558211 ],\n",
       "       [0.44657123],\n",
       "       [0.41937461],\n",
       "       [0.4013735 ],\n",
       "       [0.35301685],\n",
       "       [0.3028115 ],\n",
       "       [0.28126135],\n",
       "       [0.26437843],\n",
       "       [0.23677686],\n",
       "       [0.22503304],\n",
       "       [0.20950232],\n",
       "       [0.19135772],\n",
       "       [0.19293158],\n",
       "       [0.19532394],\n",
       "       [0.21052964],\n",
       "       [0.20451853],\n",
       "       [0.21100187],\n",
       "       [0.2639658 ],\n",
       "       [0.32670915],\n",
       "       [0.39017725],\n",
       "       [0.42457294],\n",
       "       [0.43349463],\n",
       "       [0.46239737],\n",
       "       [0.50006723],\n",
       "       [0.5312865 ],\n",
       "       [0.5278826 ],\n",
       "       [0.50115514],\n",
       "       [0.47322497],\n",
       "       [0.4650895 ],\n",
       "       [0.4203718 ],\n",
       "       [0.38982004],\n",
       "       [0.38400018],\n",
       "       [0.34067243],\n",
       "       [0.30468172],\n",
       "       [0.25677568],\n",
       "       [0.23549555],\n",
       "       [0.24867973],\n",
       "       [0.2601536 ],\n",
       "       [0.24686018],\n",
       "       [0.24357727],\n",
       "       [0.23026916],\n",
       "       [0.20660652],\n",
       "       [0.20209824],\n",
       "       [0.1977613 ],\n",
       "       [0.16049847],\n",
       "       [0.1380139 ],\n",
       "       [0.11282586],\n",
       "       [0.10133804],\n",
       "       [0.07823621],\n",
       "       [0.08659989],\n",
       "       [0.07147197],\n",
       "       [0.06476876],\n",
       "       [0.05395865],\n",
       "       [0.04661332],\n",
       "       [0.02576612],\n",
       "       [0.01618562],\n",
       "       [0.00891693],\n",
       "       [0.01225028],\n",
       "       [0.01204157],\n",
       "       [0.04709979],\n",
       "       [0.07445361],\n",
       "       [0.1324185 ],\n",
       "       [0.2361978 ],\n",
       "       [0.26808542],\n",
       "       [0.2743401 ],\n",
       "       [0.27421057],\n",
       "       [0.28539956],\n",
       "       [0.29008216],\n",
       "       [0.32368803],\n",
       "       [0.324538  ],\n",
       "       [0.284646  ],\n",
       "       [0.2648242 ],\n",
       "       [0.25160104],\n",
       "       [0.22903869],\n",
       "       [0.22375411],\n",
       "       [0.20718801],\n",
       "       [0.17571408]], dtype=float32)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = model.predict(train_x)\n",
    "yhat = model.predict(test_x)\n",
    "chat\n",
    "#test_x = test_x.reshape((test_x.shape[0], test_x.shape[2]))\n",
    "# invert scaling for forecast\n",
    "#inv_yhat = np.concatenate((yhat, test_x[:, 1:]), axis=1)\n",
    "#inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "#inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "#test_y = test_y.reshape((len(test_y), 1))\n",
    "#inv_y = np.concatenate((test_y, test_x[:, 1:]), axis=1)\n",
    "#inv_y = scaler.inverse_transform(inv_y)\n",
    "#inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "#rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "#print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.savetxt('data', reframed)\n",
    "#np.savetxt('train', train)\n",
    "#np.savetxt('test', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.66667"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corrected = test_y*(datadmax-datadmin)+datadmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15763544, 0.15763544, 0.1231526 , 0.10837428, 0.10837428,\n",
       "       0.07881765, 0.08866991, 0.08866991, 0.11330049, 0.13300486,\n",
       "       0.1625615 , 0.21182251, 0.31034467, 0.43842348, 0.64531978,\n",
       "       0.79802916, 0.84729017, 0.89162513, 0.87684681, 0.84729017,\n",
       "       0.82265959, 0.8275858 , 0.75862041, 0.76354647, 0.75369421,\n",
       "       0.699507  , 0.64531978, 0.63546767, 0.61083724, 0.5763544 ,\n",
       "       0.56650213, 0.5369455 , 0.49753675, 0.44827559])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.966667, 4.966667, 4.733333, 4.633333, 4.633333, 4.433333,\n",
       "       4.5     , 4.5     , 4.666667, 4.8     , 5.      , 5.333333,\n",
       "       6.      , 6.866667, 8.266666, 9.3     , 9.633333, 9.933333,\n",
       "       9.833333, 9.633333, 9.466666, 9.5     , 9.033334, 9.066667,\n",
       "       9.      , 8.633333, 8.266666, 8.2     , 8.033334, 7.8     ,\n",
       "       7.733333, 7.533333, 7.266667, 6.933333])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9278975, 4.857247 , 4.6417766, 4.5473795, 4.57705  , 4.45942  ,\n",
       "       4.4182954, 4.3875666, 4.438446 , 4.550346 , 4.924014 , 5.5047407,\n",
       "       6.0156093, 6.7991643, 8.03442  , 9.116669 , 9.562033 , 9.947903 ,\n",
       "       9.970335 , 9.806146 , 9.556428 , 9.539029 , 9.188082 , 8.963012 ,\n",
       "       8.966921 , 8.693976 , 8.195898 , 8.029287 , 7.9225984, 7.7554884,\n",
       "       7.711894 , 7.5440474, 7.1767955, 6.663141 ], dtype=float32)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctedpred = yhat*(datadmax-datadmin)+datadmin\n",
    "correctedpred = correctedpred.ravel()\n",
    "correctedpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fixing for final results\n",
    "#corrected = corrected[1:]\n",
    "#correctedpred = correctedpred[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x171c1bec6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(corrected, color = 'b')\n",
    "plt.plot(correctedpred, color='R')\n",
    "plt.savefig('bestLSTM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013768066400127576"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((corrected[:-1]-correctedpred[:-1])**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11733740409659477"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = mse **(1/2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015943967"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse2 = ((test_y[-1]-yhat[-1].ravel()) **2).mean()\n",
    "mse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06406915327739161"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse2 = mse2 **(1/2)\n",
    "rmse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "that = np.append(chat,yhat)\n",
    "cthat = that*(datadmax-datadmin)+datadmin\n",
    "ythat = np.append(train_y,test_y)\n",
    "cythat = ythat*(datadmax-datadmin)+datadmin\n",
    "\n",
    "print(len(correctedpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x172a0f54518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cthat, color = 'red')\n",
    "plt.plot(cythat, color = 'b')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lstmpred = pd.DataFrame(correctedpred)\n",
    "#lstmpred.to_csv('lstmpred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.966667, 4.966667, 4.733333, 4.633333, 4.633333, 4.433333,\n",
       "       4.5     , 4.5     , 4.666667, 4.8     , 5.      , 5.333333,\n",
       "       6.      , 6.866667, 8.266666, 9.3     , 9.633333, 9.933333,\n",
       "       9.833333, 9.633333, 9.466666, 9.5     , 9.033334, 9.066667,\n",
       "       9.      , 8.633333, 8.266666, 8.2     , 8.033334, 7.8     ,\n",
       "       7.733333, 7.533333, 7.266667, 6.933333])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 147us/step\n",
      "0.0015967841746340342\n"
     ]
    }
   ],
   "source": [
    "cccc= model.evaluate(test_x, test_y)\n",
    "print(cccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert RMSE from Rohit's fnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32249949219999996\n"
     ]
    }
   ],
   "source": [
    "rmselgfnnminimized = 0.04766\n",
    "rmselgfnn = rmselgfnnminimized*(datadmax-datadmin)\n",
    "print(rmselgfnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3469948376\n"
     ]
    }
   ],
   "source": [
    "rmsefnnmin = 0.05128 \n",
    "rmsefnn = rmsefnnmin* (datadmax-datadmin)\n",
    "print(rmsefnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1     DATE\n",
      "0   5.007432  4.966667  2005-Q3\n",
      "1   4.923615  4.966667  2005-Q4\n",
      "2   4.797026  4.733333  2006-Q1\n",
      "3   4.707138  4.633333  2006-Q2\n",
      "4   4.707228  4.633333  2006-Q3\n",
      "5   4.673553  4.433333  2006-Q4\n",
      "6   4.637179  4.500000  2007-Q1\n",
      "7   4.579552  4.500000  2007-Q2\n",
      "8   4.708280  4.666667  2007-Q3\n",
      "9   4.867116  4.800000  2007-Q4\n",
      "10  5.012656  5.000000  2008-Q1\n",
      "11  5.405794  5.333333  2008-Q2\n",
      "12  5.966443  6.000000  2008-Q3\n",
      "13  6.516630  6.866667  2008-Q4\n",
      "14  7.435602  8.266666  2009-Q1\n",
      "15  8.452121  9.300000  2009-Q2\n",
      "16  9.203259  9.633333  2009-Q3\n",
      "17  9.792269  9.933333  2009-Q4\n",
      "18  9.839908  9.833333  2010-Q1\n",
      "19  9.750477  9.633333  2010-Q2\n",
      "20  9.522014  9.466666  2010-Q3\n",
      "21  9.395329  9.500000  2010-Q4\n",
      "22  9.062531  9.033334  2011-Q1\n",
      "23  8.830804  9.066667  2011-Q2\n",
      "24  8.756750  9.000000  2011-Q3\n",
      "25  8.520042  8.633333  2011-Q4\n",
      "26  8.067394  8.266666  2012-Q1\n",
      "27  7.829520  8.200000  2012-Q2\n",
      "28  7.698093  8.033334  2012-Q3\n",
      "29  7.545633  7.800000  2012-Q4\n",
      "30  7.485970  7.733333  2013-Q1\n",
      "31  7.371803  7.533333  2013-Q2\n",
      "32  7.152013  7.266667  2013-Q3\n",
      "33  6.778305  6.933333  2013-Q4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dates.index=range(34)\n",
    "correctedpreddf = pd.DataFrame(correctedpred)\n",
    "correcteddf = pd.DataFrame(corrected)\n",
    "lstmgraph = pd.concat([correctedpreddf, correcteddf], ignore_index=True, join='outer', axis=1)\n",
    "lstmgraphs = lstmgraph.join(dates)\n",
    "\n",
    "print(lstmgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-07-01</th>\n",
       "      <td>5.007432</td>\n",
       "      <td>4.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-01</th>\n",
       "      <td>4.923615</td>\n",
       "      <td>4.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01</th>\n",
       "      <td>4.797026</td>\n",
       "      <td>4.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-01</th>\n",
       "      <td>4.707138</td>\n",
       "      <td>4.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-07-01</th>\n",
       "      <td>4.707228</td>\n",
       "      <td>4.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-01</th>\n",
       "      <td>4.673553</td>\n",
       "      <td>4.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>4.637179</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-04-01</th>\n",
       "      <td>4.579552</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-07-01</th>\n",
       "      <td>4.708280</td>\n",
       "      <td>4.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-10-01</th>\n",
       "      <td>4.867116</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01</th>\n",
       "      <td>5.012656</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-01</th>\n",
       "      <td>5.405794</td>\n",
       "      <td>5.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-07-01</th>\n",
       "      <td>5.966443</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-01</th>\n",
       "      <td>6.516630</td>\n",
       "      <td>6.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>7.435602</td>\n",
       "      <td>8.266666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-01</th>\n",
       "      <td>8.452121</td>\n",
       "      <td>9.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01</th>\n",
       "      <td>9.203259</td>\n",
       "      <td>9.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-01</th>\n",
       "      <td>9.792269</td>\n",
       "      <td>9.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>9.839908</td>\n",
       "      <td>9.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>9.750477</td>\n",
       "      <td>9.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>9.522014</td>\n",
       "      <td>9.466666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-01</th>\n",
       "      <td>9.395329</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>9.062531</td>\n",
       "      <td>9.033334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-01</th>\n",
       "      <td>8.830804</td>\n",
       "      <td>9.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01</th>\n",
       "      <td>8.756750</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "      <td>8.520042</td>\n",
       "      <td>8.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>8.067394</td>\n",
       "      <td>8.266666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>7.829520</td>\n",
       "      <td>8.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01</th>\n",
       "      <td>7.698093</td>\n",
       "      <td>8.033334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01</th>\n",
       "      <td>7.545633</td>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>7.485970</td>\n",
       "      <td>7.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>7.371803</td>\n",
       "      <td>7.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>7.152013</td>\n",
       "      <td>7.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>6.778305</td>\n",
       "      <td>6.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Prediction    Actual\n",
       "DATE                            \n",
       "2005-07-01    5.007432  4.966667\n",
       "2005-10-01    4.923615  4.966667\n",
       "2006-01-01    4.797026  4.733333\n",
       "2006-04-01    4.707138  4.633333\n",
       "2006-07-01    4.707228  4.633333\n",
       "2006-10-01    4.673553  4.433333\n",
       "2007-01-01    4.637179  4.500000\n",
       "2007-04-01    4.579552  4.500000\n",
       "2007-07-01    4.708280  4.666667\n",
       "2007-10-01    4.867116  4.800000\n",
       "2008-01-01    5.012656  5.000000\n",
       "2008-04-01    5.405794  5.333333\n",
       "2008-07-01    5.966443  6.000000\n",
       "2008-10-01    6.516630  6.866667\n",
       "2009-01-01    7.435602  8.266666\n",
       "2009-04-01    8.452121  9.300000\n",
       "2009-07-01    9.203259  9.633333\n",
       "2009-10-01    9.792269  9.933333\n",
       "2010-01-01    9.839908  9.833333\n",
       "2010-04-01    9.750477  9.633333\n",
       "2010-07-01    9.522014  9.466666\n",
       "2010-10-01    9.395329  9.500000\n",
       "2011-01-01    9.062531  9.033334\n",
       "2011-04-01    8.830804  9.066667\n",
       "2011-07-01    8.756750  9.000000\n",
       "2011-10-01    8.520042  8.633333\n",
       "2012-01-01    8.067394  8.266666\n",
       "2012-04-01    7.829520  8.200000\n",
       "2012-07-01    7.698093  8.033334\n",
       "2012-10-01    7.545633  7.800000\n",
       "2013-01-01    7.485970  7.733333\n",
       "2013-04-01    7.371803  7.533333\n",
       "2013-07-01    7.152013  7.266667\n",
       "2013-10-01    6.778305  6.933333"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstmgraphs.index = pd.to_datetime(lstmgraphs['DATE'])\n",
    "\n",
    "lstmgraphs2 = lstmgraphs.iloc[:,0:2]\n",
    "lstmgraphs2.columns = ['Prediction', 'Actual']\n",
    "lstmgraphs.columns = ['Prediction', 'Actual', 'Date']\n",
    "lstmgraphs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\seaborn\\timeseries.py:183: UserWarning: The tsplot function is deprecated and will be removed or replaced (in a substantially altered version) in a future release.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot label index with a null key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-1997267a8686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstmgraphs2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\seaborn\\timeseries.py\u001b[0m in \u001b[0;36mtsplot\u001b[1;34m(data, time, unit, condition, value, err_style, ci, interpolate, color, estimator, n_boot, err_palette, err_kws, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_c\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[0mdf_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_c\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   4380\u001b[0m         \"\"\"\n\u001b[0;32m   4381\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4384\u001b[0m     _shared_docs['pivot_table'] = \"\"\"\n",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mappend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mindexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mindexed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   3144\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3146\u001b[1;33m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3147\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3148\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Wil Grebner\\Documents\\python\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3850\u001b[0m                         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3851\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3852\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot label index with a null key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3854\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot label index with a null key"
     ]
    }
   ],
   "source": [
    "sns.tsplot(data = lstmgraphs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
